{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as plb\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BP = plb.Path(\"../.tmp/eval-neurips-gray-turkey-mistralai/Mistral-7B-v0.1-ft-0.0.0+e22c48a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [f for f in BP.glob(\"*/\") if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = pd.read_json('/Users/user/Documents/CodeProjects/neurips-llm-efficiency-challenge-2023/neurips-llm-efficiency-challenge/.tmp/eval-neurips-gray-turkey-mistralai/Mistral-7B-v0.1-ft-0.0.0+e22c48a/groups/mmlu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMLU = {}\n",
    "\n",
    "for row_idx in range(runs.shape[0]):\n",
    "    row = runs.iloc[row_idx]\n",
    "    headers = [h[\"value\"] for h in row.header]\n",
    "    this = pd.DataFrame(row.rows[0]).transpose()\n",
    "    this.columns = headers\n",
    "    MMLU[row.title] = this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"EM\", \"EM (Robustness)\", \"EM (Fairness)\"]\n",
    "\n",
    "outs = []\n",
    "\n",
    "for mmlu_k, mmlu_df in MMLU.items():\n",
    "    r = mmlu_df.loc['value', cols].to_dict()\n",
    "    r['set'] = mmlu_k\n",
    "    outs.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(outs).sort_values(\"EM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [h[\"value\"] for h in runs.iloc[3].header]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this = pd.DataFrame(runs.iloc[5].rows[0]).transpose()\n",
    "this.columns = headers\n",
    "this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLU subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "req = pd.read_json('/Users/user/Documents/CodeProjects/neurips-llm-efficiency-challenge-2023/neurips-llm-efficiency-challenge/.tmp/eval-neurips-gray-turkey-mistralai/Mistral-7B-v0.1-ft-0.0.0+e22c48a/mmlu:subject=clinical_knowledge,method=multiple_choice_joint,model=neurips_local,data_augmentation=canonical,max_eval_instances=3/display_requests.json')\n",
    "#inst['input'] = inst['input'].apply(lambda x: x['text'])\n",
    "#inst.iloc[0]['references']\n",
    "req = pd.DataFrame.from_dict(req['request'].tolist())\n",
    "print(req.iloc[3].prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cajajejo.commands.api.utils import MAP\n",
    "\n",
    "inst = pd.read_json('/Users/user/Documents/CodeProjects/neurips-llm-efficiency-challenge-2023/neurips-llm-efficiency-challenge/.tmp/eval-neurips-gray-turkey-mistralai/Mistral-7B-v0.1-ft-0.0.0+e22c48a/mmlu:subject=high_school_physics,method=multiple_choice_joint,model=neurips_local,data_augmentation=canonical,max_eval_instances=4/instances.json')\n",
    "\n",
    "inst['correct'] = inst['references'].apply(lambda x: [MAP[i] for i, o in enumerate(x) if 'correct' in o['tags']][0])\n",
    "\n",
    "inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = pd.read_json('/Users/user/Documents/CodeProjects/neurips-llm-efficiency-challenge-2023/neurips-llm-efficiency-challenge/.tmp/eval-neurips-gray-turkey-mistralai/Mistral-7B-v0.1-ft-0.0.0+e22c48a/mmlu:subject=high_school_physics,method=multiple_choice_joint,model=neurips_local,data_augmentation=canonical,max_eval_instances=4/display_predictions.json')\n",
    "adf[\"pred_category\"] = adf['predicted_text'].str[0]\n",
    "\n",
    "adf['pred_category'] == inst['correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.read_json('/home/user/neurips-llm-efficiency-challenge/out/runs/adaptable-starfish-mistralai/latest/bbq:subject=all,method=multiple_choice_joint,model=neurips_local,max_eval_instances=18/display_predictions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = pd.read_json('/home/user/neurips-llm-efficiency-challenge/out/runs/adaptable-starfish-mistralai/latest/bbq:subject=all,method=multiple_choice_joint,model=neurips_local,max_eval_instances=18/instances.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cajajejo.commands.api.utils import MAP\n",
    "\n",
    "c = []\n",
    "\n",
    "for r in i[\"references\"].tolist():\n",
    "    for idx, ch in enumerate(r):\n",
    "        if 'correct' in ch.get('tags'):\n",
    "            c.append(MAP[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pred == corr for pred, corr in zip(p['predicted_text'].tolist(), c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
