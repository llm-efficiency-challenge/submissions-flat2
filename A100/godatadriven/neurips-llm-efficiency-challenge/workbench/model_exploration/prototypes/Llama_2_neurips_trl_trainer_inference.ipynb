{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362e4099-a38a-4e0c-b8a7-9df02305e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from peft import (\n",
    "    get_peft_config, \n",
    "    PeftModel, \n",
    "    PeftConfig, \n",
    "    get_peft_model, \n",
    "    LoraConfig, \n",
    "    TaskType,\n",
    "    prepare_model_for_kbit_training\n",
    ")\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    BitsAndBytesConfig,\n",
    "    TrainerCallback,\n",
    "    TrainingArguments\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "from datasets import load_dataset, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2809d82-2092-452a-bf5f-3b2ed6178479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from the lit-gpt repository\n",
    "def generate_prompt(example):\n",
    "    \"\"\"Generates a standardized message to prompt the model with an instruction, optional input and a\n",
    "    'response' field.\"\"\"\n",
    "\n",
    "    if example[\"context\"]:\n",
    "        return (\n",
    "            \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            f\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['context']}\\n\\n### Response:\"\n",
    "        )\n",
    "    return (\n",
    "        \"Below is an instruction that describes a task. \"\n",
    "        \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "        f\"### Instruction:\\n{example['instruction']}\\n\\n### Response:\"\n",
    "    )\n",
    "\n",
    "\n",
    "def extract_response_text(input_string):\n",
    "    start_marker = '### Response:'\n",
    "    end_marker = '###'\n",
    "    \n",
    "    start_index = input_string.find(start_marker)\n",
    "    if start_index == -1:\n",
    "        return None\n",
    "    \n",
    "    start_index += len(start_marker)\n",
    "    \n",
    "    end_index = input_string.find(end_marker, start_index)\n",
    "    if end_index == -1:\n",
    "        return input_string[start_index:]\n",
    "    \n",
    "    return input_string[start_index:end_index].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1525f9c9-12cc-4b36-80b7-88d56b046260",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_id = \"meta-llama/Llama-2-13b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa61d1c-227a-4a0b-8533-dab2e996b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"merged/llama2-13B-instruct-dolly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b5484-a82d-4faa-8b71-5d804a77e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504b98e-3e52-4b32-a8a1-10d21e9ae8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id, use_fast=False)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "# When loading 1st time this will be slow\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id, \n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\":0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88fc7a8-3977-4cb6-b426-85d8b0297e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = {\"instruction\": \"Tell me the meaning of life\", \"context\": \"\"}\n",
    "\n",
    "#q={'instruction': 'What is the origin of orange wine?', \"context\":\"\"}\n",
    "\n",
    "prompt = generate_prompt(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a6408-3c60-4765-84ed-44ba14a6fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Response:\"\"\".format(test)\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6d4cc2-aa68-4f64-a159-386ae544965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_output = model.generate(\n",
    "  input_ids=input_ids, max_new_tokens=256\n",
    ")\n",
    "\n",
    "response = tokenizer.decode(generation_output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7d585-54dd-48e0-90ac-63207fa09cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_response_text(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245695d-d4e4-46f3-8912-c551354702bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
