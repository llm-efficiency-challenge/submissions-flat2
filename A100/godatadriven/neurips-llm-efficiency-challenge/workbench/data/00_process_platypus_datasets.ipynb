{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "W8jKJvD_aH3E"
   },
   "source": [
    "# Subsetting & merging instruction finetuning datasets\n",
    "\n",
    "| **Dataset** \t| **Source** \t| **Generation** \t|\n",
    "|---\t|---\t|---\t|\n",
    "| openai/prm800K \t| https://github.com/openai/prm800k \t| H \t|\n",
    "| databricks/databricks-dolly-15k \t| https://huggingface.co/datasets/databricks/databricks-dolly-15k \t| H \t|\n",
    "| timdettmers/openassistant-guanaco \t| https://huggingface.co/datasets/timdettmers/openassistant-guanaco \t| H \t|\n",
    "| metaeval/reclor \t| https://whyu.me/reclor/; https://openreview.net/pdf?id=HJgJtT4tvB \t| H \t|\n",
    "| mandyyyyii/scibench \t| https://github.com/mandyyyyii/scibench; https://huggingface.co/datasets/xw27/scibench \t| H \t|\n",
    "| metaeval/ScienceQA_text_only \t| https://huggingface.co/datasets/metaeval/ScienceQA_text_only \t| H \t|\n",
    "| wenhu/TheoremQA \t| https://github.com/wenhuchen/TheoremQA \t| H \t|\n",
    "| TigerResearch/tigerbot-kaggle-leetcodesolutions-en-2k \t| https://huggingface.co/datasets/TigerResearch/tigerbot-kaggle-leetcodesolutions-en-2k \t| H \t|\n",
    "| hendrycks/MATH \t| https://github.com/hendrycks/math \t| H \t|\n",
    "| duckai/arb \t| https://github.com/TheDuckAI/arb \t| H \t|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib as plb\n",
    "import json\n",
    "import random\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "from getpass import getpass\n",
    "import sh\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  pat = getpass('Huggingface PAT: ')\n",
    "\n",
    "  sh.huggingface_cli.login('--token', pat)\n",
    "except Exception as e:\n",
    "  print(e)\n",
    "finally:\n",
    "  pat = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = \"../../data/raw\"\n",
    "INTERMEDIATE_PATH = \"../../data/intermediate\"\n",
    "PROCESSED_PATH = \"../../data/processed\"\n",
    "\n",
    "raw_path = plb.Path(RAW_PATH)\n",
    "intermediate_path = plb.Path(INTERMEDIATE_PATH)\n",
    "processed_path = plb.Path(PROCESSED_PATH)\n",
    "\n",
    "raw_path.mkdir(parents=True, exist_ok=True)\n",
    "intermediate_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "processed_path.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openai/prm800K\n",
    "\n",
    "NB: this dataset is merged with MATH dataset below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this is you also want the ones were the final solution wasn't found\n",
    "ONLY_SOLVED = True\n",
    "ONLY_FOUND_ANSWER = True\n",
    "\n",
    "# Script to convert the openai prm800K dataset into input output pairs\n",
    "\n",
    "def download_files():\n",
    "    urls = [\"https://github.com/openai/prm800k/raw/main/prm800k/data/phase1_test.jsonl\",\n",
    "            \"https://github.com/openai/prm800k/raw/main/prm800k/data/phase1_train.jsonl\",\n",
    "            \"https://github.com/openai/prm800k/raw/main/prm800k/data/phase2_test.jsonl\",\n",
    "            \"https://github.com/openai/prm800k/raw/main/prm800k/data/phase2_train.jsonl\"]\n",
    "\n",
    "    raw_files_prm = raw_path / \"openai_prm800k_raw\"\n",
    "    raw_files_prm.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    output_file_names = [str(raw_files_prm / name.split('/')[-1]) for name in urls]\n",
    "    for i in range(len(urls)):\n",
    "        url = urls[i]\n",
    "        output_file = output_file_names[i]\n",
    "\n",
    "        # Check if the file already exists\n",
    "        if not os.path.isfile(output_file):\n",
    "            # If the file doesn't exist, download it\n",
    "            try:\n",
    "                subprocess.run([\"curl\", \"-L\", url, \"-o\", output_file])\n",
    "                # print(\"Downloaded\", output_file, \"successfully!\")\n",
    "            except:\n",
    "                # If the curl command fails, try wget\n",
    "                subprocess.run([\"wget\", url, \"-O\", output_file])\n",
    "                # print(\"Downloaded\", output_file, \"successfully!\")\n",
    "        else:\n",
    "            print(\"File\", output_file, \"already exists, skipping download\")\n",
    "\n",
    "    return output_file_names\n",
    "\n",
    "\n",
    "def convert_format(data, ONLY_SOLVED):\n",
    "    # Check for solved questions\n",
    "    if ONLY_SOLVED and data[\"label\"][\"finish_reason\"] != \"solution\":\n",
    "        return None\n",
    "\n",
    "    input = data[\"question\"][\"problem\"]\n",
    "    answer = data[\"question\"][\"ground_truth_answer\"]\n",
    "\n",
    "    steps = data[\"label\"][\"steps\"]\n",
    "    output = []\n",
    "    answer_marker = \"# Answer\\n\\n\"\n",
    "    for step in steps:\n",
    "        # Get a set of correct completions\n",
    "        completions = step.get(\"completions\")\n",
    "        selected_text = None\n",
    "        if completions is not None:\n",
    "            rated_completions = [comp for comp in completions if comp[\"rating\"] == 1]\n",
    "            completions_with_answer = [comp for comp in rated_completions if answer_marker in comp[\"text\"]]\n",
    "            if completions_with_answer:\n",
    "                selected_completion = random.choice(completions_with_answer)\n",
    "                selected_text = selected_completion[\"text\"]\n",
    "            elif rated_completions:\n",
    "                selected_completion = random.choice(rated_completions)\n",
    "                selected_text = selected_completion[\"text\"]\n",
    "\n",
    "        if selected_text:\n",
    "            output.append(selected_text)\n",
    "\n",
    "        human_completion = step.get(\"human_completion\")\n",
    "        if human_completion and human_completion[\"rating\"] == 1:\n",
    "            output.append(human_completion[\"text\"])\n",
    "\n",
    "    full_output = \" \".join(output)\n",
    "\n",
    "    # Find answer in the output if available\n",
    "    answer_start_index = full_output.rfind(answer_marker)\n",
    "    if answer_start_index != -1:\n",
    "        answer_end_index = answer_start_index + len(answer_marker)\n",
    "        found_answer = full_output[answer_end_index:].strip()\n",
    "    else:\n",
    "        found_answer = None\n",
    "    return {\n",
    "        \"Input\": input,\n",
    "        \"Output\": full_output,\n",
    "        \"Answer\": answer,\n",
    "        \"Found_Answer\": found_answer,\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    output_file = str(intermediate_path / \"openai_prm800k_formatted.jsonl\")\n",
    "    input_files = download_files()\n",
    "\n",
    "    with open(output_file, 'w') as out_f:\n",
    "        for input_file_name in input_files:\n",
    "            with open(input_file_name, 'r') as input_file:\n",
    "                line_count = 0\n",
    "                for line in input_file:\n",
    "                    line_count += 1\n",
    "                    data = json.loads(line)\n",
    "                    converted_data = convert_format(data, ONLY_SOLVED)\n",
    "                    if converted_data is not None:\n",
    "                        if ONLY_FOUND_ANSWER and converted_data[\"Found_Answer\"] == None:\n",
    "                            pass\n",
    "                        elif converted_data[\"Found_Answer\"] == converted_data[\"Answer\"]:\n",
    "                            out_f.write(json.dumps(converted_data) + '\\n')\n",
    "                # print the number of lines in the input file, including the file name\n",
    "                print(\"Number of lines in\", input_file_name, \":\", line_count)\n",
    "    # Print the number of lines in the output file\n",
    "    print(\"Number of lines in\", output_file, \":\", sum(1 for line in open(output_file)))\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(str(intermediate_path / \"openai_prm800k_formatted.jsonl\"), lines=True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databricks/dolly-15k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dolly = load_dataset(\"databricks/databricks-dolly-15k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolly = ds_dolly[\"train\"].to_pandas().drop(columns=[\"category\"]).rename(columns={\"context\": \"input\", \"response\": \"output\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolly.to_json(processed_path / \"databricks_dolly15k.jsonl\",\n",
    "           orient=\"records\",\n",
    "           lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dolly"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Openassistant-guanaco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install py3langid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py3langid.langid import LanguageIdentifier, MODEL_FILE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "guanaco = load_dataset('timdettmers/openassistant-guanaco',split='train')\n",
    "guanaco_test = load_dataset('timdettmers/openassistant-guanaco',split='test')\n",
    "\n",
    "# Put the guanaco data in a  dataframe from the guanaco and guanaco_test variables\n",
    "df = pd.DataFrame(guanaco)\n",
    "df_test = pd.DataFrame(guanaco_test)\n",
    "df = pd.concat([df, df_test])\n",
    "df.head()\n",
    "\n",
    "def split_text(text):\n",
    "    split_marker = \"### Assistant:\"\n",
    "    instruction, output = text.split(split_marker, 1)\n",
    "    instruction = instruction.replace(\"### Human:\", \"\").strip()\n",
    "    output = output.replace(\"### Human:\", \"### Instruction:\\n\").replace(\"### Assistant:\", \"### Response:\\n\").strip()\n",
    "    return pd.Series([instruction, output])\n",
    "\n",
    "# Apply the function to the filtered dataframe\n",
    "df[['instruction', 'output']] = df['text'].apply(split_text)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_language_with_langid(df):  \n",
    "    identifier = LanguageIdentifier.from_pickled_model(MODEL_FILE, norm_probs=True)\n",
    "    lang, prob = identifier.classify(df[\"text\"].replace(\"### Human:\", \"\").replace(\"### Assistant:\", \"\").strip())\n",
    "    df[\"lang\"] = lang\n",
    "    df[\"lang_prob\"] = prob\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(detect_language_with_langid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df.loc[lambda df: df[\"lang_prob\"] > .5].loc[lambda df: df[\"lang\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_filtered[['instruction', 'output']].to_dict('records')\n",
    "for record in data:\n",
    "    record['input'] = ''\n",
    "\n",
    "data_reordered = []\n",
    "for record in data:\n",
    "    data_reordered.append({'instruction': record['instruction'], 'input': record['input'], 'output': record['output']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (processed_path / \"guanaco.jsonl\").open('w') as f:\n",
    "    for record in data_reordered:\n",
    "        f.write(json.dumps(record) + '\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duckai/arb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_data_from_url(url):\n",
    "    headers = {'accept': 'application/json'}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()  # Raises an HTTPError if the HTTP request returned an unsuccessful status code\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "\n",
    "# MATH\n",
    "\n",
    "url = 'https://arb.duckai.org/api/lib/math'\n",
    "data = fetch_data_from_url(url)\n",
    "\n",
    "if data is not None:\n",
    "    # Extract the ids\n",
    "    ids = [item['_id'] for item in data]\n",
    "\n",
    "    formatted_data = []\n",
    "\n",
    "    # For each id, make a request to the API and format the returned data\n",
    "    for id_ in ids:\n",
    "        response = requests.get(f\"https://arb.duckai.org/api/lib/math/{id_}\")\n",
    "        response_data = response.json()\n",
    "\n",
    "        # Format the data\n",
    "        formatted_entry = {\n",
    "            \"instruction\": response_data[\"Problem_Statement\"],\n",
    "            \"input\": \"\",\n",
    "            \"output\": response_data[\"Solution\"]\n",
    "        }\n",
    "        formatted_data.append(formatted_entry)\n",
    "\n",
    "    # Create a DataFrame from the formatted data\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Save the DataFrame to a new JSON file\n",
    "    df.to_json(processed_path / \"duckai_arb_formatted_math_data.jsonl\", orient=\"records\", lines=True)\n",
    "else:\n",
    "    print(\"No data was returned from the API for Math\")\n",
    "\n",
    "\n",
    "#MCAT READING\n",
    "\n",
    "url = 'https://arb.duckai.org/api/lib/mcatReading'\n",
    "data = fetch_data_from_url(url)\n",
    "\n",
    "if data is not None:\n",
    "    # Create an empty list to hold the formatted data\n",
    "    formatted_data = []\n",
    "\n",
    "    # Loop through each item in the data\n",
    "    for item in data:\n",
    "        # Extract the instruction, possible solutions, and correct answer\n",
    "        instruction = item['Problem Statement']\n",
    "        options = item['Answer Candidates']\n",
    "        output = item['Solution']\n",
    "\n",
    "        output = output.split('.', 1)[-1].lstrip()\n",
    "\n",
    "    # Append the options to the instruction\n",
    "        for i, option in enumerate(options, start=65):\n",
    "            instruction += f\"\\n{chr(i)}. {option}\"\n",
    "\n",
    "\n",
    "        # Create a new dictionary with 'input' and 'output' switched\n",
    "        formatted_entry = {\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": \"Choose A, B, C or D as your solution.\",\n",
    "            \"output\": output\n",
    "        }\n",
    "\n",
    "        # Add the formatted entry to the list\n",
    "        formatted_data.append(formatted_entry)\n",
    "\n",
    "    # Create a DataFrame from the formatted data\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Save the DataFrame to a new JSON file\n",
    "    df.to_json(processed_path / \"duckai_arb_formatted_mcat_data.jsonl\", orient=\"records\", lines=True)\n",
    "else:\n",
    "    print(\"No data was returned from the API for MCAT Reading\")\n",
    "\n",
    "# LAW\n",
    "\n",
    "# Load the data from the file\n",
    "url = 'https://arb.duckai.org/api/lib/law'\n",
    "data = fetch_data_from_url(url)\n",
    "\n",
    "if data is not None:\n",
    "    # Create an empty list to hold the formatted data\n",
    "    formatted_data = []\n",
    "\n",
    "    # Loop through each item in the data\n",
    "    for item in data:\n",
    "        # Extract the instruction, possible solutions, and correct answer\n",
    "        instruction = item['Problem Statement']\n",
    "        options = item['Answer Candidates']\n",
    "        output = item['Final Answer']\n",
    "\n",
    "    # Append the options to the instruction\n",
    "        for i, option in enumerate(options, start=65):\n",
    "            instruction += f\"\\n{chr(i)}. {option}\"\n",
    "\n",
    "\n",
    "        # Create a new dictionary with 'input' and 'output' switched\n",
    "        formatted_entry = {\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": \"Choose A, B, C or D as your solution.\",\n",
    "            \"output\": output\n",
    "        }\n",
    "\n",
    "        # Add the formatted entry to the list\n",
    "        formatted_data.append(formatted_entry)\n",
    "\n",
    "    # Create a DataFrame from the formatted data\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Save the DataFrame to a new JSON file\n",
    "    df.to_json(processed_path / \"duckai_arb_formatted_law_data.jsonl\", orient=\"records\", lines=True)\n",
    "else:\n",
    "    print(\"No data was returned from the API for MCAT Reading\")\n",
    "\n",
    "\n",
    "#MCAT SCIENCE\n",
    "\n",
    "url = 'https://arb.duckai.org/api/lib/mcatscience/val'\n",
    "data = fetch_data_from_url(url)\n",
    "\n",
    "if data is not None:\n",
    "    # Create an empty list to hold the formatted data\n",
    "    formatted_data = []\n",
    "\n",
    "    # Loop through each item in the data\n",
    "    for item in data:\n",
    "        # Extract the instruction, possible solutions, and correct answer\n",
    "        instruction = item['Problem Statement']\n",
    "        options = item['Answer Candidates']\n",
    "        output = item['Solution']\n",
    "\n",
    "        output = output.split('.', 1)[-1].lstrip()\n",
    "\n",
    "    # Append the options to the instruction\n",
    "        for i, option in enumerate(options, start=65):  # ASCII value of 'A' is 65\n",
    "            instruction += f\"\\n{chr(i)}. {option}\"\n",
    "\n",
    "\n",
    "        # Create a new dictionary with 'input' and 'output' switched\n",
    "        formatted_entry = {\n",
    "            \"instruction\": instruction,\n",
    "            \"input\": \"Choose A, B, C or D as your solution.\",\n",
    "            \"output\": output\n",
    "        }\n",
    "\n",
    "        # Add the formatted entry to the list\n",
    "        formatted_data.append(formatted_entry)\n",
    "\n",
    "    # Create a DataFrame from the formatted data\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Save the DataFrame to a new JSON file\n",
    "    df.to_json(processed_path / \"duckai_arb_formatted_mcat_science_data.jsonl\", orient=\"records\", lines=True)\n",
    "else:\n",
    "    print(\"No data was returned from the API for MCAT Science\")\n",
    "\n",
    "# PHYSICS\n",
    "\n",
    "url = 'https://arb.duckai.org/api/lib/physics/val'\n",
    "data = fetch_data_from_url(url)\n",
    "\n",
    "\n",
    "if data is not None:\n",
    "    # Extract the ids\n",
    "    ids = [item['_id'] for item in data]\n",
    "\n",
    "    formatted_data = []\n",
    "\n",
    "    # For each id, make a request to the API and format the returned data\n",
    "    for id_ in ids:\n",
    "        try:\n",
    "            response = requests.get(f\"https://arb.duckai.org/api/lib/physics/val/{id_}\")\n",
    "            response_data = response.json()\n",
    "            # Format the data\n",
    "            formatted_entry = {\n",
    "                \"instruction\": response_data[\"Problem_Statement\"],\n",
    "                \"input\": \"\",\n",
    "                \"output\": response_data[\"Solution\"]\n",
    "            }\n",
    "            formatted_data.append(formatted_entry)\n",
    "\n",
    "        except:\n",
    "            print(f\"Error with id: {id_}\")\n",
    "\n",
    "\n",
    "    # Create a DataFrame from the formatted data\n",
    "    df = pd.DataFrame(formatted_data)\n",
    "\n",
    "    # Save the DataFrame to a new JSON file\n",
    "    df.to_json(processed_path / \"duckai_arb_formatted_physics_data.jsonl\", orient=\"records\", lines=True)\n",
    "else:\n",
    "    print(\"No data was returned from the API for Physics.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metaeval/reclor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('metaeval/reclor', split='train')\n",
    "# Function for update\n",
    "def format_question(data_entry):\n",
    "    context = data_entry['context']\n",
    "    question = data_entry['question']\n",
    "    answers = data_entry['answers']\n",
    "    label = data_entry['label']\n",
    "\n",
    "    formatted_question = context + \" \" + question\n",
    "    for i, ans in enumerate(answers):\n",
    "        formatted_question += \"\\n\" + chr(65+i) + \": \" + ans  \n",
    "\n",
    "    # Create the formatted answer string\n",
    "    formatted_answer = chr(65+label)  \n",
    "\n",
    "    return {\"instruction\": formatted_question, \"input\": \"Choose A, B, C or D as your solution.\", \"output\": formatted_answer}\n",
    "\n",
    "reclor_data = [format_question(entry) for entry in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(reclor_data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(processed_path / \"reclor.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mandyyyyii/scibench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "# The directory where the json files are stored\n",
    "# dir_path = 'original'\n",
    "\n",
    "import subprocess\n",
    "\n",
    "\n",
    "# Define the repository URL\n",
    "repo_url = \"https://github.com/mandyyyyii/scibench.git\"\n",
    "repo_name = \"scibench\"\n",
    "target_subdir = \"dataset/original\"\n",
    "\n",
    "# Clone the repository\n",
    "result_clone = subprocess.run([\"git\", \"clone\", repo_url])\n",
    "\n",
    "# Check if the clone command was successful\n",
    "if result_clone.returncode == 0:\n",
    "    print(\"Repository cloned successfully!\")\n",
    "\n",
    "    # Construct the path to the target directory within the cloned repository\n",
    "    target_path = os.path.join(os.getcwd(), repo_name, target_subdir)\n",
    "    print(\"Path to the target directory:\", target_path)\n",
    "else:\n",
    "    print(\"An error occurred while cloning the repository.\")\n",
    "\n",
    "json_files = [f for f in os.listdir(target_path) if f.endswith('.json')]\n",
    "\n",
    "\n",
    "new_data = []\n",
    "\n",
    "# Iterate over all the files\n",
    "for json_file in json_files:\n",
    "    file_path = os.path.join(target_path, json_file)\n",
    "\n",
    "    # Open each json file\n",
    "    with open(file_path, 'r') as f:\n",
    "        # Load the data\n",
    "        file_data = json.load(f)\n",
    "\n",
    "        # Transform the data\n",
    "        for d in file_data:\n",
    "            output = d.get('solution')\n",
    "            if not output:\n",
    "                output = d.get('answer_number')\n",
    "            transformed_data = {\n",
    "                \"instruction\": d.get('problem_text'),\n",
    "                \"input\": '',\n",
    "                \"output\": output\n",
    "            }\n",
    "            new_data.append(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(processed_path / \"scibench.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScienceQA_text_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "import pandas as pd\n",
    "dataset = load_dataset('metaeval/ScienceQA_text_only') \n",
    "\n",
    "# Load in to a df\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "# Print out all of the unique first three words of the question\n",
    "unique_first_three_words = df['question'].apply(lambda x: ' '.join(x.split()[:3])).unique()\n",
    "print(unique_first_three_words)\n",
    "\n",
    "# Print out all the skills\n",
    "skills = df['skill'].unique().tolist()\n",
    "for skill in sorted(skills):\n",
    "    print(skill)\n",
    "print(len(df['skill'].unique()))\n",
    "\n",
    "skills_to_remove = ['Choose customary units of distance','Choose customary units of mass','Choose customary units of volume','Is it a complete sentence or a run-on','Is the sentence simple compound, comples, or compound-complex','Use guide words']\n",
    "print('Length before removing skills: ', len(df))\n",
    "df = df[~df['skill'].isin(skills_to_remove)]\n",
    "print('Length after removing skills: ', len(df))\n",
    "\n",
    "\n",
    "# remove the task, grade, subject,topic, category, and skill columns\n",
    "df_dropped = df.drop(['task', 'grade', 'subject', 'topic', 'category', 'skill'], axis=1)\n",
    "df_dropped.head(10)\n",
    "\n",
    "# Check if every example has a choices field that is not an empty string\n",
    "print('Length of updated df:',len(df_dropped))\n",
    "df_dropped['solution'].apply(lambda x: x != '').value_counts()\n",
    "\n",
    "# Filter the df to only include examples with a non-empty choices field\n",
    "\n",
    "df_filtered = df_dropped[df_dropped['solution'].apply(lambda x: x != '')]\n",
    "print('Keeping only those questions which have a long-form solution:',len(df_filtered))\n",
    "# Reset the row numbers of df_filtered\n",
    "df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "# Create a new df with the columns we want to keep\n",
    "df_reformatted = df_filtered[['question', 'choices', 'solution', 'lecture', 'answer']]\n",
    "\n",
    "# Add a column which contains the correct answer based on the answer index for the list\n",
    "df_reformatted['correct_answer'] = df_reformatted.apply(lambda x: x['choices'][x['answer']], axis=1)\n",
    "\n",
    "# Reformat the choices column to be a string of the form: A, choice1, B, choice2, C, choice3, D, choice4\n",
    "df_reformatted['choices'] = df_reformatted['choices'].apply(lambda x: '\\n'.join([f'{chr(65+i)}: {choice}' for i, choice in enumerate(x)]))\n",
    "\n",
    "# Combine the question and choices columns into one column\n",
    "df_reformatted['question'] = df_reformatted['question'] + '\\n' + df_reformatted['choices']\n",
    "\n",
    "# Rename question to instruction, lecture to input, and solution to output\n",
    "df_reformatted = df_reformatted.rename(columns={'question': 'instruction', 'lecture': 'input', 'solution': 'output','answer':'answer'})\n",
    "\n",
    "# reorder the columns to instruction, input, output, correct_answer, answer\n",
    "df_reformatted = df_reformatted[['instruction', 'input', 'output', 'correct_answer','answer']]\n",
    "\n",
    "print('Length of df_reformatted:', len(df_reformatted))\n",
    "\n",
    "# Remove the examples which have duplicate inputs\n",
    "df_reformatted = df_reformatted.drop_duplicates(subset=['instruction'])\n",
    "print('Length of df_reformatted after removing duplicates:', len(df_reformatted))\n",
    "\n",
    "# Display a graph of the histogram of the lengths of the outputs based on words\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the lengths of the outputs\n",
    "output_lengths = df_reformatted['output'].apply(lambda x: len(x.split()))\n",
    "\n",
    "print('There are ',len(output_lengths[output_lengths > 40]), 'examples with output length > 40')\n",
    "\n",
    "# Print the number of unique inputs\n",
    "print('There are', len(df_reformatted['input'].unique()), 'unique inputs\\n')\n",
    "\n",
    "# Print the unique inputs\n",
    "df_reformatted['input'].unique()\n",
    "\n",
    "# For every input, print the number of examples with that input\n",
    "for input in df_reformatted['input'].unique():\n",
    "    print('There are', len(df_reformatted[df_reformatted['input'] == input]), 'examples with input:', input[:60])\n",
    "    print('\\n')\n",
    "\n",
    "# List of the questions that need description\n",
    "need_description = ['What information supports','Based on','Read the following','Use the evidence','Look at the','According to a']\n",
    "\n",
    "# Removing the input for those which don't need it\n",
    "def check_description(instruction):\n",
    "    for desc in need_description:\n",
    "        if desc in instruction:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Apply the function to the 'instruction' column\n",
    "df_reformatted['contains_description'] = df_reformatted['instruction'].apply(check_description)\n",
    "\n",
    "# Now update 'input' field where 'contains_description' is False\n",
    "df_reformatted.loc[~df_reformatted['contains_description'], 'input'] = ''\n",
    "\n",
    "input_lengths = df_reformatted['input'].apply(lambda x: len(x.split()))\n",
    "output_lengths = df_reformatted['output'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# remove the examples with input length > 400\n",
    "df_reformatted = df_reformatted[input_lengths <= 400].reset_index(drop=True)\n",
    "\n",
    "# save the information from the df_reformatted to a json file, with the format: {\"instruction\": \"instruction text\", \"input\": \"input text\", \"output\": \"output text\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reformatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reformatted.drop(['correct_answer','answer','contains_description'], axis=1).to_json(processed_path / 'scienceqa.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TheoremQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datasets import load_dataset\n",
    "# The path where the csv file is stored\n",
    "file_path = 'test.csv'\n",
    "output_file = processed_path / 'theoremqa.jsonl'\n",
    "dataset = load_dataset(\"wenhu/TheoremQA\", data_files=\"test.csv\")\n",
    "new_data = []\n",
    "\n",
    "# Open the csv file\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "# Transform the data\n",
    "for _, row in df.iterrows():\n",
    "    instruction = \"{}\\nRelevant Theorem: {}\".format(row['Question'], row['theorem_def'])\n",
    "    transformed_data = {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": '',\n",
    "        \"output\": row['Answer']\n",
    "    }\n",
    "    new_data.append(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(output_file, orient=\"records\", lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tigerbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"TigerResearch/tigerbot-kaggle-leetcodesolutions-en-2k\", split=\"train\") \n",
    "\n",
    "# make df from dataset\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# swap the values of instruction and input\n",
    "df['instruction'], df['input'] = df['input'], df['instruction']\n",
    "\n",
    "df = df.loc[lambda df: df[\"input\"].str.contains('python')]\n",
    "\n",
    "# make input empty\n",
    "df['input'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(processed_path / 'tigerbot.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! /usr/bin/env python3\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "import argparse\n",
    "import os\n",
    "import subprocess\n",
    "# Script to update the MATH dataset with enhanced solutions from the PRM dataset\n",
    "# See convert_prm.py for the creating the required PRM file\n",
    "\n",
    "def download_files():\n",
    "    url = 'https://people.eecs.berkeley.edu/~hendrycks/MATH.tar'\n",
    "    tar_file = 'MATH.tar'\n",
    "    output_dir = 'MATH'\n",
    "\n",
    "    # Check if the directory already exists\n",
    "    if not os.path.isdir(output_dir):\n",
    "        # If the directory doesn't exist, download the tar file\n",
    "        try:\n",
    "            subprocess.check_output([\"curl\", \"-L\", url, \"-o\", tar_file])\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"Curl failed with error:\", e.output)\n",
    "            return\n",
    "\n",
    "        # Try to unzip\n",
    "        try:\n",
    "            print(\"Unzipping\", tar_file, \"...\")\n",
    "            subprocess.check_output([\"tar\", \"-xf\", tar_file])\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"Tar failed with error:\", e.output)\n",
    "            return\n",
    "\n",
    "        # Remove the tar file\n",
    "        try:\n",
    "            subprocess.check_output([\"rm\", tar_file])\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(\"Remove tar file failed with error:\", e.output)\n",
    "            return\n",
    "    else:\n",
    "        print(\"Directory\", output_dir, \"already exists, skipping download\")\n",
    "\n",
    "    \n",
    "def main():\n",
    "    download_files()\n",
    "    # read in the .jsonl file\n",
    "    with open('../../data/intermediate/openai_prm800k_formatted.jsonl', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    jsonl_data = [json.loads(line) for line in lines]\n",
    "\n",
    "    def process_directory(directory):\n",
    "        # find all .json files in all subdirectories\n",
    "        filepaths = glob.glob(directory + '/**/*.json', recursive=True)\n",
    "        \n",
    "        combined_data = []\n",
    "        for filepath in filepaths:\n",
    "            with open(filepath, 'r') as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "                # Replace 'problem' with 'input' and 'solution' with 'output'\n",
    "                modified_data = {\n",
    "                    'instruction': data['problem'],\n",
    "                    'input': \"\",\n",
    "                    'output': data['solution'],\n",
    "                }\n",
    "\n",
    "                combined_data.append(modified_data)\n",
    "\n",
    "        # save the combined data to a .json file\n",
    "        dir_name = directory.split('/')[-1]\n",
    "        with open(f'MATH_{dir_name}_data.json', 'w') as f:\n",
    "            json.dump(combined_data, f)\n",
    "\n",
    "        return combined_data\n",
    "\n",
    "\n",
    "    # create single json files for train and test data\n",
    "    train_data = process_directory('MATH/train')\n",
    "    test_data = process_directory('MATH/test')\n",
    "\n",
    "    # add train data and test data together to get all data\n",
    "    train_data = train_data + test_data\n",
    "    \n",
    "    # train_data_locations = [data['instruction'] for data in train_data]\n",
    "\n",
    "    # Put the train and test data together\n",
    "    train_data_locations = [data['instruction'] for data in train_data]\n",
    "    test_data_locations = [data['instruction'] for data in test_data]\n",
    "\n",
    "    train_data_locations.extend(test_data_locations)\n",
    "\n",
    "    count = 0\n",
    "    # replace with the enhanced solutions\n",
    "    for data in jsonl_data:\n",
    "        if data['Input'] in train_data_locations:\n",
    "            index = train_data_locations.index(data['Input'])\n",
    "\n",
    "            answer = data['Output'].split('# Answer\\n\\n')[1]\n",
    "            modified_content = {\n",
    "                'instruction': data['Input'],\n",
    "                'input': \"\",\n",
    "                # 'output': re.sub(r'# Answer\\n\\n.*', r'\\\\boxed{' + re.escape(answer) + '}', data['Output']),\n",
    "                'output': re.sub(r'# Answer\\n\\n.*','', data['Output']),\n",
    "                # 'gt': answer\n",
    "            }\n",
    "            train_data[index] = modified_content\n",
    "            count += 1\n",
    "\n",
    "    # For every problem in the train_data, if the ouput has a boxed answer, remove the box update to keep the answer\n",
    "    for data in train_data:\n",
    "        if re.search(r'\\\\boxed{(.*)\\}', data['output']):\n",
    "            data['output'] = re.sub(r'\\\\boxed\\{(.*)\\}', r'\\1', data['output'])\n",
    "\n",
    "    #remove the math folder\n",
    "    os.remove('MATH_test_data.json')\n",
    "    os.remove('MATH_train_data.json')\n",
    "    subprocess.check_output([\"rm\", \"-rf\", \"MATH\"])\n",
    "    \n",
    "    return train_data\n",
    "\n",
    "data = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(processed_path / 'MATH_train_enhanced_no_boxed.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "r06prT7dwvmL"
   },
   "source": [
    "### LIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"GAIR/lima\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same formatting as guanaco\n",
    "\n",
    "def process_lima_record(x):\n",
    "    instruction = x[\"conversations\"][0]\n",
    "    response = x[\"conversations\"][1:]\n",
    "    response_out = response[0]\n",
    "    for i, r in enumerate(response):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        if i % 2 == 1: # human\n",
    "            response_out += \"### Instruction:\\n \" + r\n",
    "        else: # bot\n",
    "            response_out += \"### Response:\\n \" + r\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": \"\",\n",
    "        \"output\": response_out\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = df.apply(process_lima_record, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.to_json(processed_path / \"lima.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flan\n",
    "\n",
    "https://github.com/google-research/FLAN/tree/main/flan/v2\n",
    "\n",
    "> NB #1: These scripts download and process dozens of GBs of data, which is usually not feasible in a single run. We recommend starting with submixtures like cot_submix, flan2021_submix, dialog_submix, t0_submix and niv2_submix, as shown in flan/v2/run_example.py. If you plan to use Seqio/T5X for training then we recommend caching the datasets, following these instructions. If not, you can use the above script to collect the data as raw text/json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "flan_datasets = [\n",
    "    \"conceptofmind/cot_submix_original\",\n",
    "    \"conceptofmind/flan2021_submix_original\",\n",
    "    \"conceptofmind/dialog_submix_original\",\n",
    "    \"conceptofmind/t0_submix_original\",\n",
    "    # \"conceptofmind/niv2_submix_original\",\n",
    "]\n",
    "\n",
    "def download_flan_submix(flan_dataset):\n",
    "    ds_flan = load_dataset(flan_dataset)\n",
    "\n",
    "    df_flan = (\n",
    "        ds_flan[\"train\"]\n",
    "        .to_pandas()\n",
    "        [['inputs','targets']]\n",
    "        .rename(columns={\"inputs\": \"context\", \"target\": \"output\"})\n",
    "        .assign(input=\"\")\n",
    "    )\n",
    "\n",
    "    return df_flan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = download_flan_submix(\"conceptofmind/cot_submix_original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0].targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_flan.to_json(processed_path / f\"{flan_dataset.replace('/','-')}.jsonl\",\n",
    "        orient=\"records\",\n",
    "        lines=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
