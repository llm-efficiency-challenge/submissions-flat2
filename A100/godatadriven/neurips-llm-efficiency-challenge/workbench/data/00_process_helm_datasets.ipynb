{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib as plb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helm_dir = plb.Path('/Users/user/Documents/CodeProjects/neurips-llm-efficiency-challenge-2023/neurips-llm-efficiency-challenge/data/raw/helm_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = [i for i in helm_dir.glob(\"*.jsonl\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = []\n",
    "\n",
    "for fl in f:\n",
    "    print(fl)\n",
    "    cols = ['task', 'references', 'correct', 'method', 'instruction', 'prefix', 'output_prefix', 'dataset', 'subject']\n",
    "    df = pd.read_json(fl, lines=True)\n",
    "    if 'correct' not in df.columns:\n",
    "        df['correct'] = None\n",
    "    if 'subject' not in df.columns:\n",
    "        df['subject'] = None\n",
    "    df = df#.loc[:, cols]\n",
    "    if fl.name.split(\".\")[0] == \"summarization_cdnn\":\n",
    "        nmax = 3000\n",
    "    else:\n",
    "        nmax = 20_000\n",
    "    n = min([df.shape[0], nmax])\n",
    "    df = df.sample(n=n, random_state=786949692)\n",
    "    dfl.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from cajajejo.commands.api.utils import MAP\n",
    "\n",
    "def fmt_output_mc(x):\n",
    "    return MAP[x[\"correct\"]]\n",
    "\n",
    "def fmt_q(x):\n",
    "    if x['method'] == 'multiple_choice_joint':\n",
    "        references = '\\n'.join([f\"{MAP[i]}. {r.strip()}\" for i, r in enumerate(x['references'].split(';'))])\n",
    "        prompt = f\"\"\"{x['prefix']}{x['task']}\\n{references}\\n{x['output_prefix'].strip()} {fmt_output_mc(x)}\"\"\".strip()\n",
    "    else:\n",
    "        references = x['references']\n",
    "        prompt = f\"\"\"{x['prefix']}{x['task']}\\n{x['output_prefix']}{references}\"\"\".strip()\n",
    "    return prompt\n",
    "\n",
    "def n_shot_examples(df, random_state: int, n_examples: int = 2, n_shot_postfix = \"\\n\\n\"):\n",
    "    n_examples_req_per_sample = n_examples + 1\n",
    "    d_n = df.shape[0]\n",
    "    ns_s = d_n // n_examples_req_per_sample\n",
    "    if d_n - ns_s < 0:\n",
    "        raise ValueError(\"Not enough samples\")\n",
    "    print(f\"Total input samples: {d_n}\")\n",
    "    print(f\"Examples required per N-shot sample: {n_examples_req_per_sample}\")\n",
    "    print(f\"N-shot samples: {ns_s}\")\n",
    "    dshuf = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    dshuf[\"instruction_fmt\"] = dshuf.apply(fmt_q, axis=1)\n",
    "    instruction = dshuf[\"instruction\"].iloc[0]\n",
    "    samples_ns = np.array_split(dshuf, ns_s)\n",
    "    n_shot_questions = []\n",
    "    n_shot_answers = []\n",
    "    for s in samples_ns:\n",
    "        if s.shape[0] < n_examples_req_per_sample:\n",
    "            continue\n",
    "        sl = s.iloc[-1]\n",
    "        len_answer = len(MAP[sl['correct']]) if sl['method'] == 'multiple_choice_joint' else len(sl['references'])\n",
    "        comb = (instruction + \"\\n\" + f\"{n_shot_postfix}\".join(s[\"instruction_fmt\"])).strip()\n",
    "        nsh_q = comb[:(len(comb) - len_answer)].strip()\n",
    "        nsh_a = comb[-len_answer:].strip()\n",
    "        n_shot_questions.append(nsh_q)\n",
    "        n_shot_answers.append(nsh_a)\n",
    "    dfr = pd.DataFrame(\n",
    "        {\n",
    "            \"question\": n_shot_questions,\n",
    "            \"answer\": n_shot_answers,\n",
    "            \"method\": sl['method'],\n",
    "        }\n",
    "    )\n",
    "    return dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dm = dfl[4].copy().sample(frac=1, random_state=1232312).reset_index(drop=True)\n",
    "cnn_dm[\"output_prefix\"] = \"\\n\" + cnn_dm[\"output_prefix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot = n_shot_examples(cnn_dm.loc[:750], random_state=8623, n_examples=0).assign(dataset=\"cnn_dm\")\n",
    "three_shot = n_shot_examples(cnn_dm.loc[750:1500], random_state=78362, n_examples=3).assign(dataset=\"cnn_dm\")\n",
    "five_shot = n_shot_examples(cnn_dm.loc[1500:], random_state=32166, n_examples=5).assign(dataset=\"cnn_dm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dm = pd.concat([zero_shot, three_shot, five_shot]).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BBQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbq = dfl[1].copy().sample(frac=1, random_state=1232312).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot = n_shot_examples(bbq.loc[:2000], random_state=8623, n_examples=0).assign(dataset=\"bbq\")\n",
    "three_shot = n_shot_examples(bbq.loc[2000:6000], random_state=78362, n_examples=3).assign(dataset=\"bbq\")\n",
    "five_shot = n_shot_examples(bbq.loc[6000:16000], random_state=32166, n_examples=5).assign(dataset=\"bbq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbq = pd.concat([zero_shot, three_shot, five_shot]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbq"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TruthfulQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqa = dfl[2].copy().sample(frac=1, random_state=1232312).reset_index(drop=True)\n",
    "\n",
    "tqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot = n_shot_examples(tqa.loc[(14*6):], random_state=8623, n_examples=0).assign(dataset=\"truthful_qa\")\n",
    "five_shot = n_shot_examples(tqa.loc[0:(14*6)-1], random_state=32166, n_examples=5).assign(dataset=\"truthful_qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(five_shot.iloc[0].question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqa = pd.concat([zero_shot, five_shot]).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm = dfl[5].copy().sample(frac=1, random_state=1232312).reset_index(drop=True)\n",
    "\n",
    "gsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot = n_shot_examples(gsm.loc[:1000], random_state=8623, n_examples=0).assign(dataset=\"gsm\")\n",
    "three_shot = n_shot_examples(gsm.loc[1001:3500], random_state=32166, n_examples=3).assign(dataset=\"gsm\")\n",
    "five_shot = n_shot_examples(gsm.loc[3501:], random_state=89643, n_examples=5).assign(dataset=\"gsm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(five_shot.iloc[0].question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm = pd.concat([zero_shot, three_shot, five_shot]).reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmlu = dfl[3].copy().reset_index(drop=True)\n",
    "\n",
    "subjects = mmlu.subject.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mmlu = []\n",
    "\n",
    "for subject in subjects:\n",
    "    mmlus = mmlu.loc[mmlu.subject == subject].sample(frac=1, random_state=1232312).reset_index(drop=True)\n",
    "    zero_shot = n_shot_examples(mmlus.loc[3:], random_state=8623, n_examples=0).assign(dataset=\"mmlu\")\n",
    "    two_shot = n_shot_examples(mmlus.loc[:2], random_state=32166, n_examples=2).assign(dataset=\"mmlu\")\n",
    "    mmlus = pd.concat([zero_shot, two_shot]).reset_index(drop=True)\n",
    "    all_mmlu.append(mmlus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mmlu = pd.concat(all_mmlu).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_mmlu.iloc[0].question)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BigBench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigb = dfl[0].copy().reset_index(drop=True)\n",
    "\n",
    "task_names = bigb.task_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_bb = []\n",
    "\n",
    "frac_zs = .3\n",
    "frac_ns = 1 - frac_zs\n",
    "\n",
    "for taskn in task_names:\n",
    "    bigbs = bigb.loc[bigb.task_name == taskn].reset_index(drop=True)\n",
    "    subtasks = bigbs.subtask_name.unique().tolist()\n",
    "    if len(subtasks) > 1:\n",
    "        for subtask in subtasks:\n",
    "            bigbss = bigbs.loc[bigbs.subtask_name == subtask].reset_index(drop=True)\n",
    "            if bigbss.shape[0] < 30:\n",
    "                samples = n_shot_examples(bigbss, random_state=8623, n_examples=0).assign(dataset=\"big_bench\")\n",
    "            else:\n",
    "                zero_shot = n_shot_examples(bigbss.loc[:int(bigbss.shape[0]*frac_zs)], random_state=43423, n_examples=0).assign(dataset=\"big_bench\")\n",
    "                n_shot = n_shot_examples(bigbss.loc[int(int(bigbss.shape[0]*frac_ns)):], random_state=32166, n_examples=3).assign(dataset=\"big_bench\")\n",
    "                samples = pd.concat([zero_shot, n_shot]).reset_index(drop=True)\n",
    "    else:\n",
    "        if bigbs.shape[0] < 30:\n",
    "            samples = n_shot_examples(bigbs, random_state=8623, n_examples=0).assign(dataset=\"big_bench\")\n",
    "        else:\n",
    "            zero_shot = n_shot_examples(bigbs.loc[:int(bigbs.shape[0]*frac_zs)], random_state=43423, n_examples=0).assign(dataset=\"big_bench\")\n",
    "            n_shot = n_shot_examples(bigbs.loc[int(int(bigbs.shape[0]*frac_ns)):], random_state=32166, n_examples=3).assign(dataset=\"big_bench\")\n",
    "            samples = pd.concat([zero_shot, n_shot]).reset_index(drop=True)\n",
    "    samples_bb.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigb = pd.concat(samples_bb).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigb.loc[5000].question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pd.concat([cnn_dm, bbq, tqa, gsm, all_mmlu, bigb]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf['input'] = (\n",
    "    ddf\n",
    "    .apply(lambda x: \"Choose the best option out of the choices given, and return the letter corresponding to the option you choose.\" if x[\"method\"] != 'generation' else '', axis=1)\n",
    ")\n",
    "\n",
    "ddf = ddf.rename({\n",
    "    'question': 'instruction',\n",
    "    'answer': 'output'\n",
    "}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf.to_json(\"../../data/processed/helm_training_data.jsonl\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
