{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sentence-transformers\n",
    "#!pip install umap-learn\n",
    "#!pip install cluestar\n",
    "#!pip install openai\n",
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from os import environ\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "\n",
    "DEPLOYMENT_NAME = \"gpt-35-turbo\"\n",
    "chat_llm = AzureChatOpenAI(\n",
    "    # openai_api_base=BASE_URL,\n",
    "    # openai_api_version=\"2023-05-15\",\n",
    "    deployment_name=DEPLOYMENT_NAME,\n",
    "    # openai_api_key=API_KEY,\n",
    "    # openai_api_type=\"azure\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(content):\n",
    "    return chat_llm(\n",
    "        [\n",
    "            HumanMessage(\n",
    "                content=content\n",
    "            )\n",
    "        ]\n",
    "    ).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query(\"do you read me?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"mps\"\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"../../data/processed/guanaco.jsonl\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['instruction_input'] = df['instruction'] + \"\\n\\n\" + df['input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_embeddings = model.encode(df['instruction_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "\n",
    "x = UMAP(n_neighbors=10, n_components=1).fit_transform(instruction_embeddings)\n",
    "X = UMAP().fit_transform(instruction_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['x'] = x\n",
    "df = df.sort_values(by='x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt = \"\"\"\n",
    "\n",
    "You are a data curator.\n",
    "Your knowledge cutoff is end of december 2022.\n",
    "You have no knowledge of current or future events, that includes the weather and the current time.\n",
    "You are not human, you have no feelings. You have no personal preferences.\n",
    "\n",
    "You have two goals:\n",
    "1. Remove duplicate content\n",
    "2. Remove questions that are not aligned with the objective of training a model that is great at answering multiple choice or logic reasoning questions.\n",
    "\n",
    "You will receive a set of json formatted questions.\n",
    "Your task is to return for each if it should be:\n",
    "A. Kept\n",
    "B. Removed\n",
    "\n",
    "Provide your answer in the following FORMAT\n",
    "\n",
    "FORMAT:\n",
    "```json\n",
    "{\n",
    "  < identifier >: {\n",
    "    'decision': < \"KEEP\" or \"REMOVE\" >\n",
    "    'reason': < \"SIMILARITY\" or \"BAD QUESTION\" \"GOOD QUESTION\" >\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "QUESTIONS:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output = []\n",
    "for i in range(0,len(df),15):\n",
    "    subset = df.iloc[i:i+15]\n",
    "    prompt = base_prompt + json.dumps(subset.to_dict())\n",
    "    out = query(prompt)\n",
    "    output.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cluestar import plot_text\n",
    "\n",
    "plot_text(X, df['instruction_input'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
