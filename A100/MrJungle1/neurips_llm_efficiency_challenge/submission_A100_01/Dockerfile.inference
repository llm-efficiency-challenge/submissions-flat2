FROM nvcr.io/nvidia/cuda:11.8.0-devel-ubuntu22.04

RUN apt-get update  && apt-get install -y git python3-virtualenv wget 

WORKDIR /workspace

RUN pip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
RUN pip3 install -U --no-cache-dir git+https://github.com/facebookresearch/llama-recipes.git@eafea7b366bde9dc3f0b66a4cb0a8788f560c793

# Setup server requriements
COPY ./fast_api_requirements.txt .
RUN pip3 install --no-cache-dir --upgrade -r fast_api_requirements.txt

ENV HUGGINGFACE_TOKEN="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"
ENV HUGGINGFACE_REPO="jiangchensiat/llama2-exl2-4.0bpw"

# Copy over single file server
COPY ./main.py .
COPY ./api.py .

COPY ./down_load_inference.py .
RUN pip3 install --no-cache-dir exllamav2

# Download the model
RUN python3 down_load_inference.py

# Run the server
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "80"]
