2023-10-20 03:39:46.646845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Starting time is:  2023-10-20 16:09:47 IST+0530
RANDOM STRING is:  b9adab12-c9f6-4939-8894-47d1cd68ffc3
REPO DECIDED is:  anmolagarwal999/nips_challenge_b9adab12-c9f6-4939-8894-47d1cd68ffc3
Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.
Token is valid (permission: write).
Your token has been saved to /home/anmol/.cache/huggingface/token
Login successful
Total gradient accumulation steps are:  4
OUTPUT dir is:  ./models_saved/32_32_b9adab12-c9f6-4939-8894-47d1cd68ffc3
KWARGS sent to main() are:  {'model_name': 'meta-llama/Llama-2-7b-hf', 'use_peft': True, 'peft_method': 'lora', 'quantization': True, 'batch_size_training': 8, 'gradient_accumulation_steps': 4, 'dataset': 'custom_dataset', 'custom_dataset.file': './train.py:get_anmol_dataset', 'output_dir': './models_saved/32_32_b9adab12-c9f6-4939-8894-47d1cd68ffc3'}
Inside update config file
Inside update config file
Inside update config file
Anmol: The final config after all the updations is:  <class 'llama_recipes.configs.training.train_config'>
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.45s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.05it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.03s/it]
/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/peft/utils/other.py:133: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
--> Model meta-llama/Llama-2-7b-hf

--> meta-llama/Llama-2-7b-hf has 262.41024 Million params

Inside update config file
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
Inside update config file
Dataset config is:  custom_dataset(dataset='custom_dataset', file='./train.py:get_anmol_dataset', train_split='train', test_split='validation')
Starting time is:  2023-10-20 16:09:58 IST+0530
RANDOM STRING is:  41d73aaa-e1bc-4479-8940-5dc6a6c5cbdf
REPO DECIDED is:  anmolagarwal999/nips_challenge_41d73aaa-e1bc-4479-8940-5dc6a6c5cbdf
Ending time is:  2023-10-20 16:09:58 IST+0530
INSIDE INIT FUNCTION
--> Training Set Length = 6847
Starting time is:  2023-10-20 16:09:58 IST+0530
RANDOM STRING is:  143bdfdf-4700-42d6-92d0-a61638af8d61
REPO DECIDED is:  anmolagarwal999/nips_challenge_143bdfdf-4700-42d6-92d0-a61638af8d61
Ending time is:  2023-10-20 16:09:58 IST+0530
INSIDE INIT FUNCTION
--> Validation Set Length = 500
Training config is:  <class 'llama_recipes.configs.training.train_config'>
Training Epoch: 1:   0%|[34m          [0m| 0/213 [00:00<?, ?it/s]/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
Training Epoch: 1/10, step 0/855 completed (loss: 1.5289456844329834):   0%|[34m          [0m| 0/213 [00:14<?, ?it/s]Training Epoch: 1/10, step 1/855 completed (loss: 1.4507848024368286):   0%|[34m          [0m| 0/213 [00:26<?, ?it/s]Training Epoch: 1/10, step 2/855 completed (loss: 1.4353517293930054):   0%|[34m          [0m| 0/213 [00:38<?, ?it/s]Training Epoch: 1/10, step 2/855 completed (loss: 1.4353517293930054):   0%|[34m          [0m| 1/213 [00:50<2:59:12, 50.72s/it]Training Epoch: 1/10, step 3/855 completed (loss: 1.5055489540100098):   0%|[34m          [0m| 1/213 [00:50<2:59:12, 50.72s/it]Training Epoch: 1/10, step 4/855 completed (loss: 1.3007583618164062):   0%|[34m          [0m| 1/213 [01:03<2:59:12, 50.72s/it]Training Epoch: 1/10, step 5/855 completed (loss: 1.3175618648529053):   0%|[34m          [0m| 1/213 [01:15<2:59:12, 50.72s/it]Training Epoch: 1/10, step 6/855 completed (loss: 1.2570345401763916):   0%|[34m          [0m| 1/213 [01:27<2:59:12, 50.72s/it]Training Epoch: 1/10, step 6/855 completed (loss: 1.2570345401763916):   1%|[34m          [0m| 2/213 [01:39<2:55:06, 49.79s/it]Training Epoch: 1/10, step 7/855 completed (loss: 1.3013169765472412):   1%|[34m          [0m| 2/213 [01:40<2:55:06, 49.79s/it]Training Epoch: 1/10, step 8/855 completed (loss: 1.1426448822021484):   1%|[34m          [0m| 2/213 [01:52<2:55:06, 49.79s/it]Training Epoch: 1/10, step 9/855 completed (loss: 1.1942697763442993):   1%|[34m          [0m| 2/213 [02:04<2:55:06, 49.79s/it]Training Epoch: 1/10, step 10/855 completed (loss: 1.1790354251861572):   1%|[34m          [0m| 2/213 [02:16<2:55:06, 49.79s/it]Training Epoch: 1/10, step 10/855 completed (loss: 1.1790354251861572):   1%|[34mâ–         [0m| 3/213 [02:29<2:53:27, 49.56s/it]Training Epoch: 1/10, step 11/855 completed (loss: 1.155247688293457):   1%|[34mâ–         [0m| 3/213 [02:29<2:53:27, 49.56s/it] Training Epoch: 1/10, step 12/855 completed (loss: 0.9497134685516357):   1%|[34mâ–         [0m| 3/213 [02:41<2:53:27, 49.56s/it]Training Epoch: 1/10, step 13/855 completed (loss: 0.9382994174957275):   1%|[34mâ–         [0m| 3/213 [02:54<2:53:27, 49.56s/it]Training Epoch: 1/10, step 14/855 completed (loss: 0.9242885708808899):   1%|[34mâ–         [0m| 3/213 [03:06<2:53:27, 49.56s/it]Training Epoch: 1/10, step 14/855 completed (loss: 0.9242885708808899):   2%|[34mâ–         [0m| 4/213 [03:18<2:52:21, 49.48s/it]Training Epoch: 1/10, step 15/855 completed (loss: 0.9723286628723145):   2%|[34mâ–         [0m| 4/213 [03:18<2:52:21, 49.48s/it]Training Epoch: 1/10, step 16/855 completed (loss: 0.7661688923835754):   2%|[34mâ–         [0m| 4/213 [03:31<2:52:21, 49.48s/it]Training Epoch: 1/10, step 17/855 completed (loss: 0.7933817505836487):   2%|[34mâ–         [0m| 4/213 [03:43<2:52:21, 49.48s/it]Training Epoch: 1/10, step 18/855 completed (loss: 0.7566065788269043):   2%|[34mâ–         [0m| 4/213 [03:55<2:52:21, 49.48s/it]Training Epoch: 1/10, step 18/855 completed (loss: 0.7566065788269043):   2%|[34mâ–         [0m| 5/213 [04:07<2:51:21, 49.43s/it]Training Epoch: 1/10, step 19/855 completed (loss: 0.7500697374343872):   2%|[34mâ–         [0m| 5/213 [04:08<2:51:21, 49.43s/it]Training Epoch: 1/10, step 20/855 completed (loss: 0.5903610587120056):   2%|[34mâ–         [0m| 5/213 [04:20<2:51:21, 49.43s/it]Training Epoch: 1/10, step 21/855 completed (loss: 0.6519999504089355):   2%|[34mâ–         [0m| 5/213 [04:32<2:51:21, 49.43s/it]Training Epoch: 1/10, step 22/855 completed (loss: 0.6144663095474243):   2%|[34mâ–         [0m| 5/213 [04:45<2:51:21, 49.43s/it]Training Epoch: 1/10, step 22/855 completed (loss: 0.6144663095474243):   3%|[34mâ–Ž         [0m| 6/213 [04:57<2:50:24, 49.39s/it]Training Epoch: 1/10, step 23/855 completed (loss: 0.5815032720565796):   3%|[34mâ–Ž         [0m| 6/213 [04:57<2:50:24, 49.39s/it]Training Epoch: 1/10, step 24/855 completed (loss: 0.4460739493370056):   3%|[34mâ–Ž         [0m| 6/213 [05:09<2:50:24, 49.39s/it]Training Epoch: 1/10, step 25/855 completed (loss: 0.4769151210784912):   3%|[34mâ–Ž         [0m| 6/213 [05:21<2:50:24, 49.39s/it]Training Epoch: 1/10, step 26/855 completed (loss: 0.4790128469467163):   3%|[34mâ–Ž         [0m| 6/213 [05:34<2:50:24, 49.39s/it]Training Epoch: 1/10, step 26/855 completed (loss: 0.4790128469467163):   3%|[34mâ–Ž         [0m| 7/213 [05:46<2:49:26, 49.35s/it]Training Epoch: 1/10, step 27/855 completed (loss: 0.4921077489852905):   3%|[34mâ–Ž         [0m| 7/213 [05:46<2:49:26, 49.35s/it]Training Epoch: 1/10, step 28/855 completed (loss: 0.3664141893386841):   3%|[34mâ–Ž         [0m| 7/213 [05:58<2:49:26, 49.35s/it]Training Epoch: 1/10, step 29/855 completed (loss: 0.33003804087638855):   3%|[34mâ–Ž         [0m| 7/213 [06:11<2:49:26, 49.35s/it]Training Epoch: 1/10, step 30/855 completed (loss: 0.3219442367553711):   3%|[34mâ–Ž         [0m| 7/213 [06:23<2:49:26, 49.35s/it] Training Epoch: 1/10, step 30/855 completed (loss: 0.3219442367553711):   4%|[34mâ–         [0m| 8/213 [06:35<2:48:33, 49.33s/it]Training Epoch: 1/10, step 31/855 completed (loss: 0.33426037430763245):   4%|[34mâ–         [0m| 8/213 [06:35<2:48:33, 49.33s/it]Training Epoch: 1/10, step 32/855 completed (loss: 0.23372627794742584):   4%|[34mâ–         [0m| 8/213 [06:48<2:48:33, 49.33s/it]Training Epoch: 1/10, step 33/855 completed (loss: 0.24332308769226074):   4%|[34mâ–         [0m| 8/213 [07:00<2:48:33, 49.33s/it]Training Epoch: 1/10, step 34/855 completed (loss: 0.24896210432052612):   4%|[34mâ–         [0m| 8/213 [07:12<2:48:33, 49.33s/it]Training Epoch: 1/10, step 34/855 completed (loss: 0.24896210432052612):   4%|[34mâ–         [0m| 9/213 [07:25<2:47:42, 49.33s/it]Training Epoch: 1/10, step 35/855 completed (loss: 0.22051191329956055):   4%|[34mâ–         [0m| 9/213 [07:25<2:47:42, 49.33s/it]Training Epoch: 1/10, step 36/855 completed (loss: 0.1864863783121109):   4%|[34mâ–         [0m| 9/213 [07:37<2:47:42, 49.33s/it] Training Epoch: 1/10, step 37/855 completed (loss: 0.18521463871002197):   4%|[34mâ–         [0m| 9/213 [07:49<2:47:42, 49.33s/it]Training Epoch: 1/10, step 38/855 completed (loss: 0.20175708830356598):   4%|[34mâ–         [0m| 9/213 [08:02<2:47:42, 49.33s/it]Training Epoch: 1/10, step 38/855 completed (loss: 0.20175708830356598):   5%|[34mâ–         [0m| 10/213 [08:14<2:46:53, 49.33s/it]Training Epoch: 1/10, step 39/855 completed (loss: 0.17934206128120422):   5%|[34mâ–         [0m| 10/213 [08:14<2:46:53, 49.33s/it]Training Epoch: 1/10, step 40/855 completed (loss: 0.15761692821979523):   5%|[34mâ–         [0m| 10/213 [08:26<2:46:53, 49.33s/it]Training Epoch: 1/10, step 41/855 completed (loss: 0.19583135843276978):   5%|[34mâ–         [0m| 10/213 [08:39<2:46:53, 49.33s/it]Training Epoch: 1/10, step 42/855 completed (loss: 0.16505217552185059):   5%|[34mâ–         [0m| 10/213 [08:51<2:46:53, 49.33s/it]Training Epoch: 1/10, step 42/855 completed (loss: 0.16505217552185059):   5%|[34mâ–Œ         [0m| 11/213 [09:03<2:46:05, 49.33s/it]Training Epoch: 1/10, step 43/855 completed (loss: 0.17049658298492432):   5%|[34mâ–Œ         [0m| 11/213 [09:03<2:46:05, 49.33s/it]Training Epoch: 1/10, step 44/855 completed (loss: 0.1687196046113968):   5%|[34mâ–Œ         [0m| 11/213 [09:16<2:46:05, 49.33s/it] Training Epoch: 1/10, step 45/855 completed (loss: 0.16863179206848145):   5%|[34mâ–Œ         [0m| 11/213 [09:28<2:46:05, 49.33s/it]Training Epoch: 1/10, step 46/855 completed (loss: 0.16257226467132568):   5%|[34mâ–Œ         [0m| 11/213 [09:40<2:46:05, 49.33s/it]Training Epoch: 1/10, step 46/855 completed (loss: 0.16257226467132568):   6%|[34mâ–Œ         [0m| 12/213 [09:53<2:45:17, 49.34s/it]Training Epoch: 1/10, step 47/855 completed (loss: 0.17048253118991852):   6%|[34mâ–Œ         [0m| 12/213 [09:53<2:45:17, 49.34s/it]Training Epoch: 1/10, step 48/855 completed (loss: 0.16185875236988068):   6%|[34mâ–Œ         [0m| 12/213 [10:05<2:45:17, 49.34s/it]Training Epoch: 1/10, step 49/855 completed (loss: 0.13528084754943848):   6%|[34mâ–Œ         [0m| 12/213 [10:17<2:45:17, 49.34s/it]Training Epoch: 1/10, step 50/855 completed (loss: 0.14836332201957703):   6%|[34mâ–Œ         [0m| 12/213 [10:30<2:45:17, 49.34s/it]Training Epoch: 1/10, step 50/855 completed (loss: 0.14836332201957703):   6%|[34mâ–Œ         [0m| 13/213 [10:42<2:44:29, 49.35s/it]Training Epoch: 1/10, step 51/855 completed (loss: 0.13507047295570374):   6%|[34mâ–Œ         [0m| 13/213 [10:42<2:44:29, 49.35s/it]Training Epoch: 1/10, step 52/855 completed (loss: 0.15662264823913574):   6%|[34mâ–Œ         [0m| 13/213 [10:54<2:44:29, 49.35s/it]Training Epoch: 1/10, step 53/855 completed (loss: 0.16178488731384277):   6%|[34mâ–Œ         [0m| 13/213 [11:07<2:44:29, 49.35s/it]Training Epoch: 1/10, step 54/855 completed (loss: 0.166952982544899):   6%|[34mâ–Œ         [0m| 13/213 [11:19<2:44:29, 49.35s/it]  Training Epoch: 1/10, step 54/855 completed (loss: 0.166952982544899):   7%|[34mâ–‹         [0m| 14/213 [11:31<2:43:40, 49.35s/it]Training Epoch: 1/10, step 55/855 completed (loss: 0.16558219492435455):   7%|[34mâ–‹         [0m| 14/213 [11:31<2:43:40, 49.35s/it]Training Epoch: 1/10, step 56/855 completed (loss: 0.15813733637332916):   7%|[34mâ–‹         [0m| 14/213 [11:44<2:43:40, 49.35s/it]Training Epoch: 1/10, step 57/855 completed (loss: 0.16149713099002838):   7%|[34mâ–‹         [0m| 14/213 [11:56<2:43:40, 49.35s/it]Training Epoch: 1/10, step 58/855 completed (loss: 0.14807654917240143):   7%|[34mâ–‹         [0m| 14/213 [12:08<2:43:40, 49.35s/it]Training Epoch: 1/10, step 58/855 completed (loss: 0.14807654917240143):   7%|[34mâ–‹         [0m| 15/213 [12:21<2:42:51, 49.35s/it]Training Epoch: 1/10, step 59/855 completed (loss: 0.1673034429550171):   7%|[34mâ–‹         [0m| 15/213 [12:21<2:42:51, 49.35s/it] Training Epoch: 1/10, step 60/855 completed (loss: 0.14536461234092712):   7%|[34mâ–‹         [0m| 15/213 [12:33<2:42:51, 49.35s/it]Training Epoch: 1/10, step 61/855 completed (loss: 0.13035455346107483):   7%|[34mâ–‹         [0m| 15/213 [12:46<2:42:51, 49.35s/it]Training Epoch: 1/10, step 62/855 completed (loss: 0.15085271000862122):   7%|[34mâ–‹         [0m| 15/213 [12:58<2:42:51, 49.35s/it]Training Epoch: 1/10, step 62/855 completed (loss: 0.15085271000862122):   8%|[34mâ–Š         [0m| 16/213 [13:10<2:42:01, 49.35s/it]Training Epoch: 1/10, step 63/855 completed (loss: 0.14172761142253876):   8%|[34mâ–Š         [0m| 16/213 [13:10<2:42:01, 49.35s/it]Training Epoch: 1/10, step 64/855 completed (loss: 0.13421018421649933):   8%|[34mâ–Š         [0m| 16/213 [13:23<2:42:01, 49.35s/it]Training Epoch: 1/10, step 65/855 completed (loss: 0.14534379541873932):   8%|[34mâ–Š         [0m| 16/213 [13:35<2:42:01, 49.35s/it]Training Epoch: 1/10, step 66/855 completed (loss: 0.13687017560005188):   8%|[34mâ–Š         [0m| 16/213 [13:47<2:42:01, 49.35s/it]Training Epoch: 1/10, step 66/855 completed (loss: 0.13687017560005188):   8%|[34mâ–Š         [0m| 17/213 [13:59<2:41:12, 49.35s/it]Training Epoch: 1/10, step 67/855 completed (loss: 0.139996737241745):   8%|[34mâ–Š         [0m| 17/213 [14:00<2:41:12, 49.35s/it]  Training Epoch: 1/10, step 68/855 completed (loss: 0.13241004943847656):   8%|[34mâ–Š         [0m| 17/213 [14:12<2:41:12, 49.35s/it]Training Epoch: 1/10, step 69/855 completed (loss: 0.1325056403875351):   8%|[34mâ–Š         [0m| 17/213 [14:24<2:41:12, 49.35s/it] Training Epoch: 1/10, step 70/855 completed (loss: 0.1544804573059082):   8%|[34mâ–Š         [0m| 17/213 [14:37<2:41:12, 49.35s/it]Training Epoch: 1/10, step 70/855 completed (loss: 0.1544804573059082):   8%|[34mâ–Š         [0m| 18/213 [14:49<2:40:22, 49.35s/it]Training Epoch: 1/10, step 71/855 completed (loss: 0.14674273133277893):   8%|[34mâ–Š         [0m| 18/213 [14:49<2:40:22, 49.35s/it]Training Epoch: 1/10, step 72/855 completed (loss: 0.1595211923122406):   8%|[34mâ–Š         [0m| 18/213 [15:01<2:40:22, 49.35s/it] Training Epoch: 1/10, step 73/855 completed (loss: 0.13455438613891602):   8%|[34mâ–Š         [0m| 18/213 [15:14<2:40:22, 49.35s/it]Training Epoch: 1/10, step 74/855 completed (loss: 0.13366031646728516):   8%|[34mâ–Š         [0m| 18/213 [15:26<2:40:22, 49.35s/it]Training Epoch: 1/10, step 74/855 completed (loss: 0.13366031646728516):   9%|[34mâ–‰         [0m| 19/213 [15:38<2:39:33, 49.35s/it]Training Epoch: 1/10, step 75/855 completed (loss: 0.15068842470645905):   9%|[34mâ–‰         [0m| 19/213 [15:38<2:39:33, 49.35s/it]Training Epoch: 1/10, step 76/855 completed (loss: 0.14330415427684784):   9%|[34mâ–‰         [0m| 19/213 [15:51<2:39:33, 49.35s/it]Training Epoch: 1/10, step 77/855 completed (loss: 0.16130508482456207):   9%|[34mâ–‰         [0m| 19/213 [16:03<2:39:33, 49.35s/it]Training Epoch: 1/10, step 78/855 completed (loss: 0.14191974699497223):   9%|[34mâ–‰         [0m| 19/213 [16:15<2:39:33, 49.35s/it]Training Epoch: 1/10, step 78/855 completed (loss: 0.14191974699497223):   9%|[34mâ–‰         [0m| 20/213 [16:27<2:38:42, 49.34s/it]Training Epoch: 1/10, step 79/855 completed (loss: 0.13243328034877777):   9%|[34mâ–‰         [0m| 20/213 [16:28<2:38:42, 49.34s/it]Training Epoch: 1/10, step 80/855 completed (loss: 0.1261911392211914):   9%|[34mâ–‰         [0m| 20/213 [16:40<2:38:42, 49.34s/it] Training Epoch: 1/10, step 81/855 completed (loss: 0.14091791212558746):   9%|[34mâ–‰         [0m| 20/213 [16:52<2:38:42, 49.34s/it]Training Epoch: 1/10, step 82/855 completed (loss: 0.13276374340057373):   9%|[34mâ–‰         [0m| 20/213 [17:05<2:38:42, 49.34s/it]Training Epoch: 1/10, step 82/855 completed (loss: 0.13276374340057373):  10%|[34mâ–‰         [0m| 21/213 [17:17<2:37:53, 49.34s/it]Training Epoch: 1/10, step 83/855 completed (loss: 0.13391703367233276):  10%|[34mâ–‰         [0m| 21/213 [17:17<2:37:53, 49.34s/it]Training Epoch: 1/10, step 84/855 completed (loss: 0.13266848027706146):  10%|[34mâ–‰         [0m| 21/213 [17:29<2:37:53, 49.34s/it]Training Epoch: 1/10, step 85/855 completed (loss: 0.13231995701789856):  10%|[34mâ–‰         [0m| 21/213 [17:42<2:37:53, 49.34s/it]Training Epoch: 1/10, step 86/855 completed (loss: 0.13645745813846588):  10%|[34mâ–‰         [0m| 21/213 [17:54<2:37:53, 49.34s/it]Training Epoch: 1/10, step 86/855 completed (loss: 0.13645745813846588):  10%|[34mâ–ˆ         [0m| 22/213 [18:06<2:37:06, 49.35s/it]Training Epoch: 1/10, step 87/855 completed (loss: 0.13207021355628967):  10%|[34mâ–ˆ         [0m| 22/213 [18:06<2:37:06, 49.35s/it]Training Epoch: 1/10, step 88/855 completed (loss: 0.13593338429927826):  10%|[34mâ–ˆ         [0m| 22/213 [18:19<2:37:06, 49.35s/it]Training Epoch: 1/10, step 89/855 completed (loss: 0.13938526809215546):  10%|[34mâ–ˆ         [0m| 22/213 [18:31<2:37:06, 49.35s/it]Training Epoch: 1/10, step 90/855 completed (loss: 0.13913947343826294):  10%|[34mâ–ˆ         [0m| 22/213 [18:43<2:37:06, 49.35s/it]Training Epoch: 1/10, step 90/855 completed (loss: 0.13913947343826294):  11%|[34mâ–ˆ         [0m| 23/213 [18:55<2:36:16, 49.35s/it]Training Epoch: 1/10, step 91/855 completed (loss: 0.13776949048042297):  11%|[34mâ–ˆ         [0m| 23/213 [18:56<2:36:16, 49.35s/it]Training Epoch: 1/10, step 92/855 completed (loss: 0.13472308218479156):  11%|[34mâ–ˆ         [0m| 23/213 [19:08<2:36:16, 49.35s/it]Training Epoch: 1/10, step 93/855 completed (loss: 0.13479845225811005):  11%|[34mâ–ˆ         [0m| 23/213 [19:20<2:36:16, 49.35s/it]Training Epoch: 1/10, step 94/855 completed (loss: 0.14197029173374176):  11%|[34mâ–ˆ         [0m| 23/213 [19:33<2:36:16, 49.35s/it]Training Epoch: 1/10, step 94/855 completed (loss: 0.14197029173374176):  11%|[34mâ–ˆâ–        [0m| 24/213 [19:45<2:35:28, 49.36s/it]Training Epoch: 1/10, step 95/855 completed (loss: 0.1364266723394394):  11%|[34mâ–ˆâ–        [0m| 24/213 [19:45<2:35:28, 49.36s/it] Training Epoch: 1/10, step 96/855 completed (loss: 0.13247676193714142):  11%|[34mâ–ˆâ–        [0m| 24/213 [19:57<2:35:28, 49.36s/it]Training Epoch: 1/10, step 97/855 completed (loss: 0.13837413489818573):  11%|[34mâ–ˆâ–        [0m| 24/213 [20:10<2:35:28, 49.36s/it]Training Epoch: 1/10, step 98/855 completed (loss: 0.13645285367965698):  11%|[34mâ–ˆâ–        [0m| 24/213 [20:22<2:35:28, 49.36s/it]Training Epoch: 1/10, step 98/855 completed (loss: 0.13645285367965698):  12%|[34mâ–ˆâ–        [0m| 25/213 [20:34<2:34:38, 49.36s/it]Training Epoch: 1/10, step 99/855 completed (loss: 0.12864536046981812):  12%|[34mâ–ˆâ–        [0m| 25/213 [20:34<2:34:38, 49.36s/it]Training Epoch: 1/10, step 100/855 completed (loss: 0.13912491500377655):  12%|[34mâ–ˆâ–        [0m| 25/213 [20:47<2:34:38, 49.36s/it]Training Epoch: 1/10, step 101/855 completed (loss: 0.13624079525470734):  12%|[34mâ–ˆâ–        [0m| 25/213 [20:59<2:34:38, 49.36s/it]Training Epoch: 1/10, step 102/855 completed (loss: 0.1456083208322525):  12%|[34mâ–ˆâ–        [0m| 25/213 [21:11<2:34:38, 49.36s/it] Training Epoch: 1/10, step 102/855 completed (loss: 0.1456083208322525):  12%|[34mâ–ˆâ–        [0m| 26/213 [21:24<2:33:50, 49.36s/it]Training Epoch: 1/10, step 103/855 completed (loss: 0.14182835817337036):  12%|[34mâ–ˆâ–        [0m| 26/213 [21:24<2:33:50, 49.36s/it]Training Epoch: 1/10, step 104/855 completed (loss: 0.13675279915332794):  12%|[34mâ–ˆâ–        [0m| 26/213 [21:36<2:33:50, 49.36s/it]Training Epoch: 1/10, step 105/855 completed (loss: 0.13051947951316833):  12%|[34mâ–ˆâ–        [0m| 26/213 [21:48<2:33:50, 49.36s/it]Training Epoch: 1/10, step 106/855 completed (loss: 0.1446671038866043):  12%|[34mâ–ˆâ–        [0m| 26/213 [22:01<2:33:50, 49.36s/it] Training Epoch: 1/10, step 106/855 completed (loss: 0.1446671038866043):  13%|[34mâ–ˆâ–Ž        [0m| 27/213 [22:13<2:33:02, 49.37s/it]Training Epoch: 1/10, step 107/855 completed (loss: 0.12659123539924622):  13%|[34mâ–ˆâ–Ž        [0m| 27/213 [22:13<2:33:02, 49.37s/it]Training Epoch: 1/10, step 108/855 completed (loss: 0.13162240386009216):  13%|[34mâ–ˆâ–Ž        [0m| 27/213 [22:25<2:33:02, 49.37s/it]Training Epoch: 1/10, step 109/855 completed (loss: 0.12830203771591187):  13%|[34mâ–ˆâ–Ž        [0m| 27/213 [22:38<2:33:02, 49.37s/it]Training Epoch: 1/10, step 110/855 completed (loss: 0.13052575290203094):  13%|[34mâ–ˆâ–Ž        [0m| 27/213 [22:50<2:33:02, 49.37s/it]Training Epoch: 1/10, step 110/855 completed (loss: 0.13052575290203094):  13%|[34mâ–ˆâ–Ž        [0m| 28/213 [23:02<2:32:12, 49.37s/it]Training Epoch: 1/10, step 111/855 completed (loss: 0.13456550240516663):  13%|[34mâ–ˆâ–Ž        [0m| 28/213 [23:02<2:32:12, 49.37s/it]Training Epoch: 1/10, step 112/855 completed (loss: 0.13792409002780914):  13%|[34mâ–ˆâ–Ž        [0m| 28/213 [23:15<2:32:12, 49.37s/it]Training Epoch: 1/10, step 113/855 completed (loss: 0.1381843239068985):  13%|[34mâ–ˆâ–Ž        [0m| 28/213 [23:27<2:32:12, 49.37s/it] Training Epoch: 1/10, step 114/855 completed (loss: 0.1410677134990692):  13%|[34mâ–ˆâ–Ž        [0m| 28/213 [23:39<2:32:12, 49.37s/it]Training Epoch: 1/10, step 114/855 completed (loss: 0.1410677134990692):  14%|[34mâ–ˆâ–Ž        [0m| 29/213 [23:52<2:31:22, 49.36s/it]Training Epoch: 1/10, step 115/855 completed (loss: 0.13522636890411377):  14%|[34mâ–ˆâ–Ž        [0m| 29/213 [23:52<2:31:22, 49.36s/it]Training Epoch: 1/10, step 116/855 completed (loss: 0.1418604999780655):  14%|[34mâ–ˆâ–Ž        [0m| 29/213 [24:04<2:31:22, 49.36s/it] Training Epoch: 1/10, step 117/855 completed (loss: 0.13448691368103027):  14%|[34mâ–ˆâ–Ž        [0m| 29/213 [24:16<2:31:22, 49.36s/it]Training Epoch: 1/10, step 118/855 completed (loss: 0.1349576711654663):  14%|[34mâ–ˆâ–Ž        [0m| 29/213 [24:29<2:31:22, 49.36s/it] Training Epoch: 1/10, step 118/855 completed (loss: 0.1349576711654663):  14%|[34mâ–ˆâ–        [0m| 30/213 [24:41<2:30:31, 49.35s/it]Training Epoch: 1/10, step 119/855 completed (loss: 0.13472844660282135):  14%|[34mâ–ˆâ–        [0m| 30/213 [24:41<2:30:31, 49.35s/it]Training Epoch: 1/10, step 120/855 completed (loss: 0.1319008767604828):  14%|[34mâ–ˆâ–        [0m| 30/213 [24:53<2:30:31, 49.35s/it] Training Epoch: 1/10, step 121/855 completed (loss: 0.1339612752199173):  14%|[34mâ–ˆâ–        [0m| 30/213 [25:06<2:30:31, 49.35s/it]Training Epoch: 1/10, step 122/855 completed (loss: 0.13729271292686462):  14%|[34mâ–ˆâ–        [0m| 30/213 [25:18<2:30:31, 49.35s/it]Training Epoch: 1/10, step 122/855 completed (loss: 0.13729271292686462):  15%|[34mâ–ˆâ–        [0m| 31/213 [25:30<2:29:41, 49.35s/it]Training Epoch: 1/10, step 123/855 completed (loss: 0.13328278064727783):  15%|[34mâ–ˆâ–        [0m| 31/213 [25:30<2:29:41, 49.35s/it]Training Epoch: 1/10, step 124/855 completed (loss: 0.13033340871334076):  15%|[34mâ–ˆâ–        [0m| 31/213 [25:43<2:29:41, 49.35s/it]Training Epoch: 1/10, step 125/855 completed (loss: 0.13888750970363617):  15%|[34mâ–ˆâ–        [0m| 31/213 [25:55<2:29:41, 49.35s/it]Training Epoch: 1/10, step 126/855 completed (loss: 0.12955525517463684):  15%|[34mâ–ˆâ–        [0m| 31/213 [26:07<2:29:41, 49.35s/it]Training Epoch: 1/10, step 126/855 completed (loss: 0.12955525517463684):  15%|[34mâ–ˆâ–Œ        [0m| 32/213 [26:20<2:28:52, 49.35s/it]Training Epoch: 1/10, step 127/855 completed (loss: 0.14519070088863373):  15%|[34mâ–ˆâ–Œ        [0m| 32/213 [26:20<2:28:52, 49.35s/it]Training Epoch: 1/10, step 128/855 completed (loss: 0.1415775567293167):  15%|[34mâ–ˆâ–Œ        [0m| 32/213 [26:32<2:28:52, 49.35s/it] Training Epoch: 1/10, step 129/855 completed (loss: 0.13321465253829956):  15%|[34mâ–ˆâ–Œ        [0m| 32/213 [26:45<2:28:52, 49.35s/it]Training Epoch: 1/10, step 130/855 completed (loss: 0.12315185368061066):  15%|[34mâ–ˆâ–Œ        [0m| 32/213 [26:57<2:28:52, 49.35s/it]Training Epoch: 1/10, step 130/855 completed (loss: 0.12315185368061066):  15%|[34mâ–ˆâ–Œ        [0m| 33/213 [27:09<2:28:03, 49.35s/it]Training Epoch: 1/10, step 131/855 completed (loss: 0.13561810553073883):  15%|[34mâ–ˆâ–Œ        [0m| 33/213 [27:09<2:28:03, 49.35s/it]Training Epoch: 1/10, step 132/855 completed (loss: 0.133682519197464):  15%|[34mâ–ˆâ–Œ        [0m| 33/213 [27:22<2:28:03, 49.35s/it]  Training Epoch: 1/10, step 133/855 completed (loss: 0.13022930920124054):  15%|[34mâ–ˆâ–Œ        [0m| 33/213 [27:34<2:28:03, 49.35s/it]Training Epoch: 1/10, step 134/855 completed (loss: 0.12673382461071014):  15%|[34mâ–ˆâ–Œ        [0m| 33/213 [27:46<2:28:03, 49.35s/it]Training Epoch: 1/10, step 134/855 completed (loss: 0.12673382461071014):  16%|[34mâ–ˆâ–Œ        [0m| 34/213 [27:58<2:27:13, 49.35s/it]Training Epoch: 1/10, step 135/855 completed (loss: 0.12303429841995239):  16%|[34mâ–ˆâ–Œ        [0m| 34/213 [27:59<2:27:13, 49.35s/it]Training Epoch: 1/10, step 136/855 completed (loss: 0.12305984646081924):  16%|[34mâ–ˆâ–Œ        [0m| 34/213 [28:11<2:27:13, 49.35s/it]Training Epoch: 1/10, step 137/855 completed (loss: 0.13595455884933472):  16%|[34mâ–ˆâ–Œ        [0m| 34/213 [28:23<2:27:13, 49.35s/it]Training Epoch: 1/10, step 138/855 completed (loss: 0.12035646289587021):  16%|[34mâ–ˆâ–Œ        [0m| 34/213 [28:36<2:27:13, 49.35s/it]Training Epoch: 1/10, step 138/855 completed (loss: 0.12035646289587021):  16%|[34mâ–ˆâ–‹        [0m| 35/213 [28:48<2:26:24, 49.35s/it]Training Epoch: 1/10, step 139/855 completed (loss: 0.14077812433242798):  16%|[34mâ–ˆâ–‹        [0m| 35/213 [28:48<2:26:24, 49.35s/it]Training Epoch: 1/10, step 140/855 completed (loss: 0.15198709070682526):  16%|[34mâ–ˆâ–‹        [0m| 35/213 [29:00<2:26:24, 49.35s/it]Training Epoch: 1/10, step 141/855 completed (loss: 0.14645890891551971):  16%|[34mâ–ˆâ–‹        [0m| 35/213 [29:13<2:26:24, 49.35s/it]Training Epoch: 1/10, step 142/855 completed (loss: 0.1500537097454071):  16%|[34mâ–ˆâ–‹        [0m| 35/213 [29:25<2:26:24, 49.35s/it] Training Epoch: 1/10, step 142/855 completed (loss: 0.1500537097454071):  17%|[34mâ–ˆâ–‹        [0m| 36/213 [29:37<2:25:35, 49.35s/it]Training Epoch: 1/10, step 143/855 completed (loss: 0.1528407484292984):  17%|[34mâ–ˆâ–‹        [0m| 36/213 [29:37<2:25:35, 49.35s/it]Training Epoch: 1/10, step 144/855 completed (loss: 0.1254744827747345):  17%|[34mâ–ˆâ–‹        [0m| 36/213 [29:50<2:25:35, 49.35s/it]Training Epoch: 1/10, step 145/855 completed (loss: 0.12316398322582245):  17%|[34mâ–ˆâ–‹        [0m| 36/213 [30:02<2:25:35, 49.35s/it]Training Epoch: 1/10, step 146/855 completed (loss: 0.13928256928920746):  17%|[34mâ–ˆâ–‹        [0m| 36/213 [30:14<2:25:35, 49.35s/it]Training Epoch: 1/10, step 146/855 completed (loss: 0.13928256928920746):  17%|[34mâ–ˆâ–‹        [0m| 37/213 [30:26<2:24:46, 49.35s/it]Training Epoch: 1/10, step 147/855 completed (loss: 0.13541196286678314):  17%|[34mâ–ˆâ–‹        [0m| 37/213 [30:27<2:24:46, 49.35s/it]Training Epoch: 1/10, step 148/855 completed (loss: 0.15830756723880768):  17%|[34mâ–ˆâ–‹        [0m| 37/213 [30:39<2:24:46, 49.35s/it]Training Epoch: 1/10, step 149/855 completed (loss: 0.15155243873596191):  17%|[34mâ–ˆâ–‹        [0m| 37/213 [30:51<2:24:46, 49.35s/it]Training Epoch: 1/10, step 150/855 completed (loss: 0.10781121999025345):  17%|[34mâ–ˆâ–‹        [0m| 37/213 [31:04<2:24:46, 49.35s/it]Training Epoch: 1/10, step 150/855 completed (loss: 0.10781121999025345):  18%|[34mâ–ˆâ–Š        [0m| 38/213 [31:16<2:23:56, 49.35s/it]Training Epoch: 1/10, step 151/855 completed (loss: 0.15635722875595093):  18%|[34mâ–ˆâ–Š        [0m| 38/213 [31:16<2:23:56, 49.35s/it]Training Epoch: 1/10, step 152/855 completed (loss: 0.11855782568454742):  18%|[34mâ–ˆâ–Š        [0m| 38/213 [31:28<2:23:56, 49.35s/it]Training Epoch: 1/10, step 153/855 completed (loss: 0.13578930497169495):  18%|[34mâ–ˆâ–Š        [0m| 38/213 [31:41<2:23:56, 49.35s/it]Training Epoch: 1/10, step 154/855 completed (loss: 0.12567642331123352):  18%|[34mâ–ˆâ–Š        [0m| 38/213 [31:53<2:23:56, 49.35s/it]Training Epoch: 1/10, step 154/855 completed (loss: 0.12567642331123352):  18%|[34mâ–ˆâ–Š        [0m| 39/213 [32:05<2:23:07, 49.35s/it]Training Epoch: 1/10, step 155/855 completed (loss: 0.13177244365215302):  18%|[34mâ–ˆâ–Š        [0m| 39/213 [32:05<2:23:07, 49.35s/it]Training Epoch: 1/10, step 156/855 completed (loss: 0.12908177077770233):  18%|[34mâ–ˆâ–Š        [0m| 39/213 [32:18<2:23:07, 49.35s/it]Training Epoch: 1/10, step 157/855 completed (loss: 0.12431971728801727):  18%|[34mâ–ˆâ–Š        [0m| 39/213 [32:30<2:23:07, 49.35s/it]Training Epoch: 1/10, step 158/855 completed (loss: 0.13433074951171875):  18%|[34mâ–ˆâ–Š        [0m| 39/213 [32:42<2:23:07, 49.35s/it]Training Epoch: 1/10, step 158/855 completed (loss: 0.13433074951171875):  19%|[34mâ–ˆâ–‰        [0m| 40/213 [32:54<2:22:19, 49.36s/it]Training Epoch: 1/10, step 159/855 completed (loss: 0.13273483514785767):  19%|[34mâ–ˆâ–‰        [0m| 40/213 [32:55<2:22:19, 49.36s/it]Training Epoch: 1/10, step 160/855 completed (loss: 0.13083119690418243):  19%|[34mâ–ˆâ–‰        [0m| 40/213 [33:07<2:22:19, 49.36s/it]Training Epoch: 1/10, step 161/855 completed (loss: 0.12649592757225037):  19%|[34mâ–ˆâ–‰        [0m| 40/213 [33:19<2:22:19, 49.36s/it]Training Epoch: 1/10, step 162/855 completed (loss: 0.13209445774555206):  19%|[34mâ–ˆâ–‰        [0m| 40/213 [33:32<2:22:19, 49.36s/it]Training Epoch: 1/10, step 162/855 completed (loss: 0.13209445774555206):  19%|[34mâ–ˆâ–‰        [0m| 41/213 [33:44<2:21:31, 49.37s/it]Training Epoch: 1/10, step 163/855 completed (loss: 0.15607880055904388):  19%|[34mâ–ˆâ–‰        [0m| 41/213 [33:44<2:21:31, 49.37s/it]Training Epoch: 1/10, step 164/855 completed (loss: 0.156967893242836):  19%|[34mâ–ˆâ–‰        [0m| 41/213 [33:56<2:21:31, 49.37s/it]  Training Epoch: 1/10, step 165/855 completed (loss: 0.15473559498786926):  19%|[34mâ–ˆâ–‰        [0m| 41/213 [34:09<2:21:31, 49.37s/it]Training Epoch: 1/10, step 166/855 completed (loss: 0.10978839546442032):  19%|[34mâ–ˆâ–‰        [0m| 41/213 [34:21<2:21:31, 49.37s/it]Training Epoch: 1/10, step 166/855 completed (loss: 0.10978839546442032):  20%|[34mâ–ˆâ–‰        [0m| 42/213 [34:33<2:20:43, 49.38s/it]Training Epoch: 1/10, step 167/855 completed (loss: 0.1696583330631256):  20%|[34mâ–ˆâ–‰        [0m| 42/213 [34:33<2:20:43, 49.38s/it] Training Epoch: 1/10, step 168/855 completed (loss: 0.12212612479925156):  20%|[34mâ–ˆâ–‰        [0m| 42/213 [34:46<2:20:43, 49.38s/it]Training Epoch: 1/10, step 169/855 completed (loss: 0.1183001920580864):  20%|[34mâ–ˆâ–‰        [0m| 42/213 [34:58<2:20:43, 49.38s/it] Training Epoch: 1/10, step 170/855 completed (loss: 0.15767671167850494):  20%|[34mâ–ˆâ–‰        [0m| 42/213 [35:11<2:20:43, 49.38s/it]Training Epoch: 1/10, step 170/855 completed (loss: 0.15767671167850494):  20%|[34mâ–ˆâ–ˆ        [0m| 43/213 [35:23<2:19:54, 49.38s/it]Training Epoch: 1/10, step 171/855 completed (loss: 0.15038874745368958):  20%|[34mâ–ˆâ–ˆ        [0m| 43/213 [35:23<2:19:54, 49.38s/it]Training Epoch: 1/10, step 172/855 completed (loss: 0.11994379758834839):  20%|[34mâ–ˆâ–ˆ        [0m| 43/213 [35:35<2:19:54, 49.38s/it]Training Epoch: 1/10, step 173/855 completed (loss: 0.14632029831409454):  20%|[34mâ–ˆâ–ˆ        [0m| 43/213 [35:48<2:19:54, 49.38s/it]Training Epoch: 1/10, step 174/855 completed (loss: 0.10980384796857834):  20%|[34mâ–ˆâ–ˆ        [0m| 43/213 [36:00<2:19:54, 49.38s/it]Training Epoch: 1/10, step 174/855 completed (loss: 0.10980384796857834):  21%|[34mâ–ˆâ–ˆ        [0m| 44/213 [36:12<2:19:02, 49.37s/it]Training Epoch: 1/10, step 175/855 completed (loss: 0.1085326299071312):  21%|[34mâ–ˆâ–ˆ        [0m| 44/213 [36:12<2:19:02, 49.37s/it] Training Epoch: 1/10, step 176/855 completed (loss: 0.12109773606061935):  21%|[34mâ–ˆâ–ˆ        [0m| 44/213 [36:24<2:19:02, 49.37s/it]Training Epoch: 1/10, step 177/855 completed (loss: 0.13012917339801788):  21%|[34mâ–ˆâ–ˆ        [0m| 44/213 [36:37<2:19:02, 49.37s/it]Training Epoch: 1/10, step 178/855 completed (loss: 0.12457751482725143):  21%|[34mâ–ˆâ–ˆ        [0m| 44/213 [36:49<2:19:02, 49.37s/it]Training Epoch: 1/10, step 178/855 completed (loss: 0.12457751482725143):  21%|[34mâ–ˆâ–ˆ        [0m| 45/213 [37:01<2:18:13, 49.36s/it]Training Epoch: 1/10, step 179/855 completed (loss: 0.15309078991413116):  21%|[34mâ–ˆâ–ˆ        [0m| 45/213 [37:02<2:18:13, 49.36s/it]Training Epoch: 1/10, step 180/855 completed (loss: 0.13175413012504578):  21%|[34mâ–ˆâ–ˆ        [0m| 45/213 [37:14<2:18:13, 49.36s/it]Training Epoch: 1/10, step 181/855 completed (loss: 0.1344846487045288):  21%|[34mâ–ˆâ–ˆ        [0m| 45/213 [37:26<2:18:13, 49.36s/it] Training Epoch: 1/10, step 182/855 completed (loss: 0.14639884233474731):  21%|[34mâ–ˆâ–ˆ        [0m| 45/213 [37:39<2:18:13, 49.36s/it]Training Epoch: 1/10, step 182/855 completed (loss: 0.14639884233474731):  22%|[34mâ–ˆâ–ˆâ–       [0m| 46/213 [37:51<2:17:26, 49.38s/it]Training Epoch: 1/10, step 183/855 completed (loss: 0.12215779721736908):  22%|[34mâ–ˆâ–ˆâ–       [0m| 46/213 [37:51<2:17:26, 49.38s/it]Training Epoch: 1/10, step 184/855 completed (loss: 0.1275864541530609):  22%|[34mâ–ˆâ–ˆâ–       [0m| 46/213 [38:03<2:17:26, 49.38s/it] Training Epoch: 1/10, step 185/855 completed (loss: 0.11920002847909927):  22%|[34mâ–ˆâ–ˆâ–       [0m| 46/213 [38:16<2:17:26, 49.38s/it]Training Epoch: 1/10, step 186/855 completed (loss: 0.12995952367782593):  22%|[34mâ–ˆâ–ˆâ–       [0m| 46/213 [38:28<2:17:26, 49.38s/it]Training Epoch: 1/10, step 186/855 completed (loss: 0.12995952367782593):  22%|[34mâ–ˆâ–ˆâ–       [0m| 47/213 [38:40<2:16:36, 49.38s/it]Training Epoch: 1/10, step 187/855 completed (loss: 0.12892931699752808):  22%|[34mâ–ˆâ–ˆâ–       [0m| 47/213 [38:40<2:16:36, 49.38s/it]Training Epoch: 1/10, step 188/855 completed (loss: 0.1365162581205368):  22%|[34mâ–ˆâ–ˆâ–       [0m| 47/213 [38:53<2:16:36, 49.38s/it] Training Epoch: 1/10, step 189/855 completed (loss: 0.12765291333198547):  22%|[34mâ–ˆâ–ˆâ–       [0m| 47/213 [39:05<2:16:36, 49.38s/it]Training Epoch: 1/10, step 190/855 completed (loss: 0.14074033498764038):  22%|[34mâ–ˆâ–ˆâ–       [0m| 47/213 [39:17<2:16:36, 49.38s/it]Training Epoch: 1/10, step 190/855 completed (loss: 0.14074033498764038):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 48/213 [39:30<2:15:47, 49.38s/it]Training Epoch: 1/10, step 191/855 completed (loss: 0.12391386926174164):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 48/213 [39:30<2:15:47, 49.38s/it]Training Epoch: 1/10, step 192/855 completed (loss: 0.10115890204906464):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 48/213 [39:42<2:15:47, 49.38s/it]Training Epoch: 1/10, step 193/855 completed (loss: 0.13033702969551086):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 48/213 [39:54<2:15:47, 49.38s/it]Training Epoch: 1/10, step 194/855 completed (loss: 0.1104980856180191):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 48/213 [40:07<2:15:47, 49.38s/it] Training Epoch: 1/10, step 194/855 completed (loss: 0.1104980856180191):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 49/213 [40:19<2:14:57, 49.38s/it]Training Epoch: 1/10, step 195/855 completed (loss: 0.12235142290592194):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 49/213 [40:19<2:14:57, 49.38s/it]Training Epoch: 1/10, step 196/855 completed (loss: 0.16601097583770752):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 49/213 [40:31<2:14:57, 49.38s/it]Training Epoch: 1/10, step 197/855 completed (loss: 0.1301012933254242):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 49/213 [40:44<2:14:57, 49.38s/it] Training Epoch: 1/10, step 198/855 completed (loss: 0.13317753374576569):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 49/213 [40:56<2:14:57, 49.38s/it]Training Epoch: 1/10, step 198/855 completed (loss: 0.13317753374576569):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 50/213 [41:08<2:14:07, 49.37s/it]Training Epoch: 1/10, step 199/855 completed (loss: 0.14036022126674652):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 50/213 [41:08<2:14:07, 49.37s/it]Training Epoch: 1/10, step 200/855 completed (loss: 0.1252892017364502):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 50/213 [41:21<2:14:07, 49.37s/it] Training Epoch: 1/10, step 201/855 completed (loss: 0.13404417037963867):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 50/213 [41:33<2:14:07, 49.37s/it]Training Epoch: 1/10, step 202/855 completed (loss: 0.12244938313961029):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 50/213 [41:45<2:14:07, 49.37s/it]Training Epoch: 1/10, step 202/855 completed (loss: 0.12244938313961029):  24%|[34mâ–ˆâ–ˆâ–       [0m| 51/213 [41:58<2:13:18, 49.37s/it]Training Epoch: 1/10, step 203/855 completed (loss: 0.12441445887088776):  24%|[34mâ–ˆâ–ˆâ–       [0m| 51/213 [41:58<2:13:18, 49.37s/it]Training Epoch: 1/10, step 204/855 completed (loss: 0.12440154701471329):  24%|[34mâ–ˆâ–ˆâ–       [0m| 51/213 [42:10<2:13:18, 49.37s/it]Training Epoch: 1/10, step 205/855 completed (loss: 0.11085918545722961):  24%|[34mâ–ˆâ–ˆâ–       [0m| 51/213 [42:23<2:13:18, 49.37s/it]Training Epoch: 1/10, step 206/855 completed (loss: 0.12377212196588516):  24%|[34mâ–ˆâ–ˆâ–       [0m| 51/213 [42:35<2:13:18, 49.37s/it]Training Epoch: 1/10, step 206/855 completed (loss: 0.12377212196588516):  24%|[34mâ–ˆâ–ˆâ–       [0m| 52/213 [42:47<2:12:29, 49.37s/it]Training Epoch: 1/10, step 207/855 completed (loss: 0.11444036662578583):  24%|[34mâ–ˆâ–ˆâ–       [0m| 52/213 [42:47<2:12:29, 49.37s/it]Training Epoch: 1/10, step 208/855 completed (loss: 0.1314004361629486):  24%|[34mâ–ˆâ–ˆâ–       [0m| 52/213 [43:00<2:12:29, 49.37s/it] Training Epoch: 1/10, step 209/855 completed (loss: 0.1427534967660904):  24%|[34mâ–ˆâ–ˆâ–       [0m| 52/213 [43:12<2:12:29, 49.37s/it]Training Epoch: 1/10, step 210/855 completed (loss: 0.10898308455944061):  24%|[34mâ–ˆâ–ˆâ–       [0m| 52/213 [43:24<2:12:29, 49.37s/it]Training Epoch: 1/10, step 210/855 completed (loss: 0.10898308455944061):  25%|[34mâ–ˆâ–ˆâ–       [0m| 53/213 [43:36<2:11:40, 49.38s/it]Training Epoch: 1/10, step 211/855 completed (loss: 0.12739545106887817):  25%|[34mâ–ˆâ–ˆâ–       [0m| 53/213 [43:37<2:11:40, 49.38s/it]Training Epoch: 1/10, step 212/855 completed (loss: 0.1600220799446106):  25%|[34mâ–ˆâ–ˆâ–       [0m| 53/213 [43:49<2:11:40, 49.38s/it] Training Epoch: 1/10, step 213/855 completed (loss: 0.11572527140378952):  25%|[34mâ–ˆâ–ˆâ–       [0m| 53/213 [44:01<2:11:40, 49.38s/it]Training Epoch: 1/10, step 214/855 completed (loss: 0.1285339593887329):  25%|[34mâ–ˆâ–ˆâ–       [0m| 53/213 [44:14<2:11:40, 49.38s/it] Training Epoch: 1/10, step 214/855 completed (loss: 0.1285339593887329):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 54/213 [44:26<2:10:51, 49.38s/it]Training Epoch: 1/10, step 215/855 completed (loss: 0.13749808073043823):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 54/213 [44:26<2:10:51, 49.38s/it]Training Epoch: 1/10, step 216/855 completed (loss: 0.09910235553979874):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 54/213 [44:38<2:10:51, 49.38s/it]Training Epoch: 1/10, step 217/855 completed (loss: 0.12223901599645615):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 54/213 [44:51<2:10:51, 49.38s/it]Training Epoch: 1/10, step 218/855 completed (loss: 0.09078928828239441):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 54/213 [45:03<2:10:51, 49.38s/it]Training Epoch: 1/10, step 218/855 completed (loss: 0.09078928828239441):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 55/213 [45:15<2:10:00, 49.37s/it]Training Epoch: 1/10, step 219/855 completed (loss: 0.1349446177482605):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 55/213 [45:15<2:10:00, 49.37s/it] Training Epoch: 1/10, step 220/855 completed (loss: 0.11782483756542206):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 55/213 [45:28<2:10:00, 49.37s/it]Training Epoch: 1/10, step 221/855 completed (loss: 0.11562656611204147):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 55/213 [45:40<2:10:00, 49.37s/it]Training Epoch: 1/10, step 222/855 completed (loss: 0.12352406233549118):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 55/213 [45:52<2:10:00, 49.37s/it]Training Epoch: 1/10, step 222/855 completed (loss: 0.12352406233549118):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 56/213 [46:04<2:09:10, 49.37s/it]Training Epoch: 1/10, step 223/855 completed (loss: 0.12200947105884552):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 56/213 [46:05<2:09:10, 49.37s/it]Training Epoch: 1/10, step 224/855 completed (loss: 0.12808917462825775):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 56/213 [46:17<2:09:10, 49.37s/it]Training Epoch: 1/10, step 225/855 completed (loss: 0.10608834028244019):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 56/213 [46:29<2:09:10, 49.37s/it]Training Epoch: 1/10, step 226/855 completed (loss: 0.11306348443031311):  26%|[34mâ–ˆâ–ˆâ–‹       [0m| 56/213 [46:42<2:09:10, 49.37s/it]Training Epoch: 1/10, step 226/855 completed (loss: 0.11306348443031311):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 57/213 [46:54<2:08:20, 49.36s/it]Training Epoch: 1/10, step 227/855 completed (loss: 0.11886195838451385):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 57/213 [46:54<2:08:20, 49.36s/it]Training Epoch: 1/10, step 228/855 completed (loss: 0.06585061550140381):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 57/213 [47:06<2:08:20, 49.36s/it]Training Epoch: 1/10, step 229/855 completed (loss: 0.06992683559656143):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 57/213 [47:19<2:08:20, 49.36s/it]Training Epoch: 1/10, step 230/855 completed (loss: 0.12243160605430603):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 57/213 [47:31<2:08:20, 49.36s/it]Training Epoch: 1/10, step 230/855 completed (loss: 0.12243160605430603):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 58/213 [47:43<2:07:30, 49.36s/it]Training Epoch: 1/10, step 231/855 completed (loss: 0.0726141631603241):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 58/213 [47:43<2:07:30, 49.36s/it] Training Epoch: 1/10, step 232/855 completed (loss: 0.08562622219324112):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 58/213 [47:56<2:07:30, 49.36s/it]Training Epoch: 1/10, step 233/855 completed (loss: 0.08801262080669403):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 58/213 [48:08<2:07:30, 49.36s/it]Training Epoch: 1/10, step 234/855 completed (loss: 0.08024134486913681):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 58/213 [48:20<2:07:30, 49.36s/it]Training Epoch: 1/10, step 234/855 completed (loss: 0.08024134486913681):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 59/213 [48:33<2:06:41, 49.36s/it]Training Epoch: 1/10, step 235/855 completed (loss: 0.17149122059345245):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 59/213 [48:33<2:06:41, 49.36s/it]Training Epoch: 1/10, step 236/855 completed (loss: 0.13962112367153168):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 59/213 [48:45<2:06:41, 49.36s/it]Training Epoch: 1/10, step 237/855 completed (loss: 0.05616867542266846):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 59/213 [48:57<2:06:41, 49.36s/it]Training Epoch: 1/10, step 238/855 completed (loss: 0.08609827607870102):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 59/213 [49:10<2:06:41, 49.36s/it]Training Epoch: 1/10, step 238/855 completed (loss: 0.08609827607870102):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 60/213 [49:22<2:05:53, 49.37s/it]Training Epoch: 1/10, step 239/855 completed (loss: 0.09621880948543549):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 60/213 [49:22<2:05:53, 49.37s/it]Training Epoch: 1/10, step 240/855 completed (loss: 0.09477432072162628):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 60/213 [49:34<2:05:53, 49.37s/it]Training Epoch: 1/10, step 241/855 completed (loss: 0.08390940725803375):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 60/213 [49:47<2:05:53, 49.37s/it]Training Epoch: 1/10, step 242/855 completed (loss: 0.08158509433269501):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 60/213 [49:59<2:05:53, 49.37s/it]Training Epoch: 1/10, step 242/855 completed (loss: 0.08158509433269501):  29%|[34mâ–ˆâ–ˆâ–Š       [0m| 61/213 [50:11<2:05:03, 49.37s/it]Training Epoch: 1/10, step 243/855 completed (loss: 0.10118068009614944):  29%|[34mâ–ˆâ–ˆâ–Š       [0m| 61/213 [50:11<2:05:03, 49.37s/it]Training Epoch: 1/10, step 244/855 completed (loss: 0.1063813716173172):  29%|[34mâ–ˆâ–ˆâ–Š       [0m| 61/213 [50:24<2:05:03, 49.37s/it] Training Epoch: 1/10, step 245/855 completed (loss: 0.10200075060129166):  29%|[34mâ–ˆâ–ˆâ–Š       [0m| 61/213 [50:36<2:05:03, 49.37s/it]Training Epoch: 1/10, step 246/855 completed (loss: 0.11041206866502762):  29%|[34mâ–ˆâ–ˆâ–Š       [0m| 61/213 [50:49<2:05:03, 49.37s/it]Training Epoch: 1/10, step 246/855 completed (loss: 0.11041206866502762):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 62/213 [51:01<2:04:14, 49.37s/it]Training Epoch: 1/10, step 247/855 completed (loss: 0.09713828563690186):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 62/213 [51:01<2:04:14, 49.37s/it]Training Epoch: 1/10, step 248/855 completed (loss: 0.08289042860269547):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 62/213 [51:13<2:04:14, 49.37s/it]Training Epoch: 1/10, step 249/855 completed (loss: 0.08772360533475876):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 62/213 [51:26<2:04:14, 49.37s/it]Training Epoch: 1/10, step 250/855 completed (loss: 0.07982171326875687):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 62/213 [51:38<2:04:14, 49.37s/it]Training Epoch: 1/10, step 250/855 completed (loss: 0.07982171326875687):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 63/213 [51:50<2:03:25, 49.37s/it]Training Epoch: 1/10, step 251/855 completed (loss: 0.086435467004776):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 63/213 [51:50<2:03:25, 49.37s/it]  Training Epoch: 1/10, step 252/855 completed (loss: 0.0790192186832428):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 63/213 [52:03<2:03:25, 49.37s/it]Training Epoch: 1/10, step 253/855 completed (loss: 0.11576332151889801):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 63/213 [52:15<2:03:25, 49.37s/it]Training Epoch: 1/10, step 254/855 completed (loss: 0.08445663750171661):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 63/213 [52:27<2:03:25, 49.37s/it]Training Epoch: 1/10, step 254/855 completed (loss: 0.08445663750171661):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 64/213 [52:39<2:02:36, 49.37s/it]Training Epoch: 1/10, step 255/855 completed (loss: 0.09957186877727509):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 64/213 [52:40<2:02:36, 49.37s/it]Training Epoch: 1/10, step 256/855 completed (loss: 0.02639738842844963):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 64/213 [52:52<2:02:36, 49.37s/it]Training Epoch: 1/10, step 257/855 completed (loss: 0.10046529024839401):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 64/213 [53:04<2:02:36, 49.37s/it]Training Epoch: 1/10, step 258/855 completed (loss: 0.12553562223911285):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 64/213 [53:17<2:02:36, 49.37s/it]Training Epoch: 1/10, step 258/855 completed (loss: 0.12553562223911285):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 65/213 [53:29<2:01:44, 49.36s/it]Training Epoch: 1/10, step 259/855 completed (loss: 0.0995902270078659):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 65/213 [53:29<2:01:44, 49.36s/it] Training Epoch: 1/10, step 260/855 completed (loss: 0.07411660999059677):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 65/213 [53:41<2:01:44, 49.36s/it]Training Epoch: 1/10, step 261/855 completed (loss: 0.1412154585123062):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 65/213 [53:54<2:01:44, 49.36s/it] Training Epoch: 1/10, step 262/855 completed (loss: 0.05156666785478592):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 65/213 [54:06<2:01:44, 49.36s/it]Training Epoch: 1/10, step 262/855 completed (loss: 0.05156666785478592):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 66/213 [54:18<2:00:54, 49.35s/it]Training Epoch: 1/10, step 263/855 completed (loss: 0.061373550444841385):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 66/213 [54:18<2:00:54, 49.35s/it]Training Epoch: 1/10, step 264/855 completed (loss: 0.06269034743309021):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 66/213 [54:31<2:00:54, 49.35s/it] Training Epoch: 1/10, step 265/855 completed (loss: 0.1399228870868683):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 66/213 [54:43<2:00:54, 49.35s/it] Training Epoch: 1/10, step 266/855 completed (loss: 0.10542993992567062):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 66/213 [54:55<2:00:54, 49.35s/it]Training Epoch: 1/10, step 266/855 completed (loss: 0.10542993992567062):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 67/213 [55:07<2:00:03, 49.34s/it]Training Epoch: 1/10, step 267/855 completed (loss: 0.04582143574953079):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 67/213 [55:08<2:00:03, 49.34s/it]Training Epoch: 1/10, step 268/855 completed (loss: 0.06650137901306152):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 67/213 [55:20<2:00:03, 49.34s/it]Training Epoch: 1/10, step 269/855 completed (loss: 0.0803750529885292):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 67/213 [55:32<2:00:03, 49.34s/it] Training Epoch: 1/10, step 270/855 completed (loss: 0.07318173348903656):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 67/213 [55:45<2:00:03, 49.34s/it]Training Epoch: 1/10, step 270/855 completed (loss: 0.07318173348903656):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 68/213 [55:57<1:59:12, 49.33s/it]Training Epoch: 1/10, step 271/855 completed (loss: 0.08022721111774445):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 68/213 [55:57<1:59:12, 49.33s/it]Training Epoch: 1/10, step 272/855 completed (loss: 0.11611218005418777):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 68/213 [56:09<1:59:12, 49.33s/it]Training Epoch: 1/10, step 273/855 completed (loss: 0.12254498898983002):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 68/213 [56:22<1:59:12, 49.33s/it]Training Epoch: 1/10, step 274/855 completed (loss: 0.08759776502847672):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 68/213 [56:34<1:59:12, 49.33s/it]Training Epoch: 1/10, step 274/855 completed (loss: 0.08759776502847672):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 69/213 [56:46<1:58:22, 49.33s/it]Training Epoch: 1/10, step 275/855 completed (loss: 0.07236666232347488):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 69/213 [56:46<1:58:22, 49.33s/it]Training Epoch: 1/10, step 276/855 completed (loss: 0.059259939938783646):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 69/213 [56:59<1:58:22, 49.33s/it]Training Epoch: 1/10, step 277/855 completed (loss: 0.11484641581773758):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 69/213 [57:11<1:58:22, 49.33s/it] Training Epoch: 1/10, step 278/855 completed (loss: 0.026873869821429253):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 69/213 [57:23<1:58:22, 49.33s/it]Training Epoch: 1/10, step 278/855 completed (loss: 0.026873869821429253):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 70/213 [57:35<1:57:34, 49.33s/it]Training Epoch: 1/10, step 279/855 completed (loss: 0.0647663101553917):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 70/213 [57:36<1:57:34, 49.33s/it]  Training Epoch: 1/10, step 280/855 completed (loss: 0.06423193961381912):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 70/213 [57:48<1:57:34, 49.33s/it]Training Epoch: 1/10, step 281/855 completed (loss: 0.12186803668737411):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 70/213 [58:00<1:57:34, 49.33s/it]Training Epoch: 1/10, step 282/855 completed (loss: 0.07666786015033722):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 70/213 [58:13<1:57:34, 49.33s/it]Training Epoch: 1/10, step 282/855 completed (loss: 0.07666786015033722):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 71/213 [58:25<1:56:44, 49.33s/it]Training Epoch: 1/10, step 283/855 completed (loss: 0.07962033152580261):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 71/213 [58:25<1:56:44, 49.33s/it]Training Epoch: 1/10, step 284/855 completed (loss: 0.06495843082666397):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 71/213 [58:37<1:56:44, 49.33s/it]Training Epoch: 1/10, step 285/855 completed (loss: 0.0662926733493805):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 71/213 [58:50<1:56:44, 49.33s/it] Training Epoch: 1/10, step 286/855 completed (loss: 0.0750022679567337):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 71/213 [59:02<1:56:44, 49.33s/it]Training Epoch: 1/10, step 286/855 completed (loss: 0.0750022679567337):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 72/213 [59:14<1:55:54, 49.32s/it]Training Epoch: 1/10, step 287/855 completed (loss: 0.1468489170074463):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 72/213 [59:14<1:55:54, 49.32s/it]Training Epoch: 1/10, step 288/855 completed (loss: 0.12276452779769897):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 72/213 [59:27<1:55:54, 49.32s/it]Training Epoch: 1/10, step 289/855 completed (loss: 0.1006869524717331):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 72/213 [59:39<1:55:54, 49.32s/it] Training Epoch: 1/10, step 290/855 completed (loss: 0.07104536890983582):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 72/213 [59:51<1:55:54, 49.32s/it]Training Epoch: 1/10, step 290/855 completed (loss: 0.07104536890983582):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 73/213 [1:00:03<1:55:04, 49.32s/it]Training Epoch: 1/10, step 291/855 completed (loss: 0.03570975735783577):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 73/213 [1:00:03<1:55:04, 49.32s/it]Training Epoch: 1/10, step 292/855 completed (loss: 0.05173978582024574):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 73/213 [1:00:16<1:55:04, 49.32s/it]Training Epoch: 1/10, step 293/855 completed (loss: 0.08859556168317795):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 73/213 [1:00:28<1:55:04, 49.32s/it]Training Epoch: 1/10, step 294/855 completed (loss: 0.09284087270498276):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 73/213 [1:00:40<1:55:04, 49.32s/it]Training Epoch: 1/10, step 294/855 completed (loss: 0.09284087270498276):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 74/213 [1:00:53<1:54:15, 49.32s/it]Training Epoch: 1/10, step 295/855 completed (loss: 0.051515452563762665):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 74/213 [1:00:53<1:54:15, 49.32s/it]Training Epoch: 1/10, step 296/855 completed (loss: 0.06913629174232483):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 74/213 [1:01:05<1:54:15, 49.32s/it] Training Epoch: 1/10, step 297/855 completed (loss: 0.058445800095796585):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 74/213 [1:01:17<1:54:15, 49.32s/it]Training Epoch: 1/10, step 298/855 completed (loss: 0.04391990602016449):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 74/213 [1:01:30<1:54:15, 49.32s/it] Training Epoch: 1/10, step 298/855 completed (loss: 0.04391990602016449):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 75/213 [1:01:42<1:53:25, 49.31s/it]Training Epoch: 1/10, step 299/855 completed (loss: 0.06636222451925278):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 75/213 [1:01:42<1:53:25, 49.31s/it]Training Epoch: 1/10, step 300/855 completed (loss: 0.034591689705848694):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 75/213 [1:01:54<1:53:25, 49.31s/it]Training Epoch: 1/10, step 301/855 completed (loss: 0.05519739165902138):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 75/213 [1:02:07<1:53:25, 49.31s/it] Training Epoch: 1/10, step 302/855 completed (loss: 0.05207868292927742):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 75/213 [1:02:19<1:53:25, 49.31s/it]Training Epoch: 1/10, step 302/855 completed (loss: 0.05207868292927742):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 76/213 [1:02:31<1:52:37, 49.32s/it]Training Epoch: 1/10, step 303/855 completed (loss: 0.07825329899787903):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 76/213 [1:02:31<1:52:37, 49.32s/it]Training Epoch: 1/10, step 304/855 completed (loss: 0.07506877928972244):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 76/213 [1:02:44<1:52:37, 49.32s/it]Training Epoch: 1/10, step 305/855 completed (loss: 0.05502358824014664):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 76/213 [1:02:56<1:52:37, 49.32s/it]Training Epoch: 1/10, step 306/855 completed (loss: 0.026401450857520103):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 76/213 [1:03:08<1:52:37, 49.32s/it]Training Epoch: 1/10, step 306/855 completed (loss: 0.026401450857520103):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 77/213 [1:03:21<1:51:49, 49.33s/it]Training Epoch: 1/10, step 307/855 completed (loss: 0.08140413463115692):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 77/213 [1:03:21<1:51:49, 49.33s/it] Training Epoch: 1/10, step 308/855 completed (loss: 0.06576947122812271):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 77/213 [1:03:33<1:51:49, 49.33s/it]Training Epoch: 1/10, step 309/855 completed (loss: 0.062196336686611176):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 77/213 [1:03:45<1:51:49, 49.33s/it]Training Epoch: 1/10, step 310/855 completed (loss: 0.010369413532316685):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 77/213 [1:03:58<1:51:49, 49.33s/it]Training Epoch: 1/10, step 310/855 completed (loss: 0.010369413532316685):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 78/213 [1:04:10<1:50:59, 49.33s/it]Training Epoch: 1/10, step 311/855 completed (loss: 0.014938047155737877):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 78/213 [1:04:10<1:50:59, 49.33s/it]Training Epoch: 1/10, step 312/855 completed (loss: 0.2190600037574768):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 78/213 [1:04:22<1:50:59, 49.33s/it]  Training Epoch: 1/10, step 313/855 completed (loss: 0.08556181192398071):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 78/213 [1:04:35<1:50:59, 49.33s/it]Training Epoch: 1/10, step 314/855 completed (loss: 0.1305978149175644):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 78/213 [1:04:47<1:50:59, 49.33s/it] Training Epoch: 1/10, step 314/855 completed (loss: 0.1305978149175644):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 79/213 [1:04:59<1:50:09, 49.32s/it]Training Epoch: 1/10, step 315/855 completed (loss: 0.1512390822172165):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 79/213 [1:04:59<1:50:09, 49.32s/it]Training Epoch: 1/10, step 316/855 completed (loss: 0.04300151765346527):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 79/213 [1:05:12<1:50:09, 49.32s/it]Training Epoch: 1/10, step 317/855 completed (loss: 0.05705081671476364):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 79/213 [1:05:24<1:50:09, 49.32s/it]Training Epoch: 1/10, step 318/855 completed (loss: 0.0223727785050869):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 79/213 [1:05:36<1:50:09, 49.32s/it] Training Epoch: 1/10, step 318/855 completed (loss: 0.0223727785050869):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 80/213 [1:05:49<1:49:19, 49.32s/it]Training Epoch: 1/10, step 319/855 completed (loss: 0.03879975154995918):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 80/213 [1:05:49<1:49:19, 49.32s/it]Training Epoch: 1/10, step 320/855 completed (loss: 0.04090570658445358):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 80/213 [1:06:01<1:49:19, 49.32s/it]Training Epoch: 1/10, step 321/855 completed (loss: 0.022570066154003143):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 80/213 [1:06:13<1:49:19, 49.32s/it]Training Epoch: 1/10, step 322/855 completed (loss: 0.12336912006139755):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 80/213 [1:06:26<1:49:19, 49.32s/it] Training Epoch: 1/10, step 322/855 completed (loss: 0.12336912006139755):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 81/213 [1:06:38<1:48:29, 49.32s/it]Training Epoch: 1/10, step 323/855 completed (loss: 0.07898198813199997):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 81/213 [1:06:38<1:48:29, 49.32s/it]Training Epoch: 1/10, step 324/855 completed (loss: 0.08382966369390488):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 81/213 [1:06:50<1:48:29, 49.32s/it]Training Epoch: 1/10, step 325/855 completed (loss: 0.09644880145788193):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 81/213 [1:07:03<1:48:29, 49.32s/it]Training Epoch: 1/10, step 326/855 completed (loss: 0.07818553596735):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 81/213 [1:07:15<1:48:29, 49.32s/it]   Training Epoch: 1/10, step 326/855 completed (loss: 0.07818553596735):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 82/213 [1:07:27<1:47:40, 49.32s/it]Training Epoch: 1/10, step 327/855 completed (loss: 0.13230842351913452):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 82/213 [1:07:27<1:47:40, 49.32s/it]Training Epoch: 1/10, step 328/855 completed (loss: 0.06212785094976425):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 82/213 [1:07:40<1:47:40, 49.32s/it]Training Epoch: 1/10, step 329/855 completed (loss: 0.03457048907876015):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 82/213 [1:07:52<1:47:40, 49.32s/it]Training Epoch: 1/10, step 330/855 completed (loss: 0.059620898216962814):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 82/213 [1:08:04<1:47:40, 49.32s/it]Training Epoch: 1/10, step 330/855 completed (loss: 0.059620898216962814):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 83/213 [1:08:17<1:46:52, 49.33s/it]Training Epoch: 1/10, step 331/855 completed (loss: 0.07106432318687439):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 83/213 [1:08:17<1:46:52, 49.33s/it] Training Epoch: 1/10, step 332/855 completed (loss: 0.058636147528886795):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 83/213 [1:08:29<1:46:52, 49.33s/it]Training Epoch: 1/10, step 333/855 completed (loss: 0.05038467422127724):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 83/213 [1:08:41<1:46:52, 49.33s/it] Training Epoch: 1/10, step 334/855 completed (loss: 0.054140716791152954):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 83/213 [1:08:54<1:46:52, 49.33s/it]Training Epoch: 1/10, step 334/855 completed (loss: 0.054140716791152954):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 84/213 [1:09:06<1:46:04, 49.34s/it]Training Epoch: 1/10, step 335/855 completed (loss: 0.07605859637260437):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 84/213 [1:09:06<1:46:04, 49.34s/it] Training Epoch: 1/10, step 336/855 completed (loss: 0.028160886839032173):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 84/213 [1:09:18<1:46:04, 49.34s/it]Training Epoch: 1/10, step 337/855 completed (loss: 0.026256926357746124):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 84/213 [1:09:31<1:46:04, 49.34s/it]Training Epoch: 1/10, step 338/855 completed (loss: 0.029797956347465515):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 84/213 [1:09:43<1:46:04, 49.34s/it]Training Epoch: 1/10, step 338/855 completed (loss: 0.029797956347465515):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 85/213 [1:09:55<1:45:15, 49.34s/it]Training Epoch: 1/10, step 339/855 completed (loss: 0.07034870237112045):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 85/213 [1:09:55<1:45:15, 49.34s/it] Training Epoch: 1/10, step 340/855 completed (loss: 0.08405087888240814):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 85/213 [1:10:08<1:45:15, 49.34s/it]Training Epoch: 1/10, step 341/855 completed (loss: 0.08911476284265518):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 85/213 [1:10:20<1:45:15, 49.34s/it]Training Epoch: 1/10, step 342/855 completed (loss: 0.08337898552417755):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 85/213 [1:10:32<1:45:15, 49.34s/it]Training Epoch: 1/10, step 342/855 completed (loss: 0.08337898552417755):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 86/213 [1:10:45<1:44:26, 49.34s/it]Training Epoch: 1/10, step 343/855 completed (loss: 0.05160607397556305):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 86/213 [1:10:45<1:44:26, 49.34s/it]Training Epoch: 1/10, step 344/855 completed (loss: 0.0825810432434082):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 86/213 [1:10:57<1:44:26, 49.34s/it] Training Epoch: 1/10, step 345/855 completed (loss: 0.04179222136735916):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 86/213 [1:11:09<1:44:26, 49.34s/it]Training Epoch: 1/10, step 346/855 completed (loss: 0.05448554456233978):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 86/213 [1:11:22<1:44:26, 49.34s/it]Training Epoch: 1/10, step 346/855 completed (loss: 0.05448554456233978):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 87/213 [1:11:34<1:43:36, 49.34s/it]Training Epoch: 1/10, step 347/855 completed (loss: 0.08424586057662964):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 87/213 [1:11:34<1:43:36, 49.34s/it]Training Epoch: 1/10, step 348/855 completed (loss: 0.048482026904821396):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 87/213 [1:11:46<1:43:36, 49.34s/it]Training Epoch: 1/10, step 349/855 completed (loss: 0.07535353302955627):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 87/213 [1:11:59<1:43:36, 49.34s/it] Training Epoch: 1/10, step 350/855 completed (loss: 0.0553847998380661):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 87/213 [1:12:11<1:43:36, 49.34s/it] Training Epoch: 1/10, step 350/855 completed (loss: 0.0553847998380661):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 88/213 [1:12:23<1:42:46, 49.33s/it]Training Epoch: 1/10, step 351/855 completed (loss: 0.02836420387029648):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 88/213 [1:12:23<1:42:46, 49.33s/it]Training Epoch: 1/10, step 352/855 completed (loss: 0.050347696989774704):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 88/213 [1:12:36<1:42:46, 49.33s/it]Training Epoch: 1/10, step 353/855 completed (loss: 0.03364000469446182):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 88/213 [1:12:48<1:42:46, 49.33s/it] Training Epoch: 1/10, step 354/855 completed (loss: 0.02914484776556492):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 88/213 [1:13:00<1:42:46, 49.33s/it]Training Epoch: 1/10, step 354/855 completed (loss: 0.02914484776556492):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 89/213 [1:13:13<1:41:57, 49.33s/it]Training Epoch: 1/10, step 355/855 completed (loss: 0.08244182914495468):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 89/213 [1:13:13<1:41:57, 49.33s/it]Training Epoch: 1/10, step 356/855 completed (loss: 0.10977673530578613):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 89/213 [1:13:25<1:41:57, 49.33s/it]Training Epoch: 1/10, step 357/855 completed (loss: 0.029708361253142357):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 89/213 [1:13:37<1:41:57, 49.33s/it]Training Epoch: 1/10, step 358/855 completed (loss: 0.06211014837026596):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 89/213 [1:13:50<1:41:57, 49.33s/it] Training Epoch: 1/10, step 358/855 completed (loss: 0.06211014837026596):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 90/213 [1:14:02<1:41:07, 49.33s/it]Training Epoch: 1/10, step 359/855 completed (loss: 0.045663781464099884):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 90/213 [1:14:02<1:41:07, 49.33s/it]Training Epoch: 1/10, step 360/855 completed (loss: 0.0867403969168663):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 90/213 [1:14:14<1:41:07, 49.33s/it]  Training Epoch: 1/10, step 361/855 completed (loss: 0.040625132620334625):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 90/213 [1:14:27<1:41:07, 49.33s/it]Training Epoch: 1/10, step 362/855 completed (loss: 0.07202772051095963):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 90/213 [1:14:39<1:41:07, 49.33s/it] Training Epoch: 1/10, step 362/855 completed (loss: 0.07202772051095963):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 91/213 [1:14:51<1:40:18, 49.33s/it]Training Epoch: 1/10, step 363/855 completed (loss: 0.05996758118271828):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 91/213 [1:14:51<1:40:18, 49.33s/it]Training Epoch: 1/10, step 364/855 completed (loss: 0.04414095729589462):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 91/213 [1:15:04<1:40:18, 49.33s/it]Training Epoch: 1/10, step 365/855 completed (loss: 0.05851862207055092):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 91/213 [1:15:16<1:40:18, 49.33s/it]Training Epoch: 1/10, step 366/855 completed (loss: 0.04379227012395859):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 91/213 [1:15:28<1:40:18, 49.33s/it]Training Epoch: 1/10, step 366/855 completed (loss: 0.04379227012395859):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 92/213 [1:15:41<1:39:29, 49.33s/it]Training Epoch: 1/10, step 367/855 completed (loss: 0.09563620388507843):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 92/213 [1:15:41<1:39:29, 49.33s/it]Training Epoch: 1/10, step 368/855 completed (loss: 0.0722440779209137):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 92/213 [1:15:53<1:39:29, 49.33s/it] Training Epoch: 1/10, step 369/855 completed (loss: 0.031696125864982605):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 92/213 [1:16:05<1:39:29, 49.33s/it]Training Epoch: 1/10, step 370/855 completed (loss: 0.03468421474099159):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 92/213 [1:16:18<1:39:29, 49.33s/it] Training Epoch: 1/10, step 370/855 completed (loss: 0.03468421474099159):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 93/213 [1:16:30<1:38:40, 49.33s/it]Training Epoch: 1/10, step 371/855 completed (loss: 0.03844407945871353):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 93/213 [1:16:30<1:38:40, 49.33s/it]Training Epoch: 1/10, step 372/855 completed (loss: 0.056582413613796234):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 93/213 [1:16:42<1:38:40, 49.33s/it]Training Epoch: 1/10, step 373/855 completed (loss: 0.055976033210754395):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 93/213 [1:16:55<1:38:40, 49.33s/it]Training Epoch: 1/10, step 374/855 completed (loss: 0.056887153536081314):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 93/213 [1:17:07<1:38:40, 49.33s/it]Training Epoch: 1/10, step 374/855 completed (loss: 0.056887153536081314):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 94/213 [1:17:19<1:37:50, 49.33s/it]Training Epoch: 1/10, step 375/855 completed (loss: 0.05841214954853058):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 94/213 [1:17:19<1:37:50, 49.33s/it] Training Epoch: 1/10, step 376/855 completed (loss: 0.0238125529140234):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 94/213 [1:17:32<1:37:50, 49.33s/it] Training Epoch: 1/10, step 377/855 completed (loss: 0.08641800284385681):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 94/213 [1:17:44<1:37:50, 49.33s/it]Training Epoch: 1/10, step 378/855 completed (loss: 0.08223515748977661):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 94/213 [1:17:56<1:37:50, 49.33s/it]Training Epoch: 1/10, step 378/855 completed (loss: 0.08223515748977661):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 95/213 [1:18:09<1:37:01, 49.34s/it]Training Epoch: 1/10, step 379/855 completed (loss: 0.0900450348854065):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 95/213 [1:18:09<1:37:01, 49.34s/it] Training Epoch: 1/10, step 380/855 completed (loss: 0.008565397933125496):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 95/213 [1:18:21<1:37:01, 49.34s/it]Training Epoch: 1/10, step 381/855 completed (loss: 0.03633219376206398):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 95/213 [1:18:33<1:37:01, 49.34s/it] Training Epoch: 1/10, step 382/855 completed (loss: 0.0593210831284523):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 95/213 [1:18:46<1:37:01, 49.34s/it] Training Epoch: 1/10, step 382/855 completed (loss: 0.0593210831284523):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 96/213 [1:18:58<1:36:11, 49.33s/it]Training Epoch: 1/10, step 383/855 completed (loss: 0.065985769033432):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 96/213 [1:18:58<1:36:11, 49.33s/it] Training Epoch: 1/10, step 384/855 completed (loss: 0.04146171733736992):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 96/213 [1:19:10<1:36:11, 49.33s/it]Training Epoch: 1/10, step 385/855 completed (loss: 0.04769789054989815):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 96/213 [1:19:23<1:36:11, 49.33s/it]Training Epoch: 1/10, step 386/855 completed (loss: 0.033992186188697815):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 96/213 [1:19:35<1:36:11, 49.33s/it]Training Epoch: 1/10, step 386/855 completed (loss: 0.033992186188697815):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 97/213 [1:19:47<1:35:22, 49.33s/it]Training Epoch: 1/10, step 387/855 completed (loss: 0.06591761112213135):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 97/213 [1:19:47<1:35:22, 49.33s/it] Training Epoch: 1/10, step 388/855 completed (loss: 0.0571550689637661):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 97/213 [1:20:00<1:35:22, 49.33s/it] Training Epoch: 1/10, step 389/855 completed (loss: 0.09116825461387634):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 97/213 [1:20:12<1:35:22, 49.33s/it]Training Epoch: 1/10, step 390/855 completed (loss: 0.05699937045574188):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 97/213 [1:20:24<1:35:22, 49.33s/it]Training Epoch: 1/10, step 390/855 completed (loss: 0.05699937045574188):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 98/213 [1:20:37<1:34:32, 49.33s/it]Training Epoch: 1/10, step 391/855 completed (loss: 0.016605136916041374):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 98/213 [1:20:37<1:34:32, 49.33s/it]Training Epoch: 1/10, step 392/855 completed (loss: 0.06877311319112778):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 98/213 [1:20:49<1:34:32, 49.33s/it] Training Epoch: 1/10, step 393/855 completed (loss: 0.02679719775915146):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 98/213 [1:21:01<1:34:32, 49.33s/it]Training Epoch: 1/10, step 394/855 completed (loss: 0.021601632237434387):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 98/213 [1:21:14<1:34:32, 49.33s/it]Training Epoch: 1/10, step 394/855 completed (loss: 0.021601632237434387):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 99/213 [1:21:26<1:33:43, 49.33s/it]Training Epoch: 1/10, step 395/855 completed (loss: 0.014367349445819855):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 99/213 [1:21:26<1:33:43, 49.33s/it]Training Epoch: 1/10, step 396/855 completed (loss: 0.02923031710088253):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 99/213 [1:21:38<1:33:43, 49.33s/it] Training Epoch: 1/10, step 397/855 completed (loss: 0.011932320892810822):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 99/213 [1:21:51<1:33:43, 49.33s/it]Training Epoch: 1/10, step 398/855 completed (loss: 0.026324383914470673):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 99/213 [1:22:03<1:33:43, 49.33s/it]Training Epoch: 1/10, step 398/855 completed (loss: 0.026324383914470673):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 100/213 [1:22:15<1:32:54, 49.33s/it]Training Epoch: 1/10, step 399/855 completed (loss: 0.016348926350474358):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 100/213 [1:22:15<1:32:54, 49.33s/it]Training Epoch: 1/10, step 400/855 completed (loss: 0.06673932820558548):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 100/213 [1:22:28<1:32:54, 49.33s/it] Training Epoch: 1/10, step 401/855 completed (loss: 0.009185099974274635):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 100/213 [1:22:40<1:32:54, 49.33s/it]Training Epoch: 1/10, step 402/855 completed (loss: 0.040441278368234634):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 100/213 [1:22:52<1:32:54, 49.33s/it]Training Epoch: 1/10, step 402/855 completed (loss: 0.040441278368234634):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 101/213 [1:23:05<1:32:05, 49.34s/it]Training Epoch: 1/10, step 403/855 completed (loss: 0.05879189819097519):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 101/213 [1:23:05<1:32:05, 49.34s/it] Training Epoch: 1/10, step 404/855 completed (loss: 0.0007508753333240747):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 101/213 [1:23:17<1:32:05, 49.34s/it]Training Epoch: 1/10, step 405/855 completed (loss: 0.03264215588569641):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 101/213 [1:23:29<1:32:05, 49.34s/it]  Training Epoch: 1/10, step 406/855 completed (loss: 0.03801232948899269):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 101/213 [1:23:42<1:32:05, 49.34s/it]Training Epoch: 1/10, step 406/855 completed (loss: 0.03801232948899269):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 102/213 [1:23:54<1:31:16, 49.34s/it]Training Epoch: 1/10, step 407/855 completed (loss: 0.07109098881483078):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 102/213 [1:23:54<1:31:16, 49.34s/it]Training Epoch: 1/10, step 408/855 completed (loss: 0.01884648948907852):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 102/213 [1:24:06<1:31:16, 49.34s/it]Training Epoch: 1/10, step 409/855 completed (loss: 0.05389277637004852):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 102/213 [1:24:19<1:31:16, 49.34s/it]Training Epoch: 1/10, step 410/855 completed (loss: 0.034805431962013245):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 102/213 [1:24:31<1:31:16, 49.34s/it]Training Epoch: 1/10, step 410/855 completed (loss: 0.034805431962013245):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 103/213 [1:24:43<1:30:27, 49.34s/it]Training Epoch: 1/10, step 411/855 completed (loss: 0.012994889169931412):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 103/213 [1:24:43<1:30:27, 49.34s/it]Training Epoch: 1/10, step 412/855 completed (loss: 0.06665497273206711):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 103/213 [1:24:56<1:30:27, 49.34s/it] Training Epoch: 1/10, step 413/855 completed (loss: 0.0011348624248057604):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 103/213 [1:25:08<1:30:27, 49.34s/it]Training Epoch: 1/10, step 414/855 completed (loss: 0.017021767795085907):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 103/213 [1:25:20<1:30:27, 49.34s/it] Training Epoch: 1/10, step 414/855 completed (loss: 0.017021767795085907):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 104/213 [1:25:33<1:29:39, 49.35s/it]Training Epoch: 1/10, step 415/855 completed (loss: 0.09066224843263626):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 104/213 [1:25:33<1:29:39, 49.35s/it] Training Epoch: 1/10, step 416/855 completed (loss: 0.013665330596268177):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 104/213 [1:25:45<1:29:39, 49.35s/it]Training Epoch: 1/10, step 417/855 completed (loss: 0.012483560480177402):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 104/213 [1:25:58<1:29:39, 49.35s/it]Training Epoch: 1/10, step 418/855 completed (loss: 0.0047143083065748215):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 104/213 [1:26:10<1:29:39, 49.35s/it]Training Epoch: 1/10, step 418/855 completed (loss: 0.0047143083065748215):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 105/213 [1:26:22<1:28:50, 49.35s/it]Training Epoch: 1/10, step 419/855 completed (loss: 0.0005927685415372252):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 105/213 [1:26:22<1:28:50, 49.35s/it]Training Epoch: 1/10, step 420/855 completed (loss: 0.01989194005727768):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 105/213 [1:26:35<1:28:50, 49.35s/it]  Training Epoch: 1/10, step 421/855 completed (loss: 0.003328384133055806):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 105/213 [1:26:47<1:28:50, 49.35s/it]Training Epoch: 1/10, step 422/855 completed (loss: 0.04419442638754845):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 105/213 [1:26:59<1:28:50, 49.35s/it] Training Epoch: 1/10, step 422/855 completed (loss: 0.04419442638754845):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 106/213 [1:27:11<1:28:01, 49.36s/it]Training Epoch: 1/10, step 423/855 completed (loss: 0.04919138550758362):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 106/213 [1:27:12<1:28:01, 49.36s/it]Training Epoch: 1/10, step 424/855 completed (loss: 0.0618206225335598):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 106/213 [1:27:24<1:28:01, 49.36s/it] Training Epoch: 1/10, step 425/855 completed (loss: 0.005645468831062317):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 106/213 [1:27:36<1:28:01, 49.36s/it]Training Epoch: 1/10, step 426/855 completed (loss: 0.01878717914223671):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 106/213 [1:27:49<1:28:01, 49.36s/it] Training Epoch: 1/10, step 426/855 completed (loss: 0.01878717914223671):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 107/213 [1:28:01<1:27:12, 49.37s/it]Training Epoch: 1/10, step 427/855 completed (loss: 0.006525877397507429):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 107/213 [1:28:01<1:27:12, 49.37s/it]Training Epoch: 1/10, step 428/855 completed (loss: 0.021964609622955322):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 107/213 [1:28:13<1:27:12, 49.37s/it]Training Epoch: 1/10, step 429/855 completed (loss: 0.041314609348773956):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 107/213 [1:28:26<1:27:12, 49.37s/it]Training Epoch: 1/10, step 430/855 completed (loss: 0.026651941239833832):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 107/213 [1:28:38<1:27:12, 49.37s/it]Training Epoch: 1/10, step 430/855 completed (loss: 0.026651941239833832):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 108/213 [1:28:50<1:26:23, 49.37s/it]Training Epoch: 1/10, step 431/855 completed (loss: 0.03866482153534889):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 108/213 [1:28:50<1:26:23, 49.37s/it] Training Epoch: 1/10, step 432/855 completed (loss: 0.05153166502714157):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 108/213 [1:29:03<1:26:23, 49.37s/it]Training Epoch: 1/10, step 433/855 completed (loss: 0.02947765775024891):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 108/213 [1:29:15<1:26:23, 49.37s/it]Training Epoch: 1/10, step 434/855 completed (loss: 0.02307824231684208):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 108/213 [1:29:27<1:26:23, 49.37s/it]Training Epoch: 1/10, step 434/855 completed (loss: 0.02307824231684208):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 109/213 [1:29:40<1:25:34, 49.37s/it]Training Epoch: 1/10, step 435/855 completed (loss: 0.09416420757770538):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 109/213 [1:29:40<1:25:34, 49.37s/it]Training Epoch: 1/10, step 436/855 completed (loss: 0.0049909502267837524):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 109/213 [1:29:52<1:25:34, 49.37s/it]Training Epoch: 1/10, step 437/855 completed (loss: 0.08582272380590439):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 109/213 [1:30:04<1:25:34, 49.37s/it]  Training Epoch: 1/10, step 438/855 completed (loss: 0.013789779506623745):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 109/213 [1:30:17<1:25:34, 49.37s/it]Training Epoch: 1/10, step 438/855 completed (loss: 0.013789779506623745):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 110/213 [1:30:29<1:24:45, 49.38s/it]Training Epoch: 1/10, step 439/855 completed (loss: 0.04048915207386017):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 110/213 [1:30:29<1:24:45, 49.38s/it] Training Epoch: 1/10, step 440/855 completed (loss: 0.010028804652392864):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 110/213 [1:30:41<1:24:45, 49.38s/it]Training Epoch: 1/10, step 441/855 completed (loss: 0.03736621141433716):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 110/213 [1:30:54<1:24:45, 49.38s/it] Training Epoch: 1/10, step 442/855 completed (loss: 0.00995689071714878):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 110/213 [1:31:06<1:24:45, 49.38s/it]Training Epoch: 1/10, step 442/855 completed (loss: 0.00995689071714878):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 111/213 [1:31:18<1:23:56, 49.38s/it]Training Epoch: 1/10, step 443/855 completed (loss: 0.0849171057343483):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 111/213 [1:31:18<1:23:56, 49.38s/it] Training Epoch: 1/10, step 444/855 completed (loss: 0.06924854964017868):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 111/213 [1:31:31<1:23:56, 49.38s/it]Training Epoch: 1/10, step 445/855 completed (loss: 0.010035872459411621):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 111/213 [1:31:43<1:23:56, 49.38s/it]Training Epoch: 1/10, step 446/855 completed (loss: 0.007475599180907011):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 111/213 [1:31:55<1:23:56, 49.38s/it]Training Epoch: 1/10, step 446/855 completed (loss: 0.007475599180907011):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 112/213 [1:32:08<1:23:05, 49.37s/it]Training Epoch: 1/10, step 447/855 completed (loss: 0.01825924962759018):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 112/213 [1:32:08<1:23:05, 49.37s/it] Training Epoch: 1/10, step 448/855 completed (loss: 0.028219468891620636):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 112/213 [1:32:20<1:23:05, 49.37s/it]Training Epoch: 1/10, step 449/855 completed (loss: 0.02770189382135868):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 112/213 [1:32:32<1:23:05, 49.37s/it] Training Epoch: 1/10, step 450/855 completed (loss: 0.0010032966965809464):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 112/213 [1:32:45<1:23:05, 49.37s/it]Training Epoch: 1/10, step 450/855 completed (loss: 0.0010032966965809464):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 113/213 [1:32:57<1:22:16, 49.36s/it]Training Epoch: 1/10, step 451/855 completed (loss: 0.01975870318710804):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 113/213 [1:32:57<1:22:16, 49.36s/it]  Training Epoch: 1/10, step 452/855 completed (loss: 0.0213511660695076):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 113/213 [1:33:10<1:22:16, 49.36s/it] Training Epoch: 1/10, step 453/855 completed (loss: 0.018435673788189888):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 113/213 [1:33:22<1:22:16, 49.36s/it]Training Epoch: 1/10, step 454/855 completed (loss: 0.05901039391756058):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 113/213 [1:33:34<1:22:16, 49.36s/it] Training Epoch: 1/10, step 454/855 completed (loss: 0.05901039391756058):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 114/213 [1:33:46<1:21:27, 49.37s/it]Training Epoch: 1/10, step 455/855 completed (loss: 0.056918587535619736):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 114/213 [1:33:47<1:21:27, 49.37s/it]Training Epoch: 1/10, step 456/855 completed (loss: 0.026614295318722725):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 114/213 [1:33:59<1:21:27, 49.37s/it]Training Epoch: 1/10, step 457/855 completed (loss: 0.029293200001120567):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 114/213 [1:34:11<1:21:27, 49.37s/it]Training Epoch: 1/10, step 458/855 completed (loss: 0.018313616514205933):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 114/213 [1:34:24<1:21:27, 49.37s/it]Training Epoch: 1/10, step 458/855 completed (loss: 0.018313616514205933):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 115/213 [1:34:36<1:20:38, 49.38s/it]Training Epoch: 1/10, step 459/855 completed (loss: 0.0255514495074749):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 115/213 [1:34:36<1:20:38, 49.38s/it]  Training Epoch: 1/10, step 460/855 completed (loss: 0.0049942112527787685):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 115/213 [1:34:48<1:20:38, 49.38s/it]Training Epoch: 1/10, step 461/855 completed (loss: 0.04989083856344223):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 115/213 [1:35:01<1:20:38, 49.38s/it]  Training Epoch: 1/10, step 462/855 completed (loss: 0.03988060727715492):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 115/213 [1:35:13<1:20:38, 49.38s/it]Training Epoch: 1/10, step 462/855 completed (loss: 0.03988060727715492):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 116/213 [1:35:25<1:19:49, 49.38s/it]Training Epoch: 1/10, step 463/855 completed (loss: 0.01844157464802265):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 116/213 [1:35:25<1:19:49, 49.38s/it]Training Epoch: 1/10, step 464/855 completed (loss: 0.05256405100226402):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 116/213 [1:35:38<1:19:49, 49.38s/it]Training Epoch: 1/10, step 465/855 completed (loss: 0.013519389554858208):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 116/213 [1:35:50<1:19:49, 49.38s/it]Training Epoch: 1/10, step 466/855 completed (loss: 0.05680302903056145):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 116/213 [1:36:02<1:19:49, 49.38s/it] Training Epoch: 1/10, step 466/855 completed (loss: 0.05680302903056145):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 117/213 [1:36:15<1:19:00, 49.38s/it]Training Epoch: 1/10, step 467/855 completed (loss: 0.10351089388132095):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 117/213 [1:36:15<1:19:00, 49.38s/it]Training Epoch: 1/10, step 468/855 completed (loss: 0.06314599514007568):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 117/213 [1:36:27<1:19:00, 49.38s/it]Training Epoch: 1/10, step 469/855 completed (loss: 0.029644805938005447):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 117/213 [1:36:39<1:19:00, 49.38s/it]Training Epoch: 1/10, step 470/855 completed (loss: 0.13644596934318542):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 117/213 [1:36:52<1:19:00, 49.38s/it] Training Epoch: 1/10, step 470/855 completed (loss: 0.13644596934318542):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 118/213 [1:37:04<1:18:10, 49.37s/it]Training Epoch: 1/10, step 471/855 completed (loss: 0.007326488848775625):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 118/213 [1:37:04<1:18:10, 49.37s/it]Training Epoch: 1/10, step 472/855 completed (loss: 0.05220654234290123):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 118/213 [1:37:16<1:18:10, 49.37s/it] Training Epoch: 1/10, step 473/855 completed (loss: 0.012936017476022243):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 118/213 [1:37:29<1:18:10, 49.37s/it]Training Epoch: 1/10, step 474/855 completed (loss: 0.013180599547922611):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 118/213 [1:37:41<1:18:10, 49.37s/it]Training Epoch: 1/10, step 474/855 completed (loss: 0.013180599547922611):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 119/213 [1:37:53<1:17:20, 49.37s/it]Training Epoch: 1/10, step 475/855 completed (loss: 0.004008172079920769):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 119/213 [1:37:53<1:17:20, 49.37s/it]Training Epoch: 1/10, step 476/855 completed (loss: 0.07578972727060318):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 119/213 [1:38:06<1:17:20, 49.37s/it] Training Epoch: 1/10, step 477/855 completed (loss: 0.008878197520971298):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 119/213 [1:38:18<1:17:20, 49.37s/it]Training Epoch: 1/10, step 478/855 completed (loss: 0.017646031454205513):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 119/213 [1:38:30<1:17:20, 49.37s/it]Training Epoch: 1/10, step 478/855 completed (loss: 0.017646031454205513):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 120/213 [1:38:43<1:16:31, 49.37s/it]Training Epoch: 1/10, step 479/855 completed (loss: 0.013131145387887955):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 120/213 [1:38:43<1:16:31, 49.37s/it]Training Epoch: 1/10, step 480/855 completed (loss: 0.04119933396577835):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 120/213 [1:38:55<1:16:31, 49.37s/it] Training Epoch: 1/10, step 481/855 completed (loss: 0.049076225608587265):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 120/213 [1:39:07<1:16:31, 49.37s/it]Training Epoch: 1/10, step 482/855 completed (loss: 0.041068900376558304):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 120/213 [1:39:20<1:16:31, 49.37s/it]Training Epoch: 1/10, step 482/855 completed (loss: 0.041068900376558304):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 121/213 [1:39:32<1:15:41, 49.36s/it]Training Epoch: 1/10, step 483/855 completed (loss: 0.012792268767952919):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 121/213 [1:39:32<1:15:41, 49.36s/it]Training Epoch: 1/10, step 484/855 completed (loss: 0.005128339398652315):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 121/213 [1:39:44<1:15:41, 49.36s/it]Training Epoch: 1/10, step 485/855 completed (loss: 0.07044121623039246):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 121/213 [1:39:57<1:15:41, 49.36s/it] Training Epoch: 1/10, step 486/855 completed (loss: 0.01905687339603901):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 121/213 [1:40:09<1:15:41, 49.36s/it]Training Epoch: 1/10, step 486/855 completed (loss: 0.01905687339603901):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 122/213 [1:40:21<1:14:50, 49.35s/it]Training Epoch: 1/10, step 487/855 completed (loss: 0.004734639078378677):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 122/213 [1:40:21<1:14:50, 49.35s/it]Training Epoch: 1/10, step 488/855 completed (loss: 0.007610468193888664):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 122/213 [1:40:34<1:14:50, 49.35s/it]Training Epoch: 1/10, step 489/855 completed (loss: 0.06479117274284363):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 122/213 [1:40:46<1:14:50, 49.35s/it] Training Epoch: 1/10, step 490/855 completed (loss: 0.0448000505566597):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 122/213 [1:40:58<1:14:50, 49.35s/it] Training Epoch: 1/10, step 490/855 completed (loss: 0.0448000505566597):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 123/213 [1:41:11<1:14:01, 49.34s/it]Training Epoch: 1/10, step 491/855 completed (loss: 0.034398965537548065):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 123/213 [1:41:11<1:14:01, 49.34s/it]