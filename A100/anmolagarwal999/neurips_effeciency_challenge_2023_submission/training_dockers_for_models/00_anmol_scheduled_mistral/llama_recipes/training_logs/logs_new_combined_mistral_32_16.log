Starting time is:  2023-10-25 15:33:36 IST+0530
RANDOM STRING is:  2a14e64a-04ba-401a-b35a-9ed575f46c72
REPO DECIDED is:  anmolagarwal999/nips_challenge_2a14e64a-04ba-401a-b35a-9ed575f46c72
Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.
Token is valid (permission: write).
Your token has been saved to /home/t-agarwalan/.cache/huggingface/token
Login successful
Total gradient accumulation steps are:  2
OUTPUT dir is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72
Custom dataset path is:  train.py
Going to begin finetuning
Python env is:  wizard_coder_inference
Script path is:  /home/t-agarwalan/Desktop/nips_effeciency_challenge/EfficiencyChallenge/code/00_starter_repo/neurips_llm_efficiency_challenge/sample-submissions/llama_recipes/llama_recipes_external_code/src/llama_recipes/finetuning.py
KWARGS sent to main() are:  {'model_name': 'mistralai/Mistral-7B-v0.1', 'use_peft': True, 'peft_method': 'lora', 'quantization': True, 'batch_size_training': 16, 'gradient_accumulation_steps': 2, 'dataset': 'custom_dataset', 'custom_dataset.file': 'train.py:get_anmol_dataset', 'output_dir': './models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72'}
Inside update config file
Inside update config file
Inside update config file
Anmol: The final config after all the updations is:  <class 'llama_recipes.configs.training.train_config'>
Train config seed is:  42
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.28s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:04<00:00,  2.42s/it]
/anaconda/envs/wizard_coder_inference/lib/python3.8/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
/anaconda/envs/wizard_coder_inference/lib/python3.8/site-packages/torch/cuda/memory.py:303: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
--> Model mistralai/Mistral-7B-v0.1

--> mistralai/Mistral-7B-v0.1 has 262.41024 Million params

Anmol: preparing model for int8 training
Tokenizer has been loaded:  LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<PAD>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={
	0: AddedToken("<unk>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	1: AddedToken("<s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	2: AddedToken("</s>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
	32000: AddedToken("<PAD>", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),
}
Inside update config file
PEFT config is:  LoraConfig(peft_type=<PeftType.LORA: 'LORA'>, auto_mapping=None, base_model_name_or_path=None, revision=None, task_type='CAUSAL_LM', inference_mode=False, r=8, target_modules=['q_proj', 'v_proj'], lora_alpha=32, lora_dropout=0.05, fan_in_fan_out=False, bias='none', modules_to_save=None, init_lora_weights=True, layers_to_transform=None, layers_pattern=None)
trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836
Inside update config file
Dataset config is:  custom_dataset(dataset='custom_dataset', file='train.py:get_anmol_dataset', train_split='train', test_split='validation')
Starting time is:  2023-10-25 15:33:46 IST+0530
RANDOM STRING is:  1dffc25a-f840-43f4-81c2-c2f47e7d08ac
REPO DECIDED is:  anmolagarwal999/nips_challenge_1dffc25a-f840-43f4-81c2-c2f47e7d08ac
Ending time is:  2023-10-25 15:33:46 IST+0530
INSIDE INIT FUNCTION for partition:  train
TRAIN PATH is:  /home/t-agarwalan/Desktop/nips_effeciency_challenge/EfficiencyChallenge/data/training_datasets/training_datasets/combined_train_dataset.json
Initial len is:  6548
Final len is:  6494
MAX WORDS in dataset is:  1078
Anmol: Enable FSDP val is:  False
--> Training Set Length = 5519
Starting time is:  2023-10-25 15:33:49 IST+0530
RANDOM STRING is:  e834f4d2-4065-432d-ad51-e01e90c322fb
REPO DECIDED is:  anmolagarwal999/nips_challenge_e834f4d2-4065-432d-ad51-e01e90c322fb
Ending time is:  2023-10-25 15:33:49 IST+0530
INSIDE INIT FUNCTION for partition:  validation
TRAIN PATH is:  /home/t-agarwalan/Desktop/nips_effeciency_challenge/EfficiencyChallenge/data/training_datasets/training_datasets/combined_train_dataset.json
Initial len is:  6548
Final len is:  6494
MAX WORDS in dataset is:  1078
--> Validation Set Length = 975
Initializaing the optimizer and scheduler
Training config is:  <class 'llama_recipes.configs.training.train_config'>
Going to start the training process.
Model is:  PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): MistralForCausalLM(
      (model): MistralModel(
        (embed_tokens): Embedding(32000, 4096)
        (layers): ModuleList(
          (0-31): 32 x MistralDecoderLayer(
            (self_attn): MistralAttention(
              (q_proj): Linear8bitLt(
                in_features=4096, out_features=4096, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=4096, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (k_proj): Linear8bitLt(in_features=4096, out_features=1024, bias=False)
              (v_proj): Linear8bitLt(
                in_features=4096, out_features=1024, bias=False
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.05, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=4096, out_features=8, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=8, out_features=1024, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
              )
              (o_proj): Linear8bitLt(in_features=4096, out_features=4096, bias=False)
              (rotary_emb): MistralRotaryEmbedding()
            )
            (mlp): MistralMLP(
              (gate_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)
              (up_proj): Linear8bitLt(in_features=4096, out_features=14336, bias=False)
              (down_proj): Linear8bitLt(in_features=14336, out_features=4096, bias=False)
              (act_fn): SiLUActivation()
            )
            (input_layernorm): MistralRMSNorm()
            (post_attention_layernorm): MistralRMSNorm()
          )
        )
        (norm): MistralRMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
Training config received is:  <class 'llama_recipes.configs.training.train_config'>
Use fp16 has been set to:  False
Epoch starting time:  2023-10-25 15:33:51 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 0:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
/anaconda/envs/wizard_coder_inference/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
Training Epoch: 0/12, completed (loss: 2.7458720207214355):   0%|[34m          [0m| 0/172 [00:17<?, ?it/s]Training Epoch: 0/12, completed (loss: 2.7458720207214355):   1%|[34m          [0m| 1/172 [00:31<1:29:54, 31.54s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 0, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:48,  7.88s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:36,  7.73s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:26,  7.66s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:30<03:21,  7.74s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:38<03:13,  7.75s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:06,  7.79s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:58,  7.76s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:50,  7.75s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:09<02:42,  7.75s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:17<02:35,  7.76s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:25<02:27,  7.78s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:33<02:19,  7.76s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:41<02:13,  7.83s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:48<02:05,  7.84s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:56<01:57,  7.83s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:04<01:49,  7.79s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:12<01:41,  7.81s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:20<01:33,  7.82s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:28<01:26,  7.85s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:35<01:18,  7.84s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:43<01:10,  7.80s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:51<01:02,  7.80s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [02:59<00:54,  7.82s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:07<00:46,  7.82s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:14<00:39,  7.83s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:22<00:31,  7.80s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:30<00:23,  7.82s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:38<00:15,  7.84s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:46<00:07,  7.84s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:54<00:00,  7.83s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:54<00:00,  7.80s/it]
Training Epoch: 0/12, completed (loss: 0.7136865258216858):   1%|[34m          [0m| 1/172 [04:25<1:29:54, 31.54s/it]Training Epoch: 0/12, completed (loss: 2.0897254943847656):   1%|[34m          [0m| 1/172 [04:40<1:29:54, 31.54s/it]Training Epoch: 0/12, completed (loss: 2.0897254943847656):   1%|[34m          [0m| 2/172 [04:55<7:56:05, 168.04s/it]Training Epoch: 0/12, completed (loss: 0.7460970282554626):   1%|[34m          [0m| 2/172 [04:55<7:56:05, 168.04s/it]Training Epoch: 0/12, completed (loss: 1.3425511121749878):   1%|[34m          [0m| 2/172 [05:09<7:56:05, 168.04s/it]Training Epoch: 0/12, completed (loss: 1.3425511121749878):   2%|[34mâ–         [0m| 3/172 [05:24<4:55:03, 104.75s/it]Training Epoch: 0/12, completed (loss: 1.0602422952651978):   2%|[34mâ–         [0m| 3/172 [05:24<4:55:03, 104.75s/it]Training Epoch: 0/12, completed (loss: 1.1790927648544312):   2%|[34mâ–         [0m| 3/172 [05:39<4:55:03, 104.75s/it]Training Epoch: 0/12, completed (loss: 1.1790927648544312):   2%|[34mâ–         [0m| 4/172 [05:53<3:29:32, 74.84s/it] Training Epoch: 0/12, completed (loss: 0.8682965040206909):   2%|[34mâ–         [0m| 4/172 [05:53<3:29:32, 74.84s/it]Training Epoch: 0/12, completed (loss: 0.8492215871810913):   2%|[34mâ–         [0m| 4/172 [06:08<3:29:32, 74.84s/it]Training Epoch: 0/12, completed (loss: 0.8492215871810913):   3%|[34mâ–Ž         [0m| 5/172 [06:22<2:42:31, 58.39s/it]Training Epoch: 0/12, completed (loss: 0.8391115665435791):   3%|[34mâ–Ž         [0m| 5/172 [06:22<2:42:31, 58.39s/it]Training Epoch: 0/12, completed (loss: 0.6551378965377808):   3%|[34mâ–Ž         [0m| 5/172 [06:37<2:42:31, 58.39s/it]Training Epoch: 0/12, completed (loss: 0.6551378965377808):   3%|[34mâ–Ž         [0m| 6/172 [06:51<2:13:50, 48.37s/it]Training Epoch: 0/12, completed (loss: 0.7031250596046448):   3%|[34mâ–Ž         [0m| 6/172 [06:51<2:13:50, 48.37s/it]Training Epoch: 0/12, completed (loss: 0.7069759368896484):   3%|[34mâ–Ž         [0m| 6/172 [07:06<2:13:50, 48.37s/it]Training Epoch: 0/12, completed (loss: 0.7069759368896484):   4%|[34mâ–         [0m| 7/172 [07:20<1:55:51, 42.13s/it]Training Epoch: 0/12, completed (loss: 0.222605362534523):   4%|[34mâ–         [0m| 7/172 [07:21<1:55:51, 42.13s/it] Training Epoch: 0/12, completed (loss: 0.43199920654296875):   4%|[34mâ–         [0m| 7/172 [07:35<1:55:51, 42.13s/it]Training Epoch: 0/12, completed (loss: 0.43199920654296875):   5%|[34mâ–         [0m| 8/172 [07:50<1:43:50, 37.99s/it]Training Epoch: 0/12, completed (loss: 0.5197819471359253):   5%|[34mâ–         [0m| 8/172 [07:50<1:43:50, 37.99s/it] Training Epoch: 0/12, completed (loss: 0.4581608474254608):   5%|[34mâ–         [0m| 8/172 [08:05<1:43:50, 37.99s/it]Training Epoch: 0/12, completed (loss: 0.4581608474254608):   5%|[34mâ–Œ         [0m| 9/172 [08:19<1:35:54, 35.30s/it]Training Epoch: 0/12, completed (loss: 0.5023194551467896):   5%|[34mâ–Œ         [0m| 9/172 [08:19<1:35:54, 35.30s/it]Training Epoch: 0/12, completed (loss: 0.2658993899822235):   5%|[34mâ–Œ         [0m| 9/172 [08:34<1:35:54, 35.30s/it]Training Epoch: 0/12, completed (loss: 0.2658993899822235):   6%|[34mâ–Œ         [0m| 10/172 [08:48<1:29:55, 33.30s/it]Training Epoch: 0/12, completed (loss: 0.30889692902565):   6%|[34mâ–Œ         [0m| 10/172 [08:48<1:29:55, 33.30s/it]  Training Epoch: 0/12, completed (loss: 0.40645790100097656):   6%|[34mâ–Œ         [0m| 10/172 [09:02<1:29:55, 33.30s/it]Training Epoch: 0/12, completed (loss: 0.40645790100097656):   6%|[34mâ–‹         [0m| 11/172 [09:17<1:25:51, 32.00s/it]Training Epoch: 0/12, completed (loss: 0.40092167258262634):   6%|[34mâ–‹         [0m| 11/172 [09:17<1:25:51, 32.00s/it]Training Epoch: 0/12, completed (loss: 0.361096054315567):   6%|[34mâ–‹         [0m| 11/172 [09:32<1:25:51, 32.00s/it]  Training Epoch: 0/12, completed (loss: 0.361096054315567):   7%|[34mâ–‹         [0m| 12/172 [09:46<1:22:55, 31.10s/it]Training Epoch: 0/12, completed (loss: 0.38976243138313293):   7%|[34mâ–‹         [0m| 12/172 [09:46<1:22:55, 31.10s/it]Training Epoch: 0/12, completed (loss: 0.3359350562095642):   7%|[34mâ–‹         [0m| 12/172 [10:01<1:22:55, 31.10s/it] Training Epoch: 0/12, completed (loss: 0.3359350562095642):   8%|[34mâ–Š         [0m| 13/172 [10:15<1:20:44, 30.47s/it]Training Epoch: 0/12, completed (loss: 0.1829172968864441):   8%|[34mâ–Š         [0m| 13/172 [10:15<1:20:44, 30.47s/it]Training Epoch: 0/12, completed (loss: 0.5353183150291443):   8%|[34mâ–Š         [0m| 13/172 [10:30<1:20:44, 30.47s/it]Training Epoch: 0/12, completed (loss: 0.5353183150291443):   8%|[34mâ–Š         [0m| 14/172 [10:44<1:19:12, 30.08s/it]Training Epoch: 0/12, completed (loss: 0.5153796076774597):   8%|[34mâ–Š         [0m| 14/172 [10:44<1:19:12, 30.08s/it]Training Epoch: 0/12, completed (loss: 0.29585617780685425):   8%|[34mâ–Š         [0m| 14/172 [10:59<1:19:12, 30.08s/it]Training Epoch: 0/12, completed (loss: 0.29585617780685425):   9%|[34mâ–Š         [0m| 15/172 [11:13<1:17:53, 29.77s/it]Training Epoch: 0/12, completed (loss: 0.296171098947525):   9%|[34mâ–Š         [0m| 15/172 [11:13<1:17:53, 29.77s/it]  Training Epoch: 0/12, completed (loss: 0.3772839307785034):   9%|[34mâ–Š         [0m| 15/172 [11:28<1:17:53, 29.77s/it]Training Epoch: 0/12, completed (loss: 0.3772839307785034):   9%|[34mâ–‰         [0m| 16/172 [11:42<1:17:02, 29.63s/it]Training Epoch: 0/12, completed (loss: 0.37537553906440735):   9%|[34mâ–‰         [0m| 16/172 [11:43<1:17:02, 29.63s/it]Training Epoch: 0/12, completed (loss: 0.46550002694129944):   9%|[34mâ–‰         [0m| 16/172 [11:57<1:17:02, 29.63s/it]Training Epoch: 0/12, completed (loss: 0.46550002694129944):  10%|[34mâ–‰         [0m| 17/172 [12:12<1:16:12, 29.50s/it]Training Epoch: 0/12, completed (loss: 0.3255937099456787):  10%|[34mâ–‰         [0m| 17/172 [12:12<1:16:12, 29.50s/it] Training Epoch: 0/12, completed (loss: 0.40685638785362244):  10%|[34mâ–‰         [0m| 17/172 [12:26<1:16:12, 29.50s/it]Training Epoch: 0/12, completed (loss: 0.40685638785362244):  10%|[34mâ–ˆ         [0m| 18/172 [12:41<1:15:18, 29.34s/it]Training Epoch: 0/12, completed (loss: 0.2656131386756897):  10%|[34mâ–ˆ         [0m| 18/172 [12:41<1:15:18, 29.34s/it] Training Epoch: 0/12, completed (loss: 0.3339729607105255):  10%|[34mâ–ˆ         [0m| 18/172 [12:56<1:15:18, 29.34s/it]Training Epoch: 0/12, completed (loss: 0.3339729607105255):  11%|[34mâ–ˆ         [0m| 19/172 [13:10<1:14:35, 29.25s/it]Training Epoch: 0/12, completed (loss: 0.19456665217876434):  11%|[34mâ–ˆ         [0m| 19/172 [13:10<1:14:35, 29.25s/it]Training Epoch: 0/12, completed (loss: 0.49251797795295715):  11%|[34mâ–ˆ         [0m| 19/172 [13:25<1:14:35, 29.25s/it]Training Epoch: 0/12, completed (loss: 0.49251797795295715):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:39<1:13:52, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.15185758471488953):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:39<1:13:52, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.3935539126396179):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:53<1:13:52, 29.16s/it] Training Epoch: 0/12, completed (loss: 0.3935539126396179):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:08<1:13:23, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.20306353271007538):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:08<1:13:23, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.18924228847026825):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:23<1:13:23, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.18924228847026825):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:37<1:12:54, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.9139838218688965):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:37<1:12:54, 29.16s/it] Training Epoch: 0/12, completed (loss: 0.7103124856948853):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:52<1:12:54, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.7103124856948853):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:06<1:12:28, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.523906946182251):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:06<1:12:28, 29.19s/it] Training Epoch: 0/12, completed (loss: 0.5619435906410217):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:21<1:12:28, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.5619435906410217):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:35<1:11:56, 29.17s/it]Training Epoch: 0/12, completed (loss: 0.5205667018890381):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:36<1:11:56, 29.17s/it]Training Epoch: 0/12, completed (loss: 0.20207467675209045):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:50<1:11:56, 29.17s/it]Training Epoch: 0/12, completed (loss: 0.20207467675209045):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:04<1:11:20, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.13672181963920593):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:05<1:11:20, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.3270888328552246):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:19<1:11:20, 29.12s/it] Training Epoch: 0/12, completed (loss: 0.3270888328552246):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:33<1:10:46, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.35814368724823):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:34<1:10:46, 29.09s/it]  Training Epoch: 0/12, completed (loss: 0.2546193599700928):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:48<1:10:46, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.2546193599700928):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:02<1:10:13, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.45841899514198303):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:03<1:10:13, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.34171292185783386):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:17<1:10:13, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.34171292185783386):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:31<1:09:45, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.3536504805088043):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:32<1:09:45, 29.07s/it] Training Epoch: 0/12, completed (loss: 0.5483481884002686):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:46<1:09:45, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.5483481884002686):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:00<1:09:16, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.2695138156414032):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:01<1:09:16, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.3888229429721832):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:15<1:09:16, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.3888229429721832):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:29<1:08:43, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.49238044023513794):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:30<1:08:43, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.19388681650161743):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:44<1:08:43, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.19388681650161743):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [18:58<1:08:13, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.4062367379665375):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [18:59<1:08:13, 29.03s/it] Training Epoch: 0/12, completed (loss: 0.3500222861766815):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:13<1:08:13, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.3500222861766815):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:28<1:07:46, 29.05s/it]Training Epoch: 0/12, completed (loss: 0.21177038550376892):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:28<1:07:46, 29.05s/it]Training Epoch: 0/12, completed (loss: 0.25558730959892273):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:42<1:07:46, 29.05s/it]Training Epoch: 0/12, completed (loss: 0.25558730959892273):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [19:56<1:07:12, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.32196611166000366):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [19:57<1:07:12, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.5406093001365662):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:11<1:07:12, 29.01s/it] Training Epoch: 0/12, completed (loss: 0.5406093001365662):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:25<1:06:43, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.5603748559951782):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:26<1:06:43, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.42803776264190674):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:40<1:06:43, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.42803776264190674):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [20:55<1:06:15, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.18896634876728058):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [20:55<1:06:15, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.2640223205089569):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:09<1:06:15, 29.02s/it] Training Epoch: 0/12, completed (loss: 0.2640223205089569):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:24<1:05:51, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.2665655016899109):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:24<1:05:51, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.2937215268611908):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:38<1:05:51, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.2937215268611908):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [21:53<1:05:24, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.2587493658065796):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [21:53<1:05:24, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.32366326451301575):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:07<1:05:24, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.32366326451301575):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:22<1:04:45, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.06350661814212799):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:22<1:04:45, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.49177083373069763):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:36<1:04:45, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.49177083373069763):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:51<1:04:18, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.30968302488327026):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:51<1:04:18, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.38569557666778564):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:05<1:04:18, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.38569557666778564):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:20<1:03:47, 28.99s/it]Training Epoch: 0/12, completed (loss: 0.36086440086364746):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:20<1:03:47, 28.99s/it]Training Epoch: 0/12, completed (loss: 0.3770623505115509):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:34<1:03:47, 28.99s/it] Training Epoch: 0/12, completed (loss: 0.3770623505115509):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:49<1:03:23, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.3475130498409271):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:49<1:03:23, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.1164628267288208):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:04<1:03:23, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.1164628267288208):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:18<1:02:55, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.2564736008644104):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:18<1:02:55, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.2562655508518219):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:32<1:02:55, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.2562655508518219):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:47<1:02:23, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.2440965175628662):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:47<1:02:23, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.6244413256645203):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:02<1:02:23, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.6244413256645203):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:16<1:01:53, 29.01s/it] eval_ppl=tensor(13.9574, device='cuda:0') eval_epoch_loss=tensor(2.6360, device='cuda:0')
Eval epoch loss:  tensor(2.6360, device='cuda:0') | best_val_loss:  inf
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_0_1
Time while saving:  2023-10-25 15:38:17 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 0 and 1 is 2.6360068321228027
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 0, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:46,  7.80s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:37,  7.76s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:28,  7.72s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:30<03:20,  7.72s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:38<03:13,  7.74s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:06,  7.77s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:57,  7.74s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:01<02:50,  7.74s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:09<02:42,  7.75s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:17<02:35,  7.76s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:25<02:27,  7.77s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:32<02:19,  7.74s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:40<02:12,  7.77s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:48<02:04,  7.78s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:56<01:57,  7.81s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:04<01:48,  7.77s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:12<01:41,  7.80s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:19<01:33,  7.77s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:27<01:25,  7.77s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:35<01:17,  7.78s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:43<01:09,  7.76s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:50<01:01,  7.74s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [02:58<00:54,  7.78s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:06<00:46,  7.81s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:14<00:39,  7.80s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:21<00:31,  7.78s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:29<00:23,  7.82s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:37<00:15,  7.84s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:45<00:07,  7.82s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:53<00:00,  7.82s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:53<00:00,  7.78s/it]
Training Epoch: 0/12, completed (loss: 0.5174687504768372):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:09<1:01:53, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.3718673884868622):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:24<1:01:53, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.3718673884868622):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:38<3:29:36, 99.03s/it]Training Epoch: 0/12, completed (loss: 0.1706404983997345):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:38<3:29:36, 99.03s/it]Training Epoch: 0/12, completed (loss: 0.4054725170135498):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:53<3:29:36, 99.03s/it]Training Epoch: 0/12, completed (loss: 0.4054725170135498):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:07<2:43:39, 77.93s/it]Training Epoch: 0/12, completed (loss: 0.17249858379364014):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:07<2:43:39, 77.93s/it]Training Epoch: 0/12, completed (loss: 0.3764123022556305):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:22<2:43:39, 77.93s/it] Training Epoch: 0/12, completed (loss: 0.3764123022556305):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:36<2:11:52, 63.30s/it]Training Epoch: 0/12, completed (loss: 0.25166791677474976):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:36<2:11:52, 63.30s/it]Training Epoch: 0/12, completed (loss: 0.3926476240158081):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:51<2:11:52, 63.30s/it] Training Epoch: 0/12, completed (loss: 0.3926476240158081):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:05<1:49:32, 53.00s/it]Training Epoch: 0/12, completed (loss: 0.19951389729976654):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:05<1:49:32, 53.00s/it]Training Epoch: 0/12, completed (loss: 0.27809232473373413):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:20<1:49:32, 53.00s/it]Training Epoch: 0/12, completed (loss: 0.27809232473373413):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:34<1:33:51, 45.78s/it]Training Epoch: 0/12, completed (loss: 0.09063336253166199):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:34<1:33:51, 45.78s/it]Training Epoch: 0/12, completed (loss: 0.498471736907959):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:49<1:33:51, 45.78s/it]  Training Epoch: 0/12, completed (loss: 0.498471736907959):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:03<1:22:50, 40.74s/it]Training Epoch: 0/12, completed (loss: 0.33613020181655884):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:03<1:22:50, 40.74s/it]Training Epoch: 0/12, completed (loss: 0.47523394227027893):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:18<1:22:50, 40.74s/it]Training Epoch: 0/12, completed (loss: 0.47523394227027893):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:32<1:14:59, 37.18s/it]Training Epoch: 0/12, completed (loss: 0.15166079998016357):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:32<1:14:59, 37.18s/it]Training Epoch: 0/12, completed (loss: 0.3981921374797821):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:47<1:14:59, 37.18s/it] Training Epoch: 0/12, completed (loss: 0.3981921374797821):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:01<1:09:37, 34.82s/it]Training Epoch: 0/12, completed (loss: 0.3049677908420563):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:01<1:09:37, 34.82s/it]Training Epoch: 0/12, completed (loss: 0.45016586780548096):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:16<1:09:37, 34.82s/it]Training Epoch: 0/12, completed (loss: 0.45016586780548096):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:30<1:05:36, 33.08s/it]Training Epoch: 0/12, completed (loss: 0.225315660238266):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:30<1:05:36, 33.08s/it]  Training Epoch: 0/12, completed (loss: 0.25357285141944885):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:45<1:05:36, 33.08s/it]Training Epoch: 0/12, completed (loss: 0.25357285141944885):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [33:59<1:02:36, 31.84s/it]Training Epoch: 0/12, completed (loss: 0.14573660492897034):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [33:59<1:02:36, 31.84s/it]Training Epoch: 0/12, completed (loss: 0.4446488916873932):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:14<1:02:36, 31.84s/it] Training Epoch: 0/12, completed (loss: 0.4446488916873932):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:28<1:00:25, 30.98s/it]Training Epoch: 0/12, completed (loss: 0.22970379889011383):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:28<1:00:25, 30.98s/it]Training Epoch: 0/12, completed (loss: 0.15553754568099976):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:43<1:00:25, 30.98s/it]Training Epoch: 0/12, completed (loss: 0.15553754568099976):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [34:57<58:46, 30.40s/it]  Training Epoch: 0/12, completed (loss: 0.45731276273727417):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [34:57<58:46, 30.40s/it]Training Epoch: 0/12, completed (loss: 0.2841443419456482):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:12<58:46, 30.40s/it] Training Epoch: 0/12, completed (loss: 0.2841443419456482):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:26<57:32, 30.02s/it]Training Epoch: 0/12, completed (loss: 0.3369622826576233):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:26<57:32, 30.02s/it]Training Epoch: 0/12, completed (loss: 0.07564548403024673):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:41<57:32, 30.02s/it]Training Epoch: 0/12, completed (loss: 0.07564548403024673):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [35:55<56:29, 29.73s/it]Training Epoch: 0/12, completed (loss: 0.46621841192245483):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [35:55<56:29, 29.73s/it]Training Epoch: 0/12, completed (loss: 0.42666539549827576):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:10<56:29, 29.73s/it]Training Epoch: 0/12, completed (loss: 0.42666539549827576):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:25<55:44, 29.59s/it]Training Epoch: 0/12, completed (loss: 0.2858847975730896):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:25<55:44, 29.59s/it] Training Epoch: 0/12, completed (loss: 0.28549709916114807):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:39<55:44, 29.59s/it]Training Epoch: 0/12, completed (loss: 0.28549709916114807):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [36:53<54:51, 29.39s/it]Training Epoch: 0/12, completed (loss: 0.16932560503482819):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [36:54<54:51, 29.39s/it]Training Epoch: 0/12, completed (loss: 0.5372422337532043):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:08<54:51, 29.39s/it] Training Epoch: 0/12, completed (loss: 0.5372422337532043):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:23<54:16, 29.34s/it]Training Epoch: 0/12, completed (loss: 0.12391648441553116):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:23<54:16, 29.34s/it]Training Epoch: 0/12, completed (loss: 0.11485247313976288):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:38<54:16, 29.34s/it]Training Epoch: 0/12, completed (loss: 0.11485247313976288):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [37:52<53:44, 29.32s/it]Training Epoch: 0/12, completed (loss: 0.415193110704422):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [37:52<53:44, 29.32s/it]  Training Epoch: 0/12, completed (loss: 0.569448709487915):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:07<53:44, 29.32s/it]Training Epoch: 0/12, completed (loss: 0.569448709487915):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:21<53:03, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.6009057760238647):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:21<53:03, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.1942911148071289):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:36<53:03, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.1942911148071289):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [38:50<52:35, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.2508437931537628):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [38:50<52:35, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.31168878078460693):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:05<52:35, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.31168878078460693):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:19<52:03, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.20337146520614624):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:19<52:03, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.48303574323654175):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:34<52:03, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.48303574323654175):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [39:48<51:31, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.3378913104534149):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [39:49<51:31, 29.16s/it] Training Epoch: 0/12, completed (loss: 0.3396994471549988):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:03<51:31, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.3396994471549988):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:17<51:01, 29.15s/it]Training Epoch: 0/12, completed (loss: 0.2706947326660156):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:18<51:01, 29.15s/it]Training Epoch: 0/12, completed (loss: 0.21160417795181274):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:32<51:01, 29.15s/it]Training Epoch: 0/12, completed (loss: 0.21160417795181274):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [40:47<50:30, 29.14s/it]Training Epoch: 0/12, completed (loss: 0.23854462802410126):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [40:47<50:30, 29.14s/it]Training Epoch: 0/12, completed (loss: 0.5190877914428711):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:01<50:30, 29.14s/it] Training Epoch: 0/12, completed (loss: 0.5190877914428711):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:16<49:56, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.19262348115444183):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:16<49:56, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.3462018072605133):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:30<49:56, 29.09s/it] Training Epoch: 0/12, completed (loss: 0.3462018072605133):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [41:45<49:30, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.6472399830818176):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [41:45<49:30, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.2272038757801056):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:00<49:30, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.2272038757801056):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:14<49:02, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.48960864543914795):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:14<49:02, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.3486331105232239):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:29<49:02, 29.13s/it] Training Epoch: 0/12, completed (loss: 0.3486331105232239):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [42:43<48:29, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.31164950132369995):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [42:43<48:29, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.41566359996795654):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [42:58<48:29, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.41566359996795654):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:12<48:03, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.1088971346616745):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:12<48:03, 29.13s/it] Training Epoch: 0/12, completed (loss: 0.3856649696826935):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:27<48:03, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.3856649696826935):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [43:41<47:28, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.3696155250072479):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [43:41<47:28, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.35845062136650085):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [43:56<47:28, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.35845062136650085):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:10<46:59, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.2860342264175415):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:10<46:59, 29.07s/it] Training Epoch: 0/12, completed (loss: 0.21446973085403442):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:25<46:59, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.21446973085403442):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [44:39<46:29, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.40976226329803467):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [44:39<46:29, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.30307066440582275):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [44:54<46:29, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.30307066440582275):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:08<45:56, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.3498232066631317):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:08<45:56, 29.02s/it] Training Epoch: 0/12, completed (loss: 0.16026423871517181):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:23<45:56, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.16026423871517181):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [45:37<45:28, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.3144950270652771):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [45:37<45:28, 29.03s/it] Training Epoch: 0/12, completed (loss: 0.30578920245170593):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [45:52<45:28, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.30578920245170593):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:06<44:56, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.1823200285434723):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:06<44:56, 29.00s/it] Training Epoch: 0/12, completed (loss: 0.3753393590450287):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:21<44:56, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.3753393590450287):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:35<44:24, 28.96s/it]Training Epoch: 0/12, completed (loss: 0.10556965321302414):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:35<44:24, 28.96s/it]Training Epoch: 0/12, completed (loss: 0.4263697862625122):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:50<44:24, 28.96s/it] Training Epoch: 0/12, completed (loss: 0.4263697862625122):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:04<44:00, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.2631918787956238):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:04<44:00, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.27147290110588074):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:19<44:00, 29.01s/it]Training Epoch: 0/12, completed (loss: 0.27147290110588074):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:33<43:33, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.40005066990852356):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:33<43:33, 29.04s/it]Training Epoch: 0/12, completed (loss: 0.3801862597465515):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:48<43:33, 29.04s/it] Training Epoch: 0/12, completed (loss: 0.3801862597465515):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:02<43:05, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.471804141998291):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:02<43:05, 29.06s/it] Training Epoch: 0/12, completed (loss: 0.5029279589653015):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:17<43:05, 29.06s/it]Training Epoch: 0/12, completed (loss: 0.5029279589653015):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:31<42:39, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.38266727328300476):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:32<42:39, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.29492291808128357):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:46<42:39, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.29492291808128357):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:01<42:11, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.4930901527404785):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:01<42:11, 29.09s/it] Training Epoch: 0/12, completed (loss: 0.36711403727531433):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:15<42:11, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.36711403727531433):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:30<41:43, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.38749876618385315):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:30<41:43, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.4871944189071655):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:44<41:43, 29.11s/it] Training Epoch: 0/12, completed (loss: 0.4871944189071655):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [49:59<41:13, 29.10s/it] eval_ppl=tensor(1.9539, device='cuda:0') eval_epoch_loss=tensor(0.6698, device='cuda:0')
Eval epoch loss:  tensor(0.6698, device='cuda:0') | best_val_loss:  tensor(2.6360, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_0_87
Time while saving:  2023-10-25 16:03:01 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 0 and 87 is 0.6698206663131714
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 0, step_id: 173

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:46,  7.81s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:38,  7.79s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:28,  7.74s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:30<03:20,  7.70s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:38<03:13,  7.74s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:07,  7.79s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:58,  7.76s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:51,  7.80s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:09<02:43,  7.78s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:17<02:36,  7.80s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:25<02:28,  7.81s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:33<02:20,  7.79s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:41<02:13,  7.83s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:49<02:05,  7.86s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:57<01:57,  7.86s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:04<01:49,  7.82s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:12<01:41,  7.80s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:20<01:33,  7.81s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:28<01:25,  7.80s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:36<01:18,  7.83s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:43<01:10,  7.81s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:51<01:02,  7.80s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [02:59<00:54,  7.78s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:07<00:46,  7.79s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:14<00:38,  7.78s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:22<00:30,  7.74s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:30<00:23,  7.78s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:38<00:15,  7.84s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:46<00:07,  7.83s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:53<00:00,  7.80s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:53<00:00,  7.80s/it]
Training Epoch: 0/12, completed (loss: 0.14678238332271576):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [53:53<41:13, 29.10s/it]Training Epoch: 0/12, completed (loss: 0.17957498133182526):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:08<41:13, 29.10s/it]Training Epoch: 0/12, completed (loss: 0.17957498133182526):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:22<2:18:59, 99.28s/it]Training Epoch: 0/12, completed (loss: 0.2789987027645111):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:22<2:18:59, 99.28s/it] Training Epoch: 0/12, completed (loss: 0.3213318884372711):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:37<2:18:59, 99.28s/it]Training Epoch: 0/12, completed (loss: 0.3213318884372711):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [54:51<1:48:11, 78.21s/it]Training Epoch: 0/12, completed (loss: 0.20606271922588348):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [54:51<1:48:11, 78.21s/it]Training Epoch: 0/12, completed (loss: 0.2959599196910858):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:06<1:48:11, 78.21s/it] Training Epoch: 0/12, completed (loss: 0.2959599196910858):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:20<1:26:45, 63.48s/it]Training Epoch: 0/12, completed (loss: 0.4829201400279999):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:20<1:26:45, 63.48s/it]Training Epoch: 0/12, completed (loss: 0.2513236999511719):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:35<1:26:45, 63.48s/it]Training Epoch: 0/12, completed (loss: 0.2513236999511719):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [55:49<1:11:48, 53.19s/it]Training Epoch: 0/12, completed (loss: 0.3347111940383911):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [55:49<1:11:48, 53.19s/it]Training Epoch: 0/12, completed (loss: 0.2544792592525482):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:04<1:11:48, 53.19s/it]Training Epoch: 0/12, completed (loss: 0.2544792592525482):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:18<1:01:14, 45.93s/it]Training Epoch: 0/12, completed (loss: 0.37559646368026733):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:18<1:01:14, 45.93s/it]Training Epoch: 0/12, completed (loss: 0.3209177553653717):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:33<1:01:14, 45.93s/it] Training Epoch: 0/12, completed (loss: 0.3209177553653717):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [56:47<53:53, 40.93s/it]  Training Epoch: 0/12, completed (loss: 0.4624844193458557):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [56:48<53:53, 40.93s/it]Training Epoch: 0/12, completed (loss: 0.24739232659339905):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:02<53:53, 40.93s/it]Training Epoch: 0/12, completed (loss: 0.24739232659339905):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:17<48:36, 37.39s/it]Training Epoch: 0/12, completed (loss: 0.23599687218666077):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:17<48:36, 37.39s/it]Training Epoch: 0/12, completed (loss: 0.5243233442306519):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:31<48:36, 37.39s/it] Training Epoch: 0/12, completed (loss: 0.5243233442306519):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [57:46<44:48, 34.91s/it]Training Epoch: 0/12, completed (loss: 0.16646058857440948):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [57:46<44:48, 34.91s/it]Training Epoch: 0/12, completed (loss: 0.1395975798368454):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:01<44:48, 34.91s/it] Training Epoch: 0/12, completed (loss: 0.1395975798368454):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:15<42:05, 33.23s/it]Training Epoch: 0/12, completed (loss: 0.2906346619129181):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:15<42:05, 33.23s/it]Training Epoch: 0/12, completed (loss: 0.39904969930648804):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:30<42:05, 33.23s/it]Training Epoch: 0/12, completed (loss: 0.39904969930648804):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [58:44<40:00, 32.00s/it]Training Epoch: 0/12, completed (loss: 0.28006234765052795):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [58:44<40:00, 32.00s/it]Training Epoch: 0/12, completed (loss: 0.41614392399787903):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [58:59<40:00, 32.00s/it]Training Epoch: 0/12, completed (loss: 0.41614392399787903):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:13<38:22, 31.12s/it]Training Epoch: 0/12, completed (loss: 0.3952450454235077):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:13<38:22, 31.12s/it] Training Epoch: 0/12, completed (loss: 0.349322110414505):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:28<38:22, 31.12s/it] Training Epoch: 0/12, completed (loss: 0.349322110414505):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [59:42<37:09, 30.54s/it]Training Epoch: 0/12, completed (loss: 0.20159317553043365):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [59:43<37:09, 30.54s/it]Training Epoch: 0/12, completed (loss: 0.39544185996055603):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [59:57<37:09, 30.54s/it]Training Epoch: 0/12, completed (loss: 0.39544185996055603):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:11<36:06, 30.09s/it]Training Epoch: 0/12, completed (loss: 0.165274977684021):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:12<36:06, 30.09s/it]  Training Epoch: 0/12, completed (loss: 0.04169461503624916):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:26<36:06, 30.09s/it]Training Epoch: 0/12, completed (loss: 0.04169461503624916):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:00:40<35:14, 29.79s/it]Training Epoch: 0/12, completed (loss: 0.25383710861206055):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:00:41<35:14, 29.79s/it]Training Epoch: 0/12, completed (loss: 0.19747689366340637):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:00:55<35:14, 29.79s/it]Training Epoch: 0/12, completed (loss: 0.19747689366340637):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:10<34:31, 29.59s/it]Training Epoch: 0/12, completed (loss: 0.35063067078590393):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:10<34:31, 29.59s/it]Training Epoch: 0/12, completed (loss: 0.3811090588569641):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:24<34:31, 29.59s/it] Training Epoch: 0/12, completed (loss: 0.3811090588569641):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:01:39<33:50, 29.43s/it]Training Epoch: 0/12, completed (loss: 0.18801923096179962):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:01:39<33:50, 29.43s/it]Training Epoch: 0/12, completed (loss: 0.39569616317749023):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:01:53<33:50, 29.43s/it]Training Epoch: 0/12, completed (loss: 0.39569616317749023):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:08<33:11, 29.29s/it]Training Epoch: 0/12, completed (loss: 0.32494261860847473):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:08<33:11, 29.29s/it]Training Epoch: 0/12, completed (loss: 0.27851516008377075):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:22<33:11, 29.29s/it]Training Epoch: 0/12, completed (loss: 0.27851516008377075):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:02:37<32:40, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.6401504278182983):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:02:37<32:40, 29.26s/it] Training Epoch: 0/12, completed (loss: 0.2529962360858917):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:02:52<32:40, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.2529962360858917):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:06<32:08, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.26377663016319275):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:06<32:08, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.12339042872190475):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:21<32:08, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.12339042872190475):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:03:35<31:34, 29.14s/it]Training Epoch: 0/12, completed (loss: 0.37781786918640137):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:03:35<31:34, 29.14s/it]Training Epoch: 0/12, completed (loss: 0.3738093376159668):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:03:50<31:34, 29.14s/it] Training Epoch: 0/12, completed (loss: 0.3738093376159668):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:04<31:03, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.1992332935333252):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:04<31:03, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.231526717543602):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:19<31:03, 29.12s/it] Training Epoch: 0/12, completed (loss: 0.231526717543602):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:04:33<30:33, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.24378475546836853):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:04:33<30:33, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.31034964323043823):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:04:48<30:33, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.31034964323043823):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:02<30:02, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.10137934982776642):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:02<30:02, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.36587294936180115):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:17<30:02, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.36587294936180115):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:05:31<29:33, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.11520296335220337):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:05:31<29:33, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.47116732597351074):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:05:46<29:33, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.47116732597351074):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:00<29:04, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.3118540048599243):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:00<29:04, 29.07s/it] Training Epoch: 0/12, completed (loss: 0.34088972210884094):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:15<29:04, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.34088972210884094):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:06:29<28:35, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.30432239174842834):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:06:29<28:35, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.5220681428909302):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:06:44<28:35, 29.08s/it] Training Epoch: 0/12, completed (loss: 0.5220681428909302):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:06:58<28:06, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.16205377876758575):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:06:59<28:06, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.42622867226600647):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:13<28:06, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.42622867226600647):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:07:28<27:39, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.3662547171115875):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:07:28<27:39, 29.12s/it] Training Epoch: 0/12, completed (loss: 0.37350109219551086):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:07:42<27:39, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.37350109219551086):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:07:57<27:11, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.33806854486465454):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:07:57<27:11, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.26738277077674866):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:11<27:11, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.26738277077674866):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:08:26<26:41, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.23182208836078644):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:08:26<26:41, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.36842143535614014):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:08:41<26:41, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.36842143535614014):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:08:55<26:12, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.2174408882856369):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:08:55<26:12, 29.13s/it] Training Epoch: 0/12, completed (loss: 0.34909582138061523):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:10<26:12, 29.13s/it]Training Epoch: 0/12, completed (loss: 0.34909582138061523):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:24<25:41, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.33737945556640625):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:24<25:41, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.24518992006778717):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:39<25:41, 29.08s/it]Training Epoch: 0/12, completed (loss: 0.24518992006778717):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:09:53<25:12, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.3093898594379425):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:09:53<25:12, 29.09s/it] Training Epoch: 0/12, completed (loss: 0.30221235752105713):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:08<25:12, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.30221235752105713):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:22<24:48, 29.18s/it]Training Epoch: 0/12, completed (loss: 0.19121447205543518):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:23<24:48, 29.18s/it]Training Epoch: 0/12, completed (loss: 0.43398022651672363):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:37<24:48, 29.18s/it]Training Epoch: 0/12, completed (loss: 0.43398022651672363):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:10:51<24:15, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.20225755870342255):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:10:52<24:15, 29.12s/it]Training Epoch: 0/12, completed (loss: 0.6096088886260986):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:06<24:15, 29.12s/it] Training Epoch: 0/12, completed (loss: 0.6096088886260986):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:20<23:46, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.35292449593544006):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:21<23:46, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.40231630206108093):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:35<23:46, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.40231630206108093):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:11:50<23:17, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.13491585850715637):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:11:50<23:17, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.04470140486955643):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:04<23:17, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.04470140486955643):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:18<22:43, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.04670780152082443):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:19<22:43, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.24231690168380737):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:33<22:43, 29.00s/it]Training Epoch: 0/12, completed (loss: 0.24231690168380737):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:12:47<22:15, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.14956267178058624):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:12:48<22:15, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.17429517209529877):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:02<22:15, 29.02s/it]Training Epoch: 0/12, completed (loss: 0.17429517209529877):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:16<21:46, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.40209558606147766):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:17<21:46, 29.03s/it]Training Epoch: 0/12, completed (loss: 0.4408254027366638):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:31<21:46, 29.03s/it] Training Epoch: 0/12, completed (loss: 0.4408254027366638):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:13:46<21:20, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.19167517125606537):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:13:46<21:20, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.14246106147766113):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:00<21:20, 29.11s/it]Training Epoch: 0/12, completed (loss: 0.14246106147766113):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:14:15<20:51, 29.10s/it] eval_ppl=tensor(1.8263, device='cuda:0') eval_epoch_loss=tensor(0.6023, device='cuda:0')
Eval epoch loss:  tensor(0.6023, device='cuda:0') | best_val_loss:  tensor(0.6698, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_0_173
Time while saving:  2023-10-25 16:27:45 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 0 and 173 is 0.6022654175758362
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 0, step_id: 257

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:48,  7.87s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:37,  7.75s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:28,  7.74s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:30<03:20,  7.70s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:38<03:12,  7.72s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:06,  7.77s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:58,  7.75s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:51,  7.77s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:09<02:42,  7.76s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:17<02:35,  7.80s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:25<02:28,  7.81s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:33<02:20,  7.80s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:41<02:13,  7.84s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:49<02:05,  7.86s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:57<01:58,  7.87s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:04<01:49,  7.85s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:12<01:41,  7.83s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:20<01:34,  7.84s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:28<01:26,  7.85s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:36<01:18,  7.84s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:43<01:10,  7.80s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:51<01:02,  7.78s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [02:59<00:54,  7.81s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:07<00:46,  7.81s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:15<00:38,  7.79s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:22<00:31,  7.78s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:30<00:23,  7.80s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:38<00:15,  7.83s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:46<00:07,  7.82s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:54<00:00,  7.80s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:54<00:00,  7.80s/it]
Training Epoch: 0/12, completed (loss: 0.5192956328392029):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:09<20:51, 29.10s/it] Training Epoch: 0/12, completed (loss: 0.3521622121334076):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:24<20:51, 29.10s/it]Training Epoch: 0/12, completed (loss: 0.3521622121334076):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:18:38<1:09:30, 99.29s/it]Training Epoch: 0/12, completed (loss: 0.0941590741276741):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:18:38<1:09:30, 99.29s/it]Training Epoch: 0/12, completed (loss: 0.38757121562957764):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:18:53<1:09:30, 99.29s/it]Training Epoch: 0/12, completed (loss: 0.38757121562957764):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:07<53:26, 78.21s/it]  Training Epoch: 0/12, completed (loss: 0.2136325240135193):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:07<53:26, 78.21s/it] Training Epoch: 0/12, completed (loss: 0.021823810413479805):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:22<53:26, 78.21s/it]Training Epoch: 0/12, completed (loss: 0.021823810413479805):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:19:36<42:16, 63.41s/it]Training Epoch: 0/12, completed (loss: 0.18005089461803436):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:19:36<42:16, 63.41s/it] Training Epoch: 0/12, completed (loss: 0.33871471881866455):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:19:51<42:16, 63.41s/it]Training Epoch: 0/12, completed (loss: 0.33871471881866455):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:05<34:30, 53.10s/it]Training Epoch: 0/12, completed (loss: 0.3715426027774811):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:05<34:30, 53.10s/it] Training Epoch: 0/12, completed (loss: 0.3485386371612549):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:20<34:30, 53.10s/it]Training Epoch: 0/12, completed (loss: 0.3485386371612549):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:20:34<29:05, 45.94s/it]Training Epoch: 0/12, completed (loss: 0.5362037420272827):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:20:34<29:05, 45.94s/it]Training Epoch: 0/12, completed (loss: 0.19705431163311005):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:20:49<29:05, 45.94s/it]Training Epoch: 0/12, completed (loss: 0.19705431163311005):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:03<25:12, 40.88s/it]Training Epoch: 0/12, completed (loss: 0.23438268899917603):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:03<25:12, 40.88s/it]Training Epoch: 0/12, completed (loss: 0.3259699046611786):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:18<25:12, 40.88s/it] Training Epoch: 0/12, completed (loss: 0.3259699046611786):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:21:32<22:25, 37.37s/it]Training Epoch: 0/12, completed (loss: 0.3990629017353058):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:21:33<22:25, 37.37s/it]Training Epoch: 0/12, completed (loss: 0.16460375487804413):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:21:47<22:25, 37.37s/it]Training Epoch: 0/12, completed (loss: 0.16460375487804413):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:02<20:22, 34.92s/it]Training Epoch: 0/12, completed (loss: 0.11481646448373795):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:02<20:22, 34.92s/it]Training Epoch: 0/12, completed (loss: 0.12931984663009644):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:16<20:22, 34.92s/it]Training Epoch: 0/12, completed (loss: 0.12931984663009644):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:22:31<18:49, 33.21s/it]Training Epoch: 0/12, completed (loss: 0.11435036361217499):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:22:31<18:49, 33.21s/it]Training Epoch: 0/12, completed (loss: 0.29943424463272095):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:22:45<18:49, 33.21s/it]Training Epoch: 0/12, completed (loss: 0.29943424463272095):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:00<17:34, 31.96s/it]Training Epoch: 0/12, completed (loss: 0.10034304857254028):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:00<17:34, 31.96s/it]Training Epoch: 0/12, completed (loss: 0.30557355284690857):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:15<17:34, 31.96s/it]Training Epoch: 0/12, completed (loss: 0.30557355284690857):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:23:29<16:36, 31.15s/it]Training Epoch: 0/12, completed (loss: 0.32365939021110535):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:23:29<16:36, 31.15s/it]Training Epoch: 0/12, completed (loss: 0.1788615584373474):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:23:44<16:36, 31.15s/it] Training Epoch: 0/12, completed (loss: 0.1788615584373474):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:23:58<15:49, 30.63s/it]Training Epoch: 0/12, completed (loss: 0.02379700541496277):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:23:59<15:49, 30.63s/it]Training Epoch: 0/12, completed (loss: 0.002802958944812417):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:13<15:49, 30.63s/it]Training Epoch: 0/12, completed (loss: 0.002802958944812417):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:24:28<15:04, 30.16s/it]Training Epoch: 0/12, completed (loss: 0.27173954248428345):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:24:28<15:04, 30.16s/it] Training Epoch: 0/12, completed (loss: 0.45403504371643066):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:24:42<15:04, 30.16s/it]Training Epoch: 0/12, completed (loss: 0.45403504371643066):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:24:57<14:26, 29.88s/it]Training Epoch: 0/12, completed (loss: 0.3328700363636017):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:24:57<14:26, 29.88s/it] Training Epoch: 0/12, completed (loss: 0.18577302992343903):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:11<14:26, 29.88s/it]Training Epoch: 0/12, completed (loss: 0.18577302992343903):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:25:26<13:50, 29.66s/it]Training Epoch: 0/12, completed (loss: 0.47077611088752747):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:25:26<13:50, 29.66s/it]Training Epoch: 0/12, completed (loss: 0.588869571685791):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:25:41<13:50, 29.66s/it]  Training Epoch: 0/12, completed (loss: 0.588869571685791):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:25:55<13:16, 29.49s/it]Training Epoch: 0/12, completed (loss: 0.20739397406578064):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:25:55<13:16, 29.49s/it]Training Epoch: 0/12, completed (loss: 0.15744046866893768):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:10<13:16, 29.49s/it]Training Epoch: 0/12, completed (loss: 0.15744046866893768):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:26:24<12:44, 29.40s/it]Training Epoch: 0/12, completed (loss: 0.36072805523872375):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:26:24<12:44, 29.40s/it]Training Epoch: 0/12, completed (loss: 0.27925094962120056):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:26:39<12:44, 29.40s/it]Training Epoch: 0/12, completed (loss: 0.27925094962120056):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:26:53<12:13, 29.34s/it]Training Epoch: 0/12, completed (loss: 0.2948496639728546):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:26:54<12:13, 29.34s/it] Training Epoch: 0/12, completed (loss: 0.22106768190860748):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:08<12:13, 29.34s/it]Training Epoch: 0/12, completed (loss: 0.22106768190860748):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:27:23<11:43, 29.31s/it]Training Epoch: 0/12, completed (loss: 0.16314469277858734):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:27:23<11:43, 29.31s/it]Training Epoch: 0/12, completed (loss: 0.11230059713125229):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:27:37<11:43, 29.31s/it]Training Epoch: 0/12, completed (loss: 0.11230059713125229):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:27:52<11:13, 29.30s/it]Training Epoch: 0/12, completed (loss: 0.2273271381855011):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:27:52<11:13, 29.30s/it] Training Epoch: 0/12, completed (loss: 0.3471217155456543):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:07<11:13, 29.30s/it]Training Epoch: 0/12, completed (loss: 0.3471217155456543):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:28:21<10:44, 29.28s/it]Training Epoch: 0/12, completed (loss: 0.2043355256319046):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:28:21<10:44, 29.28s/it]Training Epoch: 0/12, completed (loss: 0.3560168743133545):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:28:36<10:44, 29.28s/it]Training Epoch: 0/12, completed (loss: 0.3560168743133545):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:28:50<10:14, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.5780327320098877):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:28:51<10:14, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.626100480556488):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:05<10:14, 29.26s/it] Training Epoch: 0/12, completed (loss: 0.626100480556488):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:29:20<09:45, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.48217806220054626):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:29:20<09:45, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.48091909289360046):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:29:34<09:45, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.48091909289360046):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:29:49<09:15, 29.23s/it]Training Epoch: 0/12, completed (loss: 0.46288007497787476):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:29:49<09:15, 29.23s/it]Training Epoch: 0/12, completed (loss: 0.4089089632034302):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:04<09:15, 29.23s/it] Training Epoch: 0/12, completed (loss: 0.4089089632034302):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:30:18<08:45, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.38435372710227966):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:30:18<08:45, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.20570561289787292):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:30:33<08:45, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.20570561289787292):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:30:47<08:16, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.2375306934118271):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:30:47<08:16, 29.22s/it] Training Epoch: 0/12, completed (loss: 0.3221144676208496):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:02<08:16, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.3221144676208496):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:31:16<07:47, 29.20s/it]Training Epoch: 0/12, completed (loss: 0.3386807441711426):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:31:17<07:47, 29.20s/it]Training Epoch: 0/12, completed (loss: 0.49326249957084656):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:31:31<07:47, 29.20s/it]Training Epoch: 0/12, completed (loss: 0.49326249957084656):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:31:46<07:18, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.3162861168384552):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:31:46<07:18, 29.21s/it] Training Epoch: 0/12, completed (loss: 0.5068142414093018):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:00<07:18, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.5068142414093018):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:32:15<06:48, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.09646128863096237):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:32:15<06:48, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.44565555453300476):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:32:30<06:48, 29.19s/it]Training Epoch: 0/12, completed (loss: 0.44565555453300476):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:32:44<06:20, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.18805401027202606):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:32:44<06:20, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.37811359763145447):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:32:59<06:20, 29.26s/it]Training Epoch: 0/12, completed (loss: 0.37811359763145447):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:13<05:50, 29.25s/it]Training Epoch: 0/12, completed (loss: 0.2072926163673401):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:14<05:50, 29.25s/it] Training Epoch: 0/12, completed (loss: 0.5977957248687744):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:28<05:50, 29.25s/it]Training Epoch: 0/12, completed (loss: 0.5977957248687744):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:33:43<05:21, 29.27s/it]Training Epoch: 0/12, completed (loss: 0.16025352478027344):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:33:43<05:21, 29.27s/it]Training Epoch: 0/12, completed (loss: 0.07824074476957321):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:33:57<05:21, 29.27s/it]Training Epoch: 0/12, completed (loss: 0.07824074476957321):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:12<04:52, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.23954226076602936):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:12<04:52, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.18546722829341888):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:27<04:52, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.18546722829341888):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:34:41<04:22, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.18571355938911438):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:34:41<04:22, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.48589178919792175):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:34:56<04:22, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.48589178919792175):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:10<03:53, 29.18s/it]Training Epoch: 0/12, completed (loss: 0.24915289878845215):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:10<03:53, 29.18s/it]Training Epoch: 0/12, completed (loss: 0.5234726667404175):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:25<03:53, 29.18s/it] Training Epoch: 0/12, completed (loss: 0.5234726667404175):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:35:39<03:24, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.4053117632865906):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:35:40<03:24, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.20953883230686188):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:35:54<03:24, 29.22s/it]Training Epoch: 0/12, completed (loss: 0.20953883230686188):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:09<02:55, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.43029215931892395):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:09<02:55, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.38505232334136963):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:23<02:55, 29.21s/it]Training Epoch: 0/12, completed (loss: 0.38505232334136963):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:36:38<02:25, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.5268404483795166):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:36:38<02:25, 29.16s/it] Training Epoch: 0/12, completed (loss: 0.23778517544269562):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:36:52<02:25, 29.16s/it]Training Epoch: 0/12, completed (loss: 0.23778517544269562):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:07<01:56, 29.14s/it]Training Epoch: 0/12, completed (loss: 0.25914573669433594):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:07<01:56, 29.14s/it]Training Epoch: 0/12, completed (loss: 0.10137384384870529):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:21<01:56, 29.14s/it]Training Epoch: 0/12, completed (loss: 0.10137384384870529):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:37:36<01:27, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.33986401557922363):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:37:36<01:27, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.2073843777179718):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:37:50<01:27, 29.09s/it] Training Epoch: 0/12, completed (loss: 0.2073843777179718):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:05<00:58, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.2522340714931488):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:05<00:58, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.32260453701019287):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:19<00:58, 29.07s/it]Training Epoch: 0/12, completed (loss: 0.32260453701019287):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:38:34<00:29, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.2082798033952713):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:38:34<00:29, 29.09s/it] Training Epoch: 0/12, completed (loss: 0.3034723103046417):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:38:49<00:29, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.3034723103046417): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:39:03<00:00, 29.09s/it] eval_ppl=tensor(1.7451, device='cuda:0') eval_epoch_loss=tensor(0.5568, device='cuda:0')
Eval epoch loss:  tensor(0.5568, device='cuda:0') | best_val_loss:  tensor(0.6023, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_0_257
Time while saving:  2023-10-25 16:52:01 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 0 and 257 is 0.556789219379425
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 0, step_id: 343

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:46,  7.82s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:39,  7.82s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:30,  7.79s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:21,  7.75s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:38<03:14,  7.78s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:07,  7.81s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:59,  7.80s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:52,  7.82s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:43,  7.80s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:36,  7.82s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:25<02:29,  7.86s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:33<02:20,  7.82s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:41<02:13,  7.86s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:49<02:05,  7.86s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:57<01:57,  7.84s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:05<01:49,  7.82s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:12<01:41,  7.82s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:20<01:33,  7.81s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:28<01:25,  7.80s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:36<01:18,  7.83s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:44<01:10,  7.81s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:51<01:02,  7.79s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [02:59<00:54,  7.81s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:07<00:47,  7.84s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:15<00:39,  7.83s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:23<00:31,  7.80s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:31<00:23,  7.82s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:38<00:15,  7.86s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:46<00:07,  7.84s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:54<00:00,  7.83s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:54<00:00,  7.82s/it]
Training Epoch: 0/12, completed (loss: 0.02325443923473358): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:42:58<00:00, 29.09s/it]Training Epoch: 0/12, completed (loss: 0.02325443923473358): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:42:58<00:00, 35.92s/it]
 eval_ppl=tensor(1.7583, device='cuda:0') eval_epoch_loss=tensor(0.5643, device='cuda:0')
Eval epoch loss:  tensor(0.5643, device='cuda:0') | best_val_loss:  tensor(0.5568, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_0_343
Time while saving:  2023-10-25 17:16:50 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
Epoch ending time:  2023-10-25 17:16:50 IST+0530
Validation losses are: 
{'epoch_id': 0, 'ministep_id': 1, 'eval_epoch_loss': tensor(2.6360, device='cuda:0'), 'best_val_loss_yet': tensor(2.6360, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6698, device='cuda:0'), 'best_val_loss_yet': tensor(0.6698, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6023, device='cuda:0'), 'best_val_loss_yet': tensor(0.6023, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5568, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5643, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
$$$%%%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Epoch 0: train_perplexity=1.4151, train_epoch_loss=0.3472, epoch time 6178.627500030911s
Epoch starting time:  2023-10-25 17:16:50 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 1:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training Epoch: 1/12, completed (loss: 0.137451633810997):   0%|[34m          [0m| 0/172 [00:14<?, ?it/s]Training Epoch: 1/12, completed (loss: 0.137451633810997):   1%|[34m          [0m| 1/172 [00:29<1:22:50, 29.07s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 1, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:49,  7.91s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:38,  7.81s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:29,  7.75s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:21,  7.75s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:38<03:14,  7.78s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:07,  7.81s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:58,  7.77s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:51,  7.80s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:44,  7.83s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:36,  7.82s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:25<02:28,  7.83s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:33<02:20,  7.82s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:41<02:13,  7.86s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:49<02:06,  7.90s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:57<01:58,  7.90s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:05<01:50,  7.87s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:13<01:41,  7.84s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:20<01:33,  7.82s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:28<01:26,  7.83s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:36<01:18,  7.85s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:44<01:10,  7.84s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:52<01:02,  7.82s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:00<00:54,  7.83s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:07<00:47,  7.84s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:15<00:39,  7.86s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:23<00:31,  7.81s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:31<00:23,  7.82s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:39<00:15,  7.88s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:47<00:07,  7.85s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:54<00:00,  7.83s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:55<00:00,  7.83s/it]
Training Epoch: 1/12, completed (loss: 0.1441817581653595):   1%|[34m          [0m| 1/172 [04:24<1:22:50, 29.07s/it]Training Epoch: 1/12, completed (loss: 0.15869128704071045):   1%|[34m          [0m| 1/172 [04:38<1:22:50, 29.07s/it]Training Epoch: 1/12, completed (loss: 0.15869128704071045):   1%|[34m          [0m| 2/172 [04:53<7:54:23, 167.43s/it]Training Epoch: 1/12, completed (loss: 0.2692108154296875):   1%|[34m          [0m| 2/172 [04:53<7:54:23, 167.43s/it] Training Epoch: 1/12, completed (loss: 0.09573446214199066):   1%|[34m          [0m| 2/172 [05:08<7:54:23, 167.43s/it]Training Epoch: 1/12, completed (loss: 0.09573446214199066):   2%|[34mâ–         [0m| 3/172 [05:22<4:53:56, 104.36s/it]Training Epoch: 1/12, completed (loss: 0.27893227338790894):   2%|[34mâ–         [0m| 3/172 [05:22<4:53:56, 104.36s/it]Training Epoch: 1/12, completed (loss: 0.25114578008651733):   2%|[34mâ–         [0m| 3/172 [05:37<4:53:56, 104.36s/it]Training Epoch: 1/12, completed (loss: 0.25114578008651733):   2%|[34mâ–         [0m| 4/172 [05:51<3:28:54, 74.61s/it] Training Epoch: 1/12, completed (loss: 0.16590610146522522):   2%|[34mâ–         [0m| 4/172 [05:51<3:28:54, 74.61s/it]Training Epoch: 1/12, completed (loss: 0.23162363469600677):   2%|[34mâ–         [0m| 4/172 [06:06<3:28:54, 74.61s/it]Training Epoch: 1/12, completed (loss: 0.23162363469600677):   3%|[34mâ–Ž         [0m| 5/172 [06:20<2:42:08, 58.25s/it]Training Epoch: 1/12, completed (loss: 0.4389667510986328):   3%|[34mâ–Ž         [0m| 5/172 [06:21<2:42:08, 58.25s/it] Training Epoch: 1/12, completed (loss: 0.3331257104873657):   3%|[34mâ–Ž         [0m| 5/172 [06:35<2:42:08, 58.25s/it]Training Epoch: 1/12, completed (loss: 0.3331257104873657):   3%|[34mâ–Ž         [0m| 6/172 [06:49<2:13:38, 48.30s/it]Training Epoch: 1/12, completed (loss: 0.10484529286623001):   3%|[34mâ–Ž         [0m| 6/172 [06:50<2:13:38, 48.30s/it]Training Epoch: 1/12, completed (loss: 0.3535272181034088):   3%|[34mâ–Ž         [0m| 6/172 [07:04<2:13:38, 48.30s/it] Training Epoch: 1/12, completed (loss: 0.3535272181034088):   4%|[34mâ–         [0m| 7/172 [07:19<1:55:50, 42.12s/it]Training Epoch: 1/12, completed (loss: 0.07944288104772568):   4%|[34mâ–         [0m| 7/172 [07:19<1:55:50, 42.12s/it]Training Epoch: 1/12, completed (loss: 0.24190354347229004):   4%|[34mâ–         [0m| 7/172 [07:34<1:55:50, 42.12s/it]Training Epoch: 1/12, completed (loss: 0.24190354347229004):   5%|[34mâ–         [0m| 8/172 [07:48<1:43:54, 38.02s/it]Training Epoch: 1/12, completed (loss: 0.22707369923591614):   5%|[34mâ–         [0m| 8/172 [07:48<1:43:54, 38.02s/it]Training Epoch: 1/12, completed (loss: 0.327664852142334):   5%|[34mâ–         [0m| 8/172 [08:03<1:43:54, 38.02s/it]  Training Epoch: 1/12, completed (loss: 0.327664852142334):   5%|[34mâ–Œ         [0m| 9/172 [08:17<1:35:57, 35.32s/it]Training Epoch: 1/12, completed (loss: 0.29223141074180603):   5%|[34mâ–Œ         [0m| 9/172 [08:18<1:35:57, 35.32s/it]Training Epoch: 1/12, completed (loss: 0.16121689975261688):   5%|[34mâ–Œ         [0m| 9/172 [08:32<1:35:57, 35.32s/it]Training Epoch: 1/12, completed (loss: 0.16121689975261688):   6%|[34mâ–Œ         [0m| 10/172 [08:46<1:30:00, 33.34s/it]Training Epoch: 1/12, completed (loss: 0.2166946679353714):   6%|[34mâ–Œ         [0m| 10/172 [08:47<1:30:00, 33.34s/it] Training Epoch: 1/12, completed (loss: 0.2331646829843521):   6%|[34mâ–Œ         [0m| 10/172 [09:01<1:30:00, 33.34s/it]Training Epoch: 1/12, completed (loss: 0.2331646829843521):   6%|[34mâ–‹         [0m| 11/172 [09:15<1:25:59, 32.05s/it]Training Epoch: 1/12, completed (loss: 0.25588154792785645):   6%|[34mâ–‹         [0m| 11/172 [09:16<1:25:59, 32.05s/it]Training Epoch: 1/12, completed (loss: 0.24535399675369263):   6%|[34mâ–‹         [0m| 11/172 [09:30<1:25:59, 32.05s/it]Training Epoch: 1/12, completed (loss: 0.24535399675369263):   7%|[34mâ–‹         [0m| 12/172 [09:45<1:23:03, 31.15s/it]Training Epoch: 1/12, completed (loss: 0.24841852486133575):   7%|[34mâ–‹         [0m| 12/172 [09:45<1:23:03, 31.15s/it]Training Epoch: 1/12, completed (loss: 0.1384095996618271):   7%|[34mâ–‹         [0m| 12/172 [09:59<1:23:03, 31.15s/it] Training Epoch: 1/12, completed (loss: 0.1384095996618271):   8%|[34mâ–Š         [0m| 13/172 [10:14<1:20:54, 30.53s/it]Training Epoch: 1/12, completed (loss: 0.06269308924674988):   8%|[34mâ–Š         [0m| 13/172 [10:14<1:20:54, 30.53s/it]Training Epoch: 1/12, completed (loss: 0.4549430310726166):   8%|[34mâ–Š         [0m| 13/172 [10:28<1:20:54, 30.53s/it] Training Epoch: 1/12, completed (loss: 0.4549430310726166):   8%|[34mâ–Š         [0m| 14/172 [10:43<1:19:21, 30.13s/it]Training Epoch: 1/12, completed (loss: 0.39450350403785706):   8%|[34mâ–Š         [0m| 14/172 [10:43<1:19:21, 30.13s/it]Training Epoch: 1/12, completed (loss: 0.1576036661863327):   8%|[34mâ–Š         [0m| 14/172 [10:58<1:19:21, 30.13s/it] Training Epoch: 1/12, completed (loss: 0.1576036661863327):   9%|[34mâ–Š         [0m| 15/172 [11:12<1:18:05, 29.84s/it]Training Epoch: 1/12, completed (loss: 0.22028636932373047):   9%|[34mâ–Š         [0m| 15/172 [11:12<1:18:05, 29.84s/it]Training Epoch: 1/12, completed (loss: 0.2465938925743103):   9%|[34mâ–Š         [0m| 15/172 [11:27<1:18:05, 29.84s/it] Training Epoch: 1/12, completed (loss: 0.2465938925743103):   9%|[34mâ–‰         [0m| 16/172 [11:41<1:17:09, 29.68s/it]Training Epoch: 1/12, completed (loss: 0.1944822371006012):   9%|[34mâ–‰         [0m| 16/172 [11:42<1:17:09, 29.68s/it]Training Epoch: 1/12, completed (loss: 0.41029733419418335):   9%|[34mâ–‰         [0m| 16/172 [11:56<1:17:09, 29.68s/it]Training Epoch: 1/12, completed (loss: 0.41029733419418335):  10%|[34mâ–‰         [0m| 17/172 [12:11<1:16:22, 29.56s/it]Training Epoch: 1/12, completed (loss: 0.2832522988319397):  10%|[34mâ–‰         [0m| 17/172 [12:11<1:16:22, 29.56s/it] Training Epoch: 1/12, completed (loss: 0.2636808454990387):  10%|[34mâ–‰         [0m| 17/172 [12:25<1:16:22, 29.56s/it]Training Epoch: 1/12, completed (loss: 0.2636808454990387):  10%|[34mâ–ˆ         [0m| 18/172 [12:40<1:15:29, 29.41s/it]Training Epoch: 1/12, completed (loss: 0.21351084113121033):  10%|[34mâ–ˆ         [0m| 18/172 [12:40<1:15:29, 29.41s/it]Training Epoch: 1/12, completed (loss: 0.2245025783777237):  10%|[34mâ–ˆ         [0m| 18/172 [12:55<1:15:29, 29.41s/it] Training Epoch: 1/12, completed (loss: 0.2245025783777237):  11%|[34mâ–ˆ         [0m| 19/172 [13:09<1:14:50, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.05160083994269371):  11%|[34mâ–ˆ         [0m| 19/172 [13:09<1:14:50, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.41090327501296997):  11%|[34mâ–ˆ         [0m| 19/172 [13:24<1:14:50, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.41090327501296997):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:38<1:14:08, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.045468978583812714):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:38<1:14:08, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.30961939692497253):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:53<1:14:08, 29.27s/it] Training Epoch: 1/12, completed (loss: 0.30961939692497253):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:07<1:13:40, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.12328004837036133):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:07<1:13:40, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.10906325280666351):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:22<1:13:40, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.10906325280666351):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:37<1:13:12, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.7533572912216187):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:37<1:13:12, 29.28s/it] Training Epoch: 1/12, completed (loss: 0.5836095213890076):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:51<1:13:12, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.5836095213890076):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:06<1:12:46, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.18057890236377716):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:06<1:12:46, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.381229430437088):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:21<1:12:46, 29.31s/it]  Training Epoch: 1/12, completed (loss: 0.381229430437088):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:35<1:12:16, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.42045390605926514):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:35<1:12:16, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.10554757714271545):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:50<1:12:16, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.10554757714271545):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:04<1:11:41, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.09104567021131516):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:05<1:11:41, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.20736171305179596):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:19<1:11:41, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.20736171305179596):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:34<1:11:10, 29.25s/it]Training Epoch: 1/12, completed (loss: 0.2892504334449768):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:34<1:11:10, 29.25s/it] Training Epoch: 1/12, completed (loss: 0.16389033198356628):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:48<1:11:10, 29.25s/it]Training Epoch: 1/12, completed (loss: 0.16389033198356628):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:03<1:10:38, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.3440708816051483):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:03<1:10:38, 29.23s/it] Training Epoch: 1/12, completed (loss: 0.21622715890407562):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:18<1:10:38, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.21622715890407562):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:32<1:10:09, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.1495247483253479):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:32<1:10:09, 29.23s/it] Training Epoch: 1/12, completed (loss: 0.46704593300819397):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:47<1:10:09, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.46704593300819397):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:01<1:09:41, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.20300358533859253):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:01<1:09:41, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.23569047451019287):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:16<1:09:41, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.23569047451019287):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:30<1:09:09, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.402298241853714):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:31<1:09:09, 29.22s/it]  Training Epoch: 1/12, completed (loss: 0.09953469783067703):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:45<1:09:09, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.09953469783067703):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:00<1:08:38, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.16619543731212616):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:00<1:08:38, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.21685613691806793):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:15<1:08:38, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.21685613691806793):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:29<1:08:13, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.1313195377588272):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:29<1:08:13, 29.24s/it] Training Epoch: 1/12, completed (loss: 0.1736069619655609):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:44<1:08:13, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.1736069619655609):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [19:58<1:07:40, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.24134254455566406):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [19:58<1:07:40, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.3829376995563507):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:13<1:07:40, 29.21s/it] Training Epoch: 1/12, completed (loss: 0.3829376995563507):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:27<1:07:11, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.33283698558807373):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:28<1:07:11, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.22908122837543488):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:42<1:07:11, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.22908122837543488):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [20:57<1:06:44, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.0646170973777771):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [20:57<1:06:44, 29.23s/it] Training Epoch: 1/12, completed (loss: 0.1528501659631729):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:12<1:06:44, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.1528501659631729):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:26<1:06:19, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.18491242825984955):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:26<1:06:19, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.24439649283885956):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:41<1:06:19, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.24439649283885956):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [21:55<1:05:49, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.15620750188827515):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [21:55<1:05:49, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.20613348484039307):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:10<1:05:49, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.20613348484039307):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:24<1:05:10, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.06416650861501694):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:24<1:05:10, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.4390736520290375):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:39<1:05:10, 29.18s/it] Training Epoch: 1/12, completed (loss: 0.4390736520290375):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:53<1:04:41, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.11471693217754364):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:54<1:04:41, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.3324589431285858):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:08<1:04:41, 29.18s/it] Training Epoch: 1/12, completed (loss: 0.3324589431285858):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:22<1:04:10, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.2986445724964142):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:23<1:04:10, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.24735815823078156):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:37<1:04:10, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.24735815823078156):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:52<1:03:44, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.2075573056936264):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:52<1:03:44, 29.20s/it] Training Epoch: 1/12, completed (loss: 0.039041753858327866):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:07<1:03:44, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.039041753858327866):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:21<1:03:20, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.1920560747385025):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:21<1:03:20, 29.24s/it]  Training Epoch: 1/12, completed (loss: 0.15592218935489655):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:36<1:03:20, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.15592218935489655):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:50<1:02:48, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.12559953331947327):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:50<1:02:48, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.5391383171081543):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:05<1:02:48, 29.21s/it] Training Epoch: 1/12, completed (loss: 0.5391383171081543):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:19<1:02:17, 29.20s/it] eval_ppl=tensor(1.7567, device='cuda:0') eval_epoch_loss=tensor(0.5634, device='cuda:0')
Eval epoch loss:  tensor(0.5634, device='cuda:0') | best_val_loss:  tensor(0.5568, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_1_1
Time while saving:  2023-10-25 17:21:15 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 1, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:49,  7.92s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:40,  7.88s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:30,  7.78s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:21,  7.75s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:14,  7.79s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:07,  7.83s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:59,  7.81s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:52,  7.84s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:44,  7.83s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.86s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:29,  7.88s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:21,  7.85s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:41<02:13,  7.87s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:49<02:06,  7.91s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:57<01:58,  7.92s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:05<01:50,  7.90s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:13<01:42,  7.89s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:21<01:34,  7.86s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:29<01:26,  7.88s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:37<01:18,  7.89s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:44<01:10,  7.85s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:52<01:02,  7.83s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:00<00:54,  7.84s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:08<00:47,  7.89s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:16<00:39,  7.87s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:24<00:31,  7.83s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:32<00:23,  7.84s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:40<00:15,  7.88s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:47<00:07,  7.86s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:55<00:00,  7.86s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:55<00:00,  7.86s/it]
Training Epoch: 1/12, completed (loss: 0.4218282103538513):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:16<1:02:17, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.25245165824890137):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:30<1:02:17, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.25245165824890137):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:44<3:31:30, 99.93s/it]Training Epoch: 1/12, completed (loss: 0.12143483757972717):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:45<3:31:30, 99.93s/it]Training Epoch: 1/12, completed (loss: 0.39028993248939514):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:59<3:31:30, 99.93s/it]Training Epoch: 1/12, completed (loss: 0.39028993248939514):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:13<2:45:07, 78.63s/it]Training Epoch: 1/12, completed (loss: 0.1061377227306366):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:13<2:45:07, 78.63s/it] Training Epoch: 1/12, completed (loss: 0.25296273827552795):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:28<2:45:07, 78.63s/it]Training Epoch: 1/12, completed (loss: 0.25296273827552795):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:43<2:12:58, 63.83s/it]Training Epoch: 1/12, completed (loss: 0.15684197843074799):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:43<2:12:58, 63.83s/it]Training Epoch: 1/12, completed (loss: 0.33267664909362793):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:57<2:12:58, 63.83s/it]Training Epoch: 1/12, completed (loss: 0.33267664909362793):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:12<1:50:24, 53.43s/it]Training Epoch: 1/12, completed (loss: 0.07539842277765274):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:12<1:50:24, 53.43s/it]Training Epoch: 1/12, completed (loss: 0.18706290423870087):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:27<1:50:24, 53.43s/it]Training Epoch: 1/12, completed (loss: 0.18706290423870087):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:41<1:34:35, 46.14s/it]Training Epoch: 1/12, completed (loss: 0.027411196380853653):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:41<1:34:35, 46.14s/it]Training Epoch: 1/12, completed (loss: 0.4360637962818146):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:56<1:34:35, 46.14s/it]  Training Epoch: 1/12, completed (loss: 0.4360637962818146):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:10<1:23:27, 41.05s/it]Training Epoch: 1/12, completed (loss: 0.19573698937892914):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:10<1:23:27, 41.05s/it]Training Epoch: 1/12, completed (loss: 0.3576628565788269):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:25<1:23:27, 41.05s/it] Training Epoch: 1/12, completed (loss: 0.3576628565788269):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:39<1:15:30, 37.44s/it]Training Epoch: 1/12, completed (loss: 0.12079648673534393):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:39<1:15:30, 37.44s/it]Training Epoch: 1/12, completed (loss: 0.3046974241733551):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:54<1:15:30, 37.44s/it] Training Epoch: 1/12, completed (loss: 0.3046974241733551):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:08<1:10:02, 35.02s/it]Training Epoch: 1/12, completed (loss: 0.2693421244621277):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:09<1:10:02, 35.02s/it]Training Epoch: 1/12, completed (loss: 0.42974603176116943):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:23<1:10:02, 35.02s/it]Training Epoch: 1/12, completed (loss: 0.42974603176116943):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:38<1:05:59, 33.27s/it]Training Epoch: 1/12, completed (loss: 0.17082062363624573):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:38<1:05:59, 33.27s/it]Training Epoch: 1/12, completed (loss: 0.20212072134017944):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:52<1:05:59, 33.27s/it]Training Epoch: 1/12, completed (loss: 0.20212072134017944):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:07<1:02:59, 32.03s/it]Training Epoch: 1/12, completed (loss: 0.10964875668287277):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:07<1:02:59, 32.03s/it]Training Epoch: 1/12, completed (loss: 0.35958603024482727):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:22<1:02:59, 32.03s/it]Training Epoch: 1/12, completed (loss: 0.35958603024482727):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:36<1:00:47, 31.17s/it]Training Epoch: 1/12, completed (loss: 0.14044460654258728):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:36<1:00:47, 31.17s/it]Training Epoch: 1/12, completed (loss: 0.082954041659832):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:51<1:00:47, 31.17s/it]  Training Epoch: 1/12, completed (loss: 0.082954041659832):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:05<59:07, 30.58s/it]  Training Epoch: 1/12, completed (loss: 0.3818376958370209):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:05<59:07, 30.58s/it]Training Epoch: 1/12, completed (loss: 0.2806943953037262):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:20<59:07, 30.58s/it]Training Epoch: 1/12, completed (loss: 0.2806943953037262):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:34<57:51, 30.19s/it]Training Epoch: 1/12, completed (loss: 0.2554970383644104):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:35<57:51, 30.19s/it]Training Epoch: 1/12, completed (loss: 0.03292198106646538):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:49<57:51, 30.19s/it]Training Epoch: 1/12, completed (loss: 0.03292198106646538):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:04<56:49, 29.91s/it]Training Epoch: 1/12, completed (loss: 0.36165139079093933):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:04<56:49, 29.91s/it]Training Epoch: 1/12, completed (loss: 0.3545514643192291):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:19<56:49, 29.91s/it] Training Epoch: 1/12, completed (loss: 0.3545514643192291):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:33<56:02, 29.75s/it]Training Epoch: 1/12, completed (loss: 0.17048241198062897):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:33<56:02, 29.75s/it]Training Epoch: 1/12, completed (loss: 0.22145870327949524):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:48<56:02, 29.75s/it]Training Epoch: 1/12, completed (loss: 0.22145870327949524):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:02<55:09, 29.55s/it]Training Epoch: 1/12, completed (loss: 0.14587241411209106):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:02<55:09, 29.55s/it]Training Epoch: 1/12, completed (loss: 0.3571230471134186):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:17<55:09, 29.55s/it] Training Epoch: 1/12, completed (loss: 0.3571230471134186):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:31<54:32, 29.48s/it]Training Epoch: 1/12, completed (loss: 0.09693728387355804):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:32<54:32, 29.48s/it]Training Epoch: 1/12, completed (loss: 0.016119610518217087):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:46<54:32, 29.48s/it]Training Epoch: 1/12, completed (loss: 0.016119610518217087):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:01<53:57, 29.43s/it]Training Epoch: 1/12, completed (loss: 0.3756311237812042):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:01<53:57, 29.43s/it]  Training Epoch: 1/12, completed (loss: 0.5318855047225952):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:16<53:57, 29.43s/it]Training Epoch: 1/12, completed (loss: 0.5318855047225952):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:30<53:17, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.5421555638313293):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:30<53:17, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.10726004093885422):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:45<53:17, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.10726004093885422):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [38:59<52:47, 29.33s/it]Training Epoch: 1/12, completed (loss: 0.1954534500837326):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [38:59<52:47, 29.33s/it] Training Epoch: 1/12, completed (loss: 0.21496838331222534):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:14<52:47, 29.33s/it]Training Epoch: 1/12, completed (loss: 0.21496838331222534):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:28<52:14, 29.29s/it]Training Epoch: 1/12, completed (loss: 0.12716391682624817):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:29<52:14, 29.29s/it]Training Epoch: 1/12, completed (loss: 0.32179737091064453):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:43<52:14, 29.29s/it]Training Epoch: 1/12, completed (loss: 0.32179737091064453):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [39:58<51:42, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.2591916024684906):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [39:58<51:42, 29.27s/it] Training Epoch: 1/12, completed (loss: 0.16637340188026428):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:13<51:42, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.16637340188026428):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:27<51:12, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.17059025168418884):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:27<51:12, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.12581941485404968):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:42<51:12, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.12581941485404968):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [40:56<50:41, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.15455186367034912):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [40:56<50:41, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.40035754442214966):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:11<50:41, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.40035754442214966):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:25<50:07, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.11219482868909836):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:25<50:07, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.21586695313453674):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:40<50:07, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.21586695313453674):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [41:54<49:40, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.5752358436584473):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [41:55<49:40, 29.22s/it] Training Epoch: 1/12, completed (loss: 0.17822736501693726):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:09<49:40, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.17822736501693726):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:24<49:12, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.4082146883010864):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:24<49:12, 29.23s/it] Training Epoch: 1/12, completed (loss: 0.2314779907464981):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:38<49:12, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.2314779907464981):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [42:53<48:39, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.25873005390167236):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [42:53<48:39, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.3768557012081146):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:08<48:39, 29.19s/it] Training Epoch: 1/12, completed (loss: 0.3768557012081146):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:22<48:12, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.03189404681324959):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:22<48:12, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.2721882164478302):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:37<48:12, 29.22s/it] Training Epoch: 1/12, completed (loss: 0.2721882164478302):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [43:51<47:40, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.25102120637893677):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [43:51<47:40, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.3033507168292999):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:06<47:40, 29.19s/it] Training Epoch: 1/12, completed (loss: 0.3033507168292999):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:20<47:12, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.23519091308116913):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:21<47:12, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.1520504653453827):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:35<47:12, 29.21s/it] Training Epoch: 1/12, completed (loss: 0.1520504653453827):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [44:50<46:43, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.2904503345489502):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [44:50<46:43, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.24575190246105194):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:04<46:43, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.24575190246105194):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:19<46:10, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.29357168078422546):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:19<46:10, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.08141876757144928):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:33<46:10, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.08141876757144928):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [45:48<45:43, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.18654458224773407):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [45:48<45:43, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.23522576689720154):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:03<45:43, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.23522576689720154):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:17<45:13, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.12404132634401321):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:17<45:13, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.2748907804489136):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:32<45:13, 29.18s/it] Training Epoch: 1/12, completed (loss: 0.2748907804489136):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:46<44:39, 29.12s/it]Training Epoch: 1/12, completed (loss: 0.06446523219347):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:46<44:39, 29.12s/it]  Training Epoch: 1/12, completed (loss: 0.3493185341358185):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:01<44:39, 29.12s/it]Training Epoch: 1/12, completed (loss: 0.3493185341358185):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:15<44:13, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.1604476273059845):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:16<44:13, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.18143273890018463):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:30<44:13, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.18143273890018463):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:45<43:45, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.3326348662376404):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:45<43:45, 29.17s/it] Training Epoch: 1/12, completed (loss: 0.3311900496482849):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:59<43:45, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.3311900496482849):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:14<43:17, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.39166259765625):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:14<43:17, 29.19s/it]  Training Epoch: 1/12, completed (loss: 0.287157267332077):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:29<43:17, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.287157267332077):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:43<42:49, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.3034060001373291):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:43<42:49, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.21302641928195953):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:58<42:49, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.21302641928195953):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:12<42:20, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.46219539642333984):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:12<42:20, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.32378584146499634):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:27<42:20, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.32378584146499634):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:41<41:52, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.31752049922943115):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:42<41:52, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.41544362902641296):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:56<41:52, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.41544362902641296):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [50:11<41:21, 29.19s/it] eval_ppl=tensor(1.7583, device='cuda:0') eval_epoch_loss=tensor(0.5644, device='cuda:0')
Eval epoch loss:  tensor(0.5644, device='cuda:0') | best_val_loss:  tensor(0.5568, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_1_87
Time while saving:  2023-10-25 17:46:06 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 1, step_id: 173

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:49,  7.93s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:39,  7.82s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:30,  7.78s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:21,  7.76s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:38<03:14,  7.77s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:46<03:06,  7.78s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<02:59,  7.78s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:51,  7.81s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:44,  7.81s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:36,  7.84s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:25<02:28,  7.84s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:33<02:20,  7.81s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:41<02:13,  7.87s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:49<02:05,  7.86s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:57<01:57,  7.86s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:05<01:49,  7.82s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:12<01:41,  7.81s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:20<01:33,  7.82s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:28<01:26,  7.85s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:36<01:18,  7.89s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:44<01:10,  7.85s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:52<01:02,  7.83s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:00<00:54,  7.84s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:08<00:47,  7.89s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:15<00:39,  7.88s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:23<00:31,  7.85s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:31<00:23,  7.88s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:39<00:15,  7.92s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:47<00:07,  7.90s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:55<00:00,  7.89s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:55<00:00,  7.85s/it]
Training Epoch: 1/12, completed (loss: 0.10552191734313965):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:06<41:21, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.059133123606443405):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:21<41:21, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.059133123606443405):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:35<2:19:45, 99.83s/it]Training Epoch: 1/12, completed (loss: 0.19520436227321625):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:35<2:19:45, 99.83s/it] Training Epoch: 1/12, completed (loss: 0.2853521406650543):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:50<2:19:45, 99.83s/it] Training Epoch: 1/12, completed (loss: 0.2853521406650543):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:04<1:48:46, 78.64s/it]Training Epoch: 1/12, completed (loss: 0.15308956801891327):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:05<1:48:46, 78.64s/it]Training Epoch: 1/12, completed (loss: 0.2464863657951355):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:19<1:48:46, 78.64s/it] Training Epoch: 1/12, completed (loss: 0.2464863657951355):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:34<1:27:13, 63.82s/it]Training Epoch: 1/12, completed (loss: 0.4415235221385956):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:34<1:27:13, 63.82s/it]Training Epoch: 1/12, completed (loss: 0.19117096066474915):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:49<1:27:13, 63.82s/it]Training Epoch: 1/12, completed (loss: 0.19117096066474915):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:03<1:12:11, 53.47s/it]Training Epoch: 1/12, completed (loss: 0.2919142246246338):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:03<1:12:11, 53.47s/it] Training Epoch: 1/12, completed (loss: 0.18912577629089355):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:18<1:12:11, 53.47s/it]Training Epoch: 1/12, completed (loss: 0.18912577629089355):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:32<1:01:33, 46.17s/it]Training Epoch: 1/12, completed (loss: 0.3245082497596741):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:32<1:01:33, 46.17s/it] Training Epoch: 1/12, completed (loss: 0.1793181449174881):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:47<1:01:33, 46.17s/it]Training Epoch: 1/12, completed (loss: 0.1793181449174881):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:02<54:09, 41.14s/it]  Training Epoch: 1/12, completed (loss: 0.3794696033000946):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:02<54:09, 41.14s/it]Training Epoch: 1/12, completed (loss: 0.18559397757053375):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:16<54:09, 41.14s/it]Training Epoch: 1/12, completed (loss: 0.18559397757053375):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:31<48:49, 37.56s/it]Training Epoch: 1/12, completed (loss: 0.2008439600467682):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:31<48:49, 37.56s/it] Training Epoch: 1/12, completed (loss: 0.5477696657180786):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:46<48:49, 37.56s/it]Training Epoch: 1/12, completed (loss: 0.5477696657180786):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:00<44:58, 35.05s/it]Training Epoch: 1/12, completed (loss: 0.13546442985534668):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:00<44:58, 35.05s/it]Training Epoch: 1/12, completed (loss: 0.07089506834745407):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:15<44:58, 35.05s/it]Training Epoch: 1/12, completed (loss: 0.07089506834745407):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:29<42:13, 33.33s/it]Training Epoch: 1/12, completed (loss: 0.2251543253660202):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:29<42:13, 33.33s/it] Training Epoch: 1/12, completed (loss: 0.32392618060112):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:44<42:13, 33.33s/it]  Training Epoch: 1/12, completed (loss: 0.32392618060112):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [58:58<40:07, 32.11s/it]Training Epoch: 1/12, completed (loss: 0.21452391147613525):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [58:59<40:07, 32.11s/it]Training Epoch: 1/12, completed (loss: 0.3071754574775696):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:13<40:07, 32.11s/it] Training Epoch: 1/12, completed (loss: 0.3071754574775696):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:28<38:29, 31.22s/it]Training Epoch: 1/12, completed (loss: 0.2987825870513916):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:28<38:29, 31.22s/it]Training Epoch: 1/12, completed (loss: 0.3212599754333496):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:43<38:29, 31.22s/it]Training Epoch: 1/12, completed (loss: 0.3212599754333496):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [59:57<37:15, 30.63s/it]Training Epoch: 1/12, completed (loss: 0.14430098235607147):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [59:57<37:15, 30.63s/it]Training Epoch: 1/12, completed (loss: 0.2585684061050415):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:12<37:15, 30.63s/it]Training Epoch: 1/12, completed (loss: 0.2585684061050415):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:26<36:12, 30.17s/it]Training Epoch: 1/12, completed (loss: 0.06290904432535172):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:26<36:12, 30.17s/it]Training Epoch: 1/12, completed (loss: 0.032381631433963776):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:41<36:12, 30.17s/it]Training Epoch: 1/12, completed (loss: 0.032381631433963776):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:00:55<35:18, 29.83s/it]Training Epoch: 1/12, completed (loss: 0.2000407725572586):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:00:55<35:18, 29.83s/it]  Training Epoch: 1/12, completed (loss: 0.10426584631204605):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:10<35:18, 29.83s/it]Training Epoch: 1/12, completed (loss: 0.10426584631204605):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:24<34:34, 29.63s/it]Training Epoch: 1/12, completed (loss: 0.20914007723331451):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:24<34:34, 29.63s/it]Training Epoch: 1/12, completed (loss: 0.3215583860874176):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:39<34:34, 29.63s/it] Training Epoch: 1/12, completed (loss: 0.3215583860874176):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:01:53<33:53, 29.47s/it]Training Epoch: 1/12, completed (loss: 0.1037273183465004):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:01:53<33:53, 29.47s/it]Training Epoch: 1/12, completed (loss: 0.22066406905651093):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:08<33:53, 29.47s/it]Training Epoch: 1/12, completed (loss: 0.22066406905651093):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:22<33:16, 29.36s/it]Training Epoch: 1/12, completed (loss: 0.20442411303520203):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:23<33:16, 29.36s/it]Training Epoch: 1/12, completed (loss: 0.2453623116016388):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:37<33:16, 29.36s/it] Training Epoch: 1/12, completed (loss: 0.2453623116016388):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:02:52<32:45, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.5096142292022705):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:02:52<32:45, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.15268851816654205):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:06<32:45, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.15268851816654205):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:21<32:14, 29.32s/it]Training Epoch: 1/12, completed (loss: 0.2256898134946823):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:21<32:14, 29.32s/it] Training Epoch: 1/12, completed (loss: 0.06739682704210281):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:36<32:14, 29.32s/it]Training Epoch: 1/12, completed (loss: 0.06739682704210281):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:03:50<31:42, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.2835342288017273):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:03:50<31:42, 29.27s/it] Training Epoch: 1/12, completed (loss: 0.299428254365921):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:05<31:42, 29.27s/it] Training Epoch: 1/12, completed (loss: 0.299428254365921):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:19<31:11, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.15873822569847107):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:19<31:11, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.17838610708713531):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:34<31:11, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.17838610708713531):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:04:48<30:40, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.16606420278549194):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:04:49<30:40, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.15154416859149933):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:03<30:40, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.15154416859149933):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:18<30:08, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.0340745747089386):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:18<30:08, 29.17s/it] Training Epoch: 1/12, completed (loss: 0.2535293996334076):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:32<30:08, 29.17s/it]Training Epoch: 1/12, completed (loss: 0.2535293996334076):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:05:47<29:40, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.002709927037358284):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:05:47<29:40, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.2837136387825012):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:02<29:40, 29.19s/it]  Training Epoch: 1/12, completed (loss: 0.2837136387825012):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:16<29:09, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.30286598205566406):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:16<29:09, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.2740704417228699):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:31<29:09, 29.16s/it] Training Epoch: 1/12, completed (loss: 0.2740704417228699):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:06:45<28:40, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.19795918464660645):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:06:45<28:40, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.46392008662223816):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:00<28:40, 29.16s/it]Training Epoch: 1/12, completed (loss: 0.46392008662223816):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:14<28:10, 29.15s/it]Training Epoch: 1/12, completed (loss: 0.06795455515384674):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:14<28:10, 29.15s/it]Training Epoch: 1/12, completed (loss: 0.37654998898506165):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:29<28:10, 29.15s/it]Training Epoch: 1/12, completed (loss: 0.37654998898506165):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:07:43<27:44, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.2816808521747589):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:07:44<27:44, 29.21s/it] Training Epoch: 1/12, completed (loss: 0.30760353803634644):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:07:58<27:44, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.30760353803634644):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:13<27:16, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.29767540097236633):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:13<27:16, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.20203080773353577):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:28<27:16, 29.23s/it]Training Epoch: 1/12, completed (loss: 0.20203080773353577):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:08:42<26:46, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.14145810902118683):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:08:42<26:46, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.25585123896598816):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:08:57<26:46, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.25585123896598816):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:11<26:17, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.18987779319286346):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:11<26:17, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.21882371604442596):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:26<26:17, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.21882371604442596):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:40<25:47, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.24995753169059753):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:40<25:47, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.21410682797431946):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:55<25:47, 29.20s/it]Training Epoch: 1/12, completed (loss: 0.21410682797431946):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:10<25:18, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.2585553526878357):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:10<25:18, 29.21s/it] Training Epoch: 1/12, completed (loss: 0.27560749650001526):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:24<25:18, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.27560749650001526):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:39<24:53, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.15283066034317017):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:39<24:53, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.33938995003700256):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:54<24:53, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.33938995003700256):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:08<24:22, 29.25s/it]Training Epoch: 1/12, completed (loss: 0.09812301397323608):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:08<24:22, 29.25s/it]Training Epoch: 1/12, completed (loss: 0.5284363031387329):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:23<24:22, 29.25s/it] Training Epoch: 1/12, completed (loss: 0.5284363031387329):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:37<23:54, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.2538970112800598):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:38<23:54, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.3049614131450653):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:52<23:54, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.3049614131450653):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:07<23:24, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.11037448048591614):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:07<23:24, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.018042998388409615):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:21<23:24, 29.27s/it]Training Epoch: 1/12, completed (loss: 0.018042998388409615):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:36<22:51, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.03207673132419586):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:36<22:51, 29.18s/it] Training Epoch: 1/12, completed (loss: 0.21898147463798523):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:51<22:51, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.21898147463798523):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:05<22:22, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.07745757699012756):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:05<22:22, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.12479855120182037):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:20<22:22, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.12479855120182037):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:34<21:53, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.3546082079410553):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:34<21:53, 29.18s/it] Training Epoch: 1/12, completed (loss: 0.35048797726631165):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:49<21:53, 29.18s/it]Training Epoch: 1/12, completed (loss: 0.35048797726631165):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:03<21:26, 29.25s/it]Training Epoch: 1/12, completed (loss: 0.1629299819469452):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:04<21:26, 29.25s/it] Training Epoch: 1/12, completed (loss: 0.07287339121103287):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:18<21:26, 29.25s/it]Training Epoch: 1/12, completed (loss: 0.07287339121103287):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:14:33<20:56, 29.22s/it] eval_ppl=tensor(1.7374, device='cuda:0') eval_epoch_loss=tensor(0.5524, device='cuda:0')
Eval epoch loss:  tensor(0.5524, device='cuda:0') | best_val_loss:  tensor(0.5568, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_1_173
Time while saving:  2023-10-25 18:10:57 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 1 and 173 is 0.5524091720581055
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 1, step_id: 257

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:47,  7.85s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:39,  7.85s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:30,  7.81s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.81s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.85s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:08,  7.84s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<03:00,  7.84s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:52,  7.84s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.87s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.87s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.90s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:21,  7.89s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.92s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.93s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.93s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.90s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:13<01:42,  7.87s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:21<01:34,  7.86s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:29<01:26,  7.86s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:37<01:18,  7.90s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:45<01:10,  7.86s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:02,  7.85s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.86s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:08<00:47,  7.87s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:16<00:39,  7.87s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:24<00:31,  7.85s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:32<00:23,  7.87s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:40<00:15,  7.91s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:48<00:07,  7.90s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:56<00:00,  7.86s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:56<00:00,  7.87s/it]
Training Epoch: 1/12, completed (loss: 0.45590347051620483):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:29<20:56, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.28332841396331787):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:44<20:56, 29.22s/it]Training Epoch: 1/12, completed (loss: 0.28332841396331787):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:18:58<1:10:02, 100.06s/it]Training Epoch: 1/12, completed (loss: 0.06193716451525688):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:18:58<1:10:02, 100.06s/it]Training Epoch: 1/12, completed (loss: 0.24857968091964722):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:13<1:10:02, 100.06s/it]Training Epoch: 1/12, completed (loss: 0.24857968091964722):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:27<53:49, 78.78s/it]   Training Epoch: 1/12, completed (loss: 0.12567386031150818):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:27<53:49, 78.78s/it]Training Epoch: 1/12, completed (loss: 0.005159249994903803):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:42<53:49, 78.78s/it]Training Epoch: 1/12, completed (loss: 0.005159249994903803):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:19:56<42:33, 63.84s/it]Training Epoch: 1/12, completed (loss: 0.13121934235095978):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:19:56<42:33, 63.84s/it] Training Epoch: 1/12, completed (loss: 0.2535111606121063):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:11<42:33, 63.84s/it] Training Epoch: 1/12, completed (loss: 0.2535111606121063):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:25<34:42, 53.41s/it]Training Epoch: 1/12, completed (loss: 0.23410294950008392):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:25<34:42, 53.41s/it]Training Epoch: 1/12, completed (loss: 0.27556535601615906):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:40<34:42, 53.41s/it]Training Epoch: 1/12, completed (loss: 0.27556535601615906):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:20:54<29:15, 46.19s/it]Training Epoch: 1/12, completed (loss: 0.5100682973861694):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:20:55<29:15, 46.19s/it] Training Epoch: 1/12, completed (loss: 0.1022397056221962):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:09<29:15, 46.19s/it]Training Epoch: 1/12, completed (loss: 0.1022397056221962):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:24<25:20, 41.11s/it]Training Epoch: 1/12, completed (loss: 0.13550162315368652):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:24<25:20, 41.11s/it]Training Epoch: 1/12, completed (loss: 0.26465627551078796):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:39<25:20, 41.11s/it]Training Epoch: 1/12, completed (loss: 0.26465627551078796):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:21:53<22:32, 37.57s/it]Training Epoch: 1/12, completed (loss: 0.30615881085395813):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:21:53<22:32, 37.57s/it]Training Epoch: 1/12, completed (loss: 0.08496013283729553):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:08<22:32, 37.57s/it]Training Epoch: 1/12, completed (loss: 0.08496013283729553):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:22<20:28, 35.09s/it]Training Epoch: 1/12, completed (loss: 0.07405489683151245):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:23<20:28, 35.09s/it]Training Epoch: 1/12, completed (loss: 0.01669086329638958):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:37<20:28, 35.09s/it]Training Epoch: 1/12, completed (loss: 0.01669086329638958):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:22:52<18:53, 33.35s/it]Training Epoch: 1/12, completed (loss: 0.032157741487026215):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:22:52<18:53, 33.35s/it]Training Epoch: 1/12, completed (loss: 0.23691457509994507):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:06<18:53, 33.35s/it] Training Epoch: 1/12, completed (loss: 0.23691457509994507):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:21<17:38, 32.08s/it]Training Epoch: 1/12, completed (loss: 0.023345228284597397):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:21<17:38, 32.08s/it]Training Epoch: 1/12, completed (loss: 0.2514720559120178):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:36<17:38, 32.08s/it]  Training Epoch: 1/12, completed (loss: 0.2514720559120178):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:23:50<16:39, 31.25s/it]Training Epoch: 1/12, completed (loss: 0.22007685899734497):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:23:50<16:39, 31.25s/it]Training Epoch: 1/12, completed (loss: 0.08967805653810501):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:05<16:39, 31.25s/it]Training Epoch: 1/12, completed (loss: 0.08967805653810501):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:20<15:52, 30.73s/it]Training Epoch: 1/12, completed (loss: 0.007878243923187256):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:20<15:52, 30.73s/it]Training Epoch: 1/12, completed (loss: 5.0993578042835e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:34<15:52, 30.73s/it] Training Epoch: 1/12, completed (loss: 5.0993578042835e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:24:49<15:07, 30.26s/it]Training Epoch: 1/12, completed (loss: 0.2450554370880127):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:24:49<15:07, 30.26s/it] Training Epoch: 1/12, completed (loss: 0.45484790205955505):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:04<15:07, 30.26s/it]Training Epoch: 1/12, completed (loss: 0.45484790205955505):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:18<14:28, 29.96s/it]Training Epoch: 1/12, completed (loss: 0.3069775402545929):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:18<14:28, 29.96s/it] Training Epoch: 1/12, completed (loss: 0.1323634535074234):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:33<14:28, 29.96s/it]Training Epoch: 1/12, completed (loss: 0.1323634535074234):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:25:47<13:52, 29.74s/it]Training Epoch: 1/12, completed (loss: 0.46455755829811096):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:25:47<13:52, 29.74s/it]Training Epoch: 1/12, completed (loss: 0.5279703736305237):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:02<13:52, 29.74s/it] Training Epoch: 1/12, completed (loss: 0.5279703736305237):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:16<13:18, 29.56s/it]Training Epoch: 1/12, completed (loss: 0.14717410504817963):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:17<13:18, 29.56s/it]Training Epoch: 1/12, completed (loss: 0.12022759020328522):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:31<13:18, 29.56s/it]Training Epoch: 1/12, completed (loss: 0.12022759020328522):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:26:46<12:46, 29.49s/it]Training Epoch: 1/12, completed (loss: 0.2519458830356598):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:26:46<12:46, 29.49s/it] Training Epoch: 1/12, completed (loss: 0.19074738025665283):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:00<12:46, 29.49s/it]Training Epoch: 1/12, completed (loss: 0.19074738025665283):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:15<12:15, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.27015766501426697):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:15<12:15, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.15421618521213531):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:30<12:15, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.15421618521213531):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:27:44<11:46, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.03390150144696236):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:27:45<11:46, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.08895012736320496):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:27:59<11:46, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.08895012736320496):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:14<11:16, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.20922903716564178):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:14<11:16, 29.42s/it]Training Epoch: 1/12, completed (loss: 0.3064062297344208):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:29<11:16, 29.42s/it] Training Epoch: 1/12, completed (loss: 0.3064062297344208):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:28:43<10:46, 29.39s/it]Training Epoch: 1/12, completed (loss: 0.1922667920589447):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:28:43<10:46, 29.39s/it]Training Epoch: 1/12, completed (loss: 0.33410438895225525):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:28:58<10:46, 29.39s/it]Training Epoch: 1/12, completed (loss: 0.33410438895225525):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:12<10:17, 29.39s/it]Training Epoch: 1/12, completed (loss: 0.4664335250854492):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:13<10:17, 29.39s/it] Training Epoch: 1/12, completed (loss: 0.47510117292404175):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:27<10:17, 29.39s/it]Training Epoch: 1/12, completed (loss: 0.47510117292404175):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:29:42<09:47, 29.38s/it]Training Epoch: 1/12, completed (loss: 0.41816389560699463):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:29:42<09:47, 29.38s/it]Training Epoch: 1/12, completed (loss: 0.39317601919174194):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:29:57<09:47, 29.38s/it]Training Epoch: 1/12, completed (loss: 0.39317601919174194):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:11<09:17, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.4373701810836792):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:11<09:17, 29.35s/it] Training Epoch: 1/12, completed (loss: 0.30700597167015076):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:26<09:17, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.30700597167015076):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:30:40<08:48, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.3021029829978943):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:30:41<08:48, 29.34s/it] Training Epoch: 1/12, completed (loss: 0.1932927668094635):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:30:55<08:48, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.1932927668094635):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:10<08:18, 29.33s/it]Training Epoch: 1/12, completed (loss: 0.21062877774238586):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:10<08:18, 29.33s/it]Training Epoch: 1/12, completed (loss: 0.20526984333992004):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:25<08:18, 29.33s/it]Training Epoch: 1/12, completed (loss: 0.20526984333992004):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:31:39<07:49, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.2995258867740631):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:31:39<07:49, 29.31s/it] Training Epoch: 1/12, completed (loss: 0.37981662154197693):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:31:54<07:49, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.37981662154197693):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:08<07:19, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.29644230008125305):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:09<07:19, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.41537564992904663):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:23<07:19, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.41537564992904663):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:32:38<06:49, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.04445570334792137):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:32:38<06:49, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.39521902799606323):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:32:53<06:49, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.39521902799606323):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:07<06:21, 29.36s/it]Training Epoch: 1/12, completed (loss: 0.16151680052280426):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:07<06:21, 29.36s/it]Training Epoch: 1/12, completed (loss: 0.36131855845451355):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:22<06:21, 29.36s/it]Training Epoch: 1/12, completed (loss: 0.36131855845451355):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:36<05:52, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.16250555217266083):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:37<05:52, 29.34s/it]Training Epoch: 1/12, completed (loss: 0.4656704366207123):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:51<05:52, 29.34s/it] Training Epoch: 1/12, completed (loss: 0.4656704366207123):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:06<05:22, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.11223120242357254):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:06<05:22, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.05105053260922432):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:21<05:22, 29.35s/it]Training Epoch: 1/12, completed (loss: 0.05105053260922432):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:35<04:53, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.20525269210338593):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:35<04:53, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.18746180832386017):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:50<04:53, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.18746180832386017):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:04<04:23, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.1634567230939865):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:04<04:23, 29.30s/it] Training Epoch: 1/12, completed (loss: 0.41936635971069336):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:19<04:23, 29.30s/it]Training Epoch: 1/12, completed (loss: 0.41936635971069336):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:33<03:54, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.2096002697944641):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:34<03:54, 29.26s/it] Training Epoch: 1/12, completed (loss: 0.45640310645103455):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:48<03:54, 29.26s/it]Training Epoch: 1/12, completed (loss: 0.45640310645103455):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:03<03:25, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.36960533261299133):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:03<03:25, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.18436594307422638):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:18<03:25, 29.31s/it]Training Epoch: 1/12, completed (loss: 0.18436594307422638):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:32<02:55, 29.32s/it]Training Epoch: 1/12, completed (loss: 0.3853614926338196):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:32<02:55, 29.32s/it] Training Epoch: 1/12, completed (loss: 0.24122852087020874):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:47<02:55, 29.32s/it]Training Epoch: 1/12, completed (loss: 0.24122852087020874):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:01<02:26, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.3471946716308594):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:02<02:26, 29.28s/it] Training Epoch: 1/12, completed (loss: 0.18613570928573608):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:16<02:26, 29.28s/it]Training Epoch: 1/12, completed (loss: 0.18613570928573608):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:31<01:56, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.2340106964111328):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:31<01:56, 29.24s/it] Training Epoch: 1/12, completed (loss: 0.08135458081960678):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:45<01:56, 29.24s/it]Training Epoch: 1/12, completed (loss: 0.08135458081960678):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:00<01:27, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.28875160217285156):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:00<01:27, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.15691113471984863):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:14<01:27, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.15691113471984863):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:29<00:58, 29.15s/it]Training Epoch: 1/12, completed (loss: 0.20372354984283447):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:29<00:58, 29.15s/it]Training Epoch: 1/12, completed (loss: 0.31160038709640503):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:43<00:58, 29.15s/it]Training Epoch: 1/12, completed (loss: 0.31160038709640503):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:38:58<00:29, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.1902390569448471):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:38:58<00:29, 29.19s/it] Training Epoch: 1/12, completed (loss: 0.2512994706630707):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:13<00:29, 29.19s/it]Training Epoch: 1/12, completed (loss: 0.2512994706630707): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:39:27<00:00, 29.21s/it] eval_ppl=tensor(1.7355, device='cuda:0') eval_epoch_loss=tensor(0.5513, device='cuda:0')
Eval epoch loss:  tensor(0.5513, device='cuda:0') | best_val_loss:  tensor(0.5524, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_1_257
Time while saving:  2023-10-25 18:35:20 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 1 and 257 is 0.5512856245040894
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 1, step_id: 343

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.99s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:42,  7.93s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.86s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.86s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.89s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.88s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.87s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.88s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.94s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.92s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.95s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.95s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.90s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.89s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.90s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.90s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.93s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.92s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.89s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.88s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.91s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.92s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.90s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.92s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.91s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.90s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it]
Training Epoch: 1/12, completed (loss: 0.0007373430416919291): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:25<00:00, 29.21s/it]Training Epoch: 1/12, completed (loss: 0.0007373430416919291): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:25<00:00, 36.08s/it]
 eval_ppl=tensor(1.7136, device='cuda:0') eval_epoch_loss=tensor(0.5386, device='cuda:0')
Eval epoch loss:  tensor(0.5386, device='cuda:0') | best_val_loss:  tensor(0.5513, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_1_343
Time while saving:  2023-10-25 19:00:15 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 1 and 343 is 0.5386059880256653
$$$$$$ EVALUATION DONE $$$$$$
Epoch ending time:  2023-10-25 19:00:16 IST+0530
Validation losses are: 
{'epoch_id': 0, 'ministep_id': 1, 'eval_epoch_loss': tensor(2.6360, device='cuda:0'), 'best_val_loss_yet': tensor(2.6360, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6698, device='cuda:0'), 'best_val_loss_yet': tensor(0.6698, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6023, device='cuda:0'), 'best_val_loss_yet': tensor(0.6023, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5568, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5643, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5634, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5644, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5524, device='cuda:0'), 'best_val_loss_yet': tensor(0.5524, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5513, device='cuda:0'), 'best_val_loss_yet': tensor(0.5513, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5386, device='cuda:0'), 'best_val_loss_yet': tensor(0.5386, device='cuda:0')}
$$$%%%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Epoch 1: train_perplexity=1.2658, train_epoch_loss=0.2357, epoch time 6205.489173253998s
Epoch starting time:  2023-10-25 19:00:16 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 2:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training Epoch: 2/12, completed (loss: 0.12735791504383087):   0%|[34m          [0m| 0/172 [00:14<?, ?it/s]Training Epoch: 2/12, completed (loss: 0.12735791504383087):   1%|[34m          [0m| 1/172 [00:29<1:23:03, 29.14s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 2, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:47,  7.85s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:39,  7.84s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:31,  7.82s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:22,  7.79s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:15,  7.83s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:08,  7.87s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:54<03:01,  7.87s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:02<02:52,  7.86s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.86s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.87s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:29,  7.89s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:21,  7.86s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.90s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.92s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:58,  7.93s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:05<01:50,  7.90s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:13<01:42,  7.90s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:21<01:34,  7.91s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:29<01:26,  7.91s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:37<01:19,  7.93s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:45<01:11,  7.92s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.93s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.92s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.92s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.92s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.90s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.93s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.97s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.96s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:56<00:00,  7.91s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:56<00:00,  7.90s/it]
Training Epoch: 2/12, completed (loss: 0.11466497927904129):   1%|[34m          [0m| 1/172 [04:26<1:23:03, 29.14s/it]Training Epoch: 2/12, completed (loss: 0.15782587230205536):   1%|[34m          [0m| 1/172 [04:41<1:23:03, 29.14s/it]Training Epoch: 2/12, completed (loss: 0.15782587230205536):   1%|[34m          [0m| 2/172 [04:55<7:57:53, 168.67s/it]Training Epoch: 2/12, completed (loss: 0.23825427889823914):   1%|[34m          [0m| 2/172 [04:55<7:57:53, 168.67s/it]Training Epoch: 2/12, completed (loss: 0.05747683718800545):   1%|[34m          [0m| 2/172 [05:10<7:57:53, 168.67s/it]Training Epoch: 2/12, completed (loss: 0.05747683718800545):   2%|[34mâ–         [0m| 3/172 [05:24<4:55:56, 105.07s/it]Training Epoch: 2/12, completed (loss: 0.2366124838590622):   2%|[34mâ–         [0m| 3/172 [05:25<4:55:56, 105.07s/it] Training Epoch: 2/12, completed (loss: 0.19308166205883026):   2%|[34mâ–         [0m| 3/172 [05:39<4:55:56, 105.07s/it]Training Epoch: 2/12, completed (loss: 0.19308166205883026):   2%|[34mâ–         [0m| 4/172 [05:53<3:30:15, 75.09s/it] Training Epoch: 2/12, completed (loss: 0.12990614771842957):   2%|[34mâ–         [0m| 4/172 [05:54<3:30:15, 75.09s/it]Training Epoch: 2/12, completed (loss: 0.22151394188404083):   2%|[34mâ–         [0m| 4/172 [06:08<3:30:15, 75.09s/it]Training Epoch: 2/12, completed (loss: 0.22151394188404083):   3%|[34mâ–Ž         [0m| 5/172 [06:23<2:43:01, 58.57s/it]Training Epoch: 2/12, completed (loss: 0.43218111991882324):   3%|[34mâ–Ž         [0m| 5/172 [06:23<2:43:01, 58.57s/it]Training Epoch: 2/12, completed (loss: 0.2954069972038269):   3%|[34mâ–Ž         [0m| 5/172 [06:38<2:43:01, 58.57s/it] Training Epoch: 2/12, completed (loss: 0.2954069972038269):   3%|[34mâ–Ž         [0m| 6/172 [06:52<2:14:17, 48.54s/it]Training Epoch: 2/12, completed (loss: 0.06328950822353363):   3%|[34mâ–Ž         [0m| 6/172 [06:52<2:14:17, 48.54s/it]Training Epoch: 2/12, completed (loss: 0.2978767454624176):   3%|[34mâ–Ž         [0m| 6/172 [07:07<2:14:17, 48.54s/it] Training Epoch: 2/12, completed (loss: 0.2978767454624176):   4%|[34mâ–         [0m| 7/172 [07:21<1:56:14, 42.27s/it]Training Epoch: 2/12, completed (loss: 0.0610695518553257):   4%|[34mâ–         [0m| 7/172 [07:21<1:56:14, 42.27s/it]Training Epoch: 2/12, completed (loss: 0.2091136872768402):   4%|[34mâ–         [0m| 7/172 [07:36<1:56:14, 42.27s/it]Training Epoch: 2/12, completed (loss: 0.2091136872768402):   5%|[34mâ–         [0m| 8/172 [07:51<1:44:16, 38.15s/it]Training Epoch: 2/12, completed (loss: 0.1776265949010849):   5%|[34mâ–         [0m| 8/172 [07:51<1:44:16, 38.15s/it]Training Epoch: 2/12, completed (loss: 0.31271296739578247):   5%|[34mâ–         [0m| 8/172 [08:06<1:44:16, 38.15s/it]Training Epoch: 2/12, completed (loss: 0.31271296739578247):   5%|[34mâ–Œ         [0m| 9/172 [08:20<1:36:15, 35.43s/it]Training Epoch: 2/12, completed (loss: 0.25603511929512024):   5%|[34mâ–Œ         [0m| 9/172 [08:20<1:36:15, 35.43s/it]Training Epoch: 2/12, completed (loss: 0.13344983756542206):   5%|[34mâ–Œ         [0m| 9/172 [08:35<1:36:15, 35.43s/it]Training Epoch: 2/12, completed (loss: 0.13344983756542206):   6%|[34mâ–Œ         [0m| 10/172 [08:49<1:30:18, 33.45s/it]Training Epoch: 2/12, completed (loss: 0.2004958540201187):   6%|[34mâ–Œ         [0m| 10/172 [08:49<1:30:18, 33.45s/it] Training Epoch: 2/12, completed (loss: 0.19255821406841278):   6%|[34mâ–Œ         [0m| 10/172 [09:04<1:30:18, 33.45s/it]Training Epoch: 2/12, completed (loss: 0.19255821406841278):   6%|[34mâ–‹         [0m| 11/172 [09:18<1:26:16, 32.15s/it]Training Epoch: 2/12, completed (loss: 0.21869231760501862):   6%|[34mâ–‹         [0m| 11/172 [09:18<1:26:16, 32.15s/it]Training Epoch: 2/12, completed (loss: 0.22672030329704285):   6%|[34mâ–‹         [0m| 11/172 [09:33<1:26:16, 32.15s/it]Training Epoch: 2/12, completed (loss: 0.22672030329704285):   7%|[34mâ–‹         [0m| 12/172 [09:47<1:23:18, 31.24s/it]Training Epoch: 2/12, completed (loss: 0.15256918966770172):   7%|[34mâ–‹         [0m| 12/172 [09:48<1:23:18, 31.24s/it]Training Epoch: 2/12, completed (loss: 0.09968414157629013):   7%|[34mâ–‹         [0m| 12/172 [10:02<1:23:18, 31.24s/it]Training Epoch: 2/12, completed (loss: 0.09968414157629013):   8%|[34mâ–Š         [0m| 13/172 [10:17<1:21:06, 30.61s/it]Training Epoch: 2/12, completed (loss: 0.030966417863965034):   8%|[34mâ–Š         [0m| 13/172 [10:17<1:21:06, 30.61s/it]Training Epoch: 2/12, completed (loss: 0.36372217535972595):   8%|[34mâ–Š         [0m| 13/172 [10:31<1:21:06, 30.61s/it] Training Epoch: 2/12, completed (loss: 0.36372217535972595):   8%|[34mâ–Š         [0m| 14/172 [10:46<1:19:36, 30.23s/it]Training Epoch: 2/12, completed (loss: 0.3416576087474823):   8%|[34mâ–Š         [0m| 14/172 [10:46<1:19:36, 30.23s/it] Training Epoch: 2/12, completed (loss: 0.11839430034160614):   8%|[34mâ–Š         [0m| 14/172 [11:01<1:19:36, 30.23s/it]Training Epoch: 2/12, completed (loss: 0.11839430034160614):   9%|[34mâ–Š         [0m| 15/172 [11:15<1:18:17, 29.92s/it]Training Epoch: 2/12, completed (loss: 0.19632023572921753):   9%|[34mâ–Š         [0m| 15/172 [11:15<1:18:17, 29.92s/it]Training Epoch: 2/12, completed (loss: 0.13882112503051758):   9%|[34mâ–Š         [0m| 15/172 [11:30<1:18:17, 29.92s/it]Training Epoch: 2/12, completed (loss: 0.13882112503051758):   9%|[34mâ–‰         [0m| 16/172 [11:45<1:17:25, 29.78s/it]Training Epoch: 2/12, completed (loss: 0.1739029586315155):   9%|[34mâ–‰         [0m| 16/172 [11:45<1:17:25, 29.78s/it] Training Epoch: 2/12, completed (loss: 0.37138059735298157):   9%|[34mâ–‰         [0m| 16/172 [11:59<1:17:25, 29.78s/it]Training Epoch: 2/12, completed (loss: 0.37138059735298157):  10%|[34mâ–‰         [0m| 17/172 [12:14<1:16:37, 29.66s/it]Training Epoch: 2/12, completed (loss: 0.24865135550498962):  10%|[34mâ–‰         [0m| 17/172 [12:14<1:16:37, 29.66s/it]Training Epoch: 2/12, completed (loss: 0.19803375005722046):  10%|[34mâ–‰         [0m| 17/172 [12:29<1:16:37, 29.66s/it]Training Epoch: 2/12, completed (loss: 0.19803375005722046):  10%|[34mâ–ˆ         [0m| 18/172 [12:43<1:15:44, 29.51s/it]Training Epoch: 2/12, completed (loss: 0.2137327939271927):  10%|[34mâ–ˆ         [0m| 18/172 [12:43<1:15:44, 29.51s/it] Training Epoch: 2/12, completed (loss: 0.1989148110151291):  10%|[34mâ–ˆ         [0m| 18/172 [12:58<1:15:44, 29.51s/it]Training Epoch: 2/12, completed (loss: 0.1989148110151291):  11%|[34mâ–ˆ         [0m| 19/172 [13:12<1:15:05, 29.45s/it]Training Epoch: 2/12, completed (loss: 0.05312112718820572):  11%|[34mâ–ˆ         [0m| 19/172 [13:13<1:15:05, 29.45s/it]Training Epoch: 2/12, completed (loss: 0.3531336188316345):  11%|[34mâ–ˆ         [0m| 19/172 [13:27<1:15:05, 29.45s/it] Training Epoch: 2/12, completed (loss: 0.3531336188316345):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:42<1:14:23, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.045871391892433167):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:42<1:14:23, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.2852649688720703):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:56<1:14:23, 29.37s/it]  Training Epoch: 2/12, completed (loss: 0.2852649688720703):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:11<1:13:54, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.08253215998411179):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:11<1:13:54, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.07060202956199646):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:26<1:13:54, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.07060202956199646):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:40<1:13:26, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.5988070964813232):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:41<1:13:26, 29.37s/it] Training Epoch: 2/12, completed (loss: 0.5088691115379333):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:55<1:13:26, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.5088691115379333):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:10<1:12:59, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.16600485146045685):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:10<1:12:59, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.33467456698417664):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:25<1:12:59, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.33467456698417664):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:39<1:12:27, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.387413889169693):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:39<1:12:27, 29.38s/it]  Training Epoch: 2/12, completed (loss: 0.07480943948030472):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:54<1:12:27, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.07480943948030472):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:08<1:11:53, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.03454575315117836):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:09<1:11:53, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.1918562948703766):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:23<1:11:53, 29.34s/it] Training Epoch: 2/12, completed (loss: 0.1918562948703766):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:38<1:11:22, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.2825428545475006):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:38<1:11:22, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.1561218500137329):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:53<1:11:22, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.1561218500137329):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:07<1:10:49, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.26605290174484253):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:07<1:10:49, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.1924072802066803):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:22<1:10:49, 29.31s/it] Training Epoch: 2/12, completed (loss: 0.1924072802066803):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:36<1:10:22, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.09386981278657913):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:36<1:10:22, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.36284369230270386):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:51<1:10:22, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.36284369230270386):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:06<1:09:53, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.26240983605384827):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:06<1:09:53, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.22195661067962646):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:20<1:09:53, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.22195661067962646):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:35<1:09:22, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.40954363346099854):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:35<1:09:22, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.060208842158317566):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:50<1:09:22, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.060208842158317566):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:04<1:08:53, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.12192664295434952):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:04<1:08:53, 29.32s/it] Training Epoch: 2/12, completed (loss: 0.19225308299064636):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:19<1:08:53, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.19225308299064636):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:34<1:08:29, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.090244822204113):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:34<1:08:29, 29.35s/it]  Training Epoch: 2/12, completed (loss: 0.19633229076862335):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:48<1:08:29, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.19633229076862335):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:03<1:07:55, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.21451355516910553):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:03<1:07:55, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.3419926166534424):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:18<1:07:55, 29.32s/it] Training Epoch: 2/12, completed (loss: 0.3419926166534424):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:32<1:07:26, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.29464566707611084):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:32<1:07:26, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.18967340886592865):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:47<1:07:26, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.18967340886592865):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:02<1:06:59, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.03838425129652023):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:02<1:06:59, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.13949601352214813):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:17<1:06:59, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.13949601352214813):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:31<1:06:32, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.1370609700679779):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:31<1:06:32, 29.36s/it] Training Epoch: 2/12, completed (loss: 0.10508313775062561):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:46<1:06:32, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.10508313775062561):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:00<1:06:03, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.11788301914930344):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:01<1:06:03, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.19793283939361572):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:15<1:06:03, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.19793283939361572):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:29<1:05:25, 29.29s/it]Training Epoch: 2/12, completed (loss: 0.02091628685593605):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:30<1:05:25, 29.29s/it]Training Epoch: 2/12, completed (loss: 0.42564821243286133):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:44<1:05:25, 29.29s/it]Training Epoch: 2/12, completed (loss: 0.42564821243286133):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:59<1:04:55, 29.29s/it]Training Epoch: 2/12, completed (loss: 0.10966220498085022):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:59<1:04:55, 29.29s/it]Training Epoch: 2/12, completed (loss: 0.34456899762153625):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:14<1:04:55, 29.29s/it]Training Epoch: 2/12, completed (loss: 0.34456899762153625):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:28<1:04:23, 29.27s/it]Training Epoch: 2/12, completed (loss: 0.24846848845481873):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:28<1:04:23, 29.27s/it]Training Epoch: 2/12, completed (loss: 0.20317675173282623):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:43<1:04:23, 29.27s/it]Training Epoch: 2/12, completed (loss: 0.20317675173282623):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:57<1:04:00, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.17360687255859375):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:58<1:04:00, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.041768286377191544):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:12<1:04:00, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.041768286377191544):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:27<1:03:35, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.1550716906785965):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:27<1:03:35, 29.35s/it]  Training Epoch: 2/12, completed (loss: 0.12028217315673828):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:42<1:03:35, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.12028217315673828):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:56<1:03:04, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.09014572203159332):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:56<1:03:04, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.449849933385849):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:11<1:03:04, 29.34s/it]  Training Epoch: 2/12, completed (loss: 0.449849933385849):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:25<1:02:33, 29.33s/it] eval_ppl=tensor(1.7109, device='cuda:0') eval_epoch_loss=tensor(0.5370, device='cuda:0')
Eval epoch loss:  tensor(0.5370, device='cuda:0') | best_val_loss:  tensor(0.5386, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/best_model_yet_epoch_2_1
Time while saving:  2023-10-25 19:04:42 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
best eval loss on epoch 2 and 1 is 0.5370364785194397
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 2, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.98s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.93s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.89s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.86s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.90s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:45,  7.90s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.90s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.90s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.90s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.93s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.94s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.91s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.92s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.94s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.93s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:04,  8.01s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.99s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  8.00s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.98s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:26<00:31,  7.95s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.94s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.97s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:50<00:07,  7.95s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it]
Training Epoch: 2/12, completed (loss: 0.33985722064971924):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:24<1:02:33, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.1977563053369522):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:38<1:02:33, 29.33s/it] Training Epoch: 2/12, completed (loss: 0.1977563053369522):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:53<3:33:13, 100.74s/it]Training Epoch: 2/12, completed (loss: 0.036268655210733414):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:53<3:33:13, 100.74s/it]Training Epoch: 2/12, completed (loss: 0.33881667256355286):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [30:08<3:33:13, 100.74s/it] Training Epoch: 2/12, completed (loss: 0.33881667256355286):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:22<2:46:22, 79.22s/it] Training Epoch: 2/12, completed (loss: 0.09708914905786514):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:22<2:46:22, 79.22s/it]Training Epoch: 2/12, completed (loss: 0.1835588961839676):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:37<2:46:22, 79.22s/it] Training Epoch: 2/12, completed (loss: 0.1835588961839676):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:51<2:13:57, 64.30s/it]Training Epoch: 2/12, completed (loss: 0.14734435081481934):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:52<2:13:57, 64.30s/it]Training Epoch: 2/12, completed (loss: 0.33371099829673767):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [31:06<2:13:57, 64.30s/it]Training Epoch: 2/12, completed (loss: 0.33371099829673767):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:21<1:51:09, 53.79s/it]Training Epoch: 2/12, completed (loss: 0.05449453741312027):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:21<1:51:09, 53.79s/it]Training Epoch: 2/12, completed (loss: 0.14318068325519562):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:35<1:51:09, 53.79s/it]Training Epoch: 2/12, completed (loss: 0.14318068325519562):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:50<1:35:10, 46.43s/it]Training Epoch: 2/12, completed (loss: 0.010055436752736568):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:50<1:35:10, 46.43s/it]Training Epoch: 2/12, completed (loss: 0.4384317696094513):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [32:05<1:35:10, 46.43s/it]  Training Epoch: 2/12, completed (loss: 0.4384317696094513):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:19<1:23:56, 41.28s/it]Training Epoch: 2/12, completed (loss: 0.16771060228347778):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:19<1:23:56, 41.28s/it]Training Epoch: 2/12, completed (loss: 0.32560527324676514):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:34<1:23:56, 41.28s/it]Training Epoch: 2/12, completed (loss: 0.32560527324676514):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:48<1:15:55, 37.65s/it]Training Epoch: 2/12, completed (loss: 0.1247960552573204):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:49<1:15:55, 37.65s/it] Training Epoch: 2/12, completed (loss: 0.28478461503982544):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [33:03<1:15:55, 37.65s/it]Training Epoch: 2/12, completed (loss: 0.28478461503982544):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:18<1:10:26, 35.22s/it]Training Epoch: 2/12, completed (loss: 0.18936143815517426):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:18<1:10:26, 35.22s/it]Training Epoch: 2/12, completed (loss: 0.4235031306743622):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:33<1:10:26, 35.22s/it] Training Epoch: 2/12, completed (loss: 0.4235031306743622):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:47<1:06:20, 33.45s/it]Training Epoch: 2/12, completed (loss: 0.08508394658565521):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:47<1:06:20, 33.45s/it]Training Epoch: 2/12, completed (loss: 0.18874257802963257):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [34:02<1:06:20, 33.45s/it]Training Epoch: 2/12, completed (loss: 0.18874257802963257):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:16<1:03:21, 32.21s/it]Training Epoch: 2/12, completed (loss: 0.0995418131351471):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:17<1:03:21, 32.21s/it] Training Epoch: 2/12, completed (loss: 0.23269617557525635):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:31<1:03:21, 32.21s/it]Training Epoch: 2/12, completed (loss: 0.23269617557525635):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:46<1:01:06, 31.34s/it]Training Epoch: 2/12, completed (loss: 0.1135522797703743):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:46<1:01:06, 31.34s/it] Training Epoch: 2/12, completed (loss: 0.08132386952638626):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [35:01<1:01:06, 31.34s/it]Training Epoch: 2/12, completed (loss: 0.08132386952638626):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:15<59:26, 30.75s/it]  Training Epoch: 2/12, completed (loss: 0.33396270871162415):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:15<59:26, 30.75s/it]Training Epoch: 2/12, completed (loss: 0.27095699310302734):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:30<59:26, 30.75s/it]Training Epoch: 2/12, completed (loss: 0.27095699310302734):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:45<58:09, 30.35s/it]Training Epoch: 2/12, completed (loss: 0.2743876278400421):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:45<58:09, 30.35s/it] Training Epoch: 2/12, completed (loss: 0.007502618711441755):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:59<58:09, 30.35s/it]Training Epoch: 2/12, completed (loss: 0.007502618711441755):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:14<57:06, 30.05s/it]Training Epoch: 2/12, completed (loss: 0.28929680585861206):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:14<57:06, 30.05s/it] Training Epoch: 2/12, completed (loss: 0.3276923894882202):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:29<57:06, 30.05s/it] Training Epoch: 2/12, completed (loss: 0.3276923894882202):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:43<56:17, 29.89s/it]Training Epoch: 2/12, completed (loss: 0.1533074975013733):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:44<56:17, 29.89s/it]Training Epoch: 2/12, completed (loss: 0.11271414160728455):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:58<56:17, 29.89s/it]Training Epoch: 2/12, completed (loss: 0.11271414160728455):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:13<55:22, 29.67s/it]Training Epoch: 2/12, completed (loss: 0.0764428898692131):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:13<55:22, 29.67s/it] Training Epoch: 2/12, completed (loss: 0.3188534080982208):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:28<55:22, 29.67s/it]Training Epoch: 2/12, completed (loss: 0.3188534080982208):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:42<54:45, 29.60s/it]Training Epoch: 2/12, completed (loss: 0.06986868381500244):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:42<54:45, 29.60s/it]Training Epoch: 2/12, completed (loss: 0.00036264208029024303):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:57<54:45, 29.60s/it]Training Epoch: 2/12, completed (loss: 0.00036264208029024303):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:11<54:09, 29.54s/it]Training Epoch: 2/12, completed (loss: 0.354106068611145):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:12<54:09, 29.54s/it]     Training Epoch: 2/12, completed (loss: 0.4847060739994049):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:26<54:09, 29.54s/it]Training Epoch: 2/12, completed (loss: 0.4847060739994049):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:41<53:30, 29.45s/it]Training Epoch: 2/12, completed (loss: 0.5187389254570007):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:41<53:30, 29.45s/it]Training Epoch: 2/12, completed (loss: 0.08816348761320114):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:56<53:30, 29.45s/it]Training Epoch: 2/12, completed (loss: 0.08816348761320114):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:10<53:00, 29.45s/it]Training Epoch: 2/12, completed (loss: 0.17279013991355896):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:10<53:00, 29.45s/it]Training Epoch: 2/12, completed (loss: 0.1914878636598587):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:25<53:00, 29.45s/it] Training Epoch: 2/12, completed (loss: 0.1914878636598587):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:39<52:27, 29.42s/it]Training Epoch: 2/12, completed (loss: 0.11649850010871887):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:40<52:27, 29.42s/it]Training Epoch: 2/12, completed (loss: 0.2581983506679535):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:54<52:27, 29.42s/it] Training Epoch: 2/12, completed (loss: 0.2581983506679535):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:09<51:56, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.180332750082016):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:09<51:56, 29.40s/it] Training Epoch: 2/12, completed (loss: 0.13092155754566193):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:24<51:56, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.13092155754566193):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:38<51:25, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.10107888281345367):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:38<51:25, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.13740390539169312):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:53<51:25, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.13740390539169312):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:08<50:54, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.13978837430477142):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:08<50:54, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.3312913179397583):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:22<50:54, 29.37s/it] Training Epoch: 2/12, completed (loss: 0.3312913179397583):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:37<50:18, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.028487063944339752):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:37<50:18, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.1880652904510498):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:52<50:18, 29.31s/it]  Training Epoch: 2/12, completed (loss: 0.1880652904510498):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:06<49:52, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.4834557771682739):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:06<49:52, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.1732056736946106):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:21<49:52, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.1732056736946106):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:36<49:26, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.3469528257846832):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:36<49:26, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.1813098043203354):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:50<49:26, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.1813098043203354):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:05<48:54, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.16086766123771667):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:05<48:54, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.3711475729942322):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:20<48:54, 29.34s/it] Training Epoch: 2/12, completed (loss: 0.3711475729942322):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:34<48:26, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.012099777348339558):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:34<48:26, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.22167420387268066):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:49<48:26, 29.36s/it] Training Epoch: 2/12, completed (loss: 0.22167420387268066):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:03<47:53, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.22867059707641602):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:04<47:53, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.24836209416389465):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:18<47:53, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.24836209416389465):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:33<47:26, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.19125424325466156):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:33<47:26, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.0994587391614914):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:48<47:26, 29.34s/it] Training Epoch: 2/12, completed (loss: 0.0994587391614914):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:02<46:55, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.24083669483661652):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:02<46:55, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.16425246000289917):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:17<46:55, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.16425246000289917):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:31<46:23, 29.30s/it]Training Epoch: 2/12, completed (loss: 0.2750113606452942):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:32<46:23, 29.30s/it] Training Epoch: 2/12, completed (loss: 0.05013110861182213):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:46<46:23, 29.30s/it]Training Epoch: 2/12, completed (loss: 0.05013110861182213):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:01<45:55, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.16420328617095947):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:01<45:55, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.17325039207935333):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:16<45:55, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.17325039207935333):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:30<45:25, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.14534863829612732):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:30<45:25, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.24691152572631836):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:45<45:25, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.24691152572631836):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:59<44:51, 29.26s/it]Training Epoch: 2/12, completed (loss: 0.03811796009540558):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:59<44:51, 29.26s/it]Training Epoch: 2/12, completed (loss: 0.31289902329444885):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:14<44:51, 29.26s/it]Training Epoch: 2/12, completed (loss: 0.31289902329444885):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:29<44:26, 29.30s/it]Training Epoch: 2/12, completed (loss: 0.05405848100781441):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:29<44:26, 29.30s/it]Training Epoch: 2/12, completed (loss: 0.147158682346344):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:43<44:26, 29.30s/it]  Training Epoch: 2/12, completed (loss: 0.147158682346344):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:58<43:57, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.2624702751636505):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:58<43:57, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.29989108443260193):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:13<43:57, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.29989108443260193):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:27<43:30, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.35311591625213623):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:27<43:30, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.25587502121925354):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:42<43:30, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.25587502121925354):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:57<43:02, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.32262369990348816):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:57<43:02, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.13785704970359802):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [49:12<43:02, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.13785704970359802):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:26<42:33, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.4341913163661957):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:26<42:33, 29.35s/it] Training Epoch: 2/12, completed (loss: 0.2995123565196991):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:41<42:33, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.2995123565196991):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:55<42:05, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.2781331539154053):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:56<42:05, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.3652093708515167):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [50:10<42:05, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.3652093708515167):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [50:25<41:34, 29.35s/it] eval_ppl=tensor(1.7805, device='cuda:0') eval_epoch_loss=tensor(0.5769, device='cuda:0')
Eval epoch loss:  tensor(0.5769, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_2_87
Time while saving:  2023-10-25 19:29:40 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 2, step_id: 173

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:48,  7.88s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:40,  7.89s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:31,  7.84s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.85s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.91s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.88s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.90s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.90s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.91s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.92s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.90s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.97s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.96s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.94s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.94s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.93s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.91s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.94s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.92s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.90s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.91s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.92s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.93s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.91s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.95s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.90s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it]
Training Epoch: 2/12, completed (loss: 0.09790969640016556):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:23<41:34, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.031547363847494125):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:38<41:34, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.031547363847494125):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:52<2:21:06, 100.79s/it]Training Epoch: 2/12, completed (loss: 0.15884482860565186):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:52<2:21:06, 100.79s/it] Training Epoch: 2/12, completed (loss: 0.24514469504356384):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [55:07<2:21:06, 100.79s/it]Training Epoch: 2/12, completed (loss: 0.24514469504356384):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:22<1:49:46, 79.36s/it] Training Epoch: 2/12, completed (loss: 0.06458183377981186):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:22<1:49:46, 79.36s/it]Training Epoch: 2/12, completed (loss: 0.19334882497787476):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:36<1:49:46, 79.36s/it]Training Epoch: 2/12, completed (loss: 0.19334882497787476):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:51<1:27:58, 64.37s/it]Training Epoch: 2/12, completed (loss: 0.4396584928035736):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:51<1:27:58, 64.37s/it] Training Epoch: 2/12, completed (loss: 0.13532252609729767):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [56:06<1:27:58, 64.37s/it]Training Epoch: 2/12, completed (loss: 0.13532252609729767):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:20<1:12:45, 53.90s/it]Training Epoch: 2/12, completed (loss: 0.2628057301044464):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:21<1:12:45, 53.90s/it] Training Epoch: 2/12, completed (loss: 0.17842866480350494):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:35<1:12:45, 53.90s/it]Training Epoch: 2/12, completed (loss: 0.17842866480350494):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:50<1:02:02, 46.53s/it]Training Epoch: 2/12, completed (loss: 0.30045467615127563):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:50<1:02:02, 46.53s/it]Training Epoch: 2/12, completed (loss: 0.0966091975569725):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [57:05<1:02:02, 46.53s/it] Training Epoch: 2/12, completed (loss: 0.0966091975569725):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:19<54:33, 41.43s/it]  Training Epoch: 2/12, completed (loss: 0.33021146059036255):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:19<54:33, 41.43s/it]Training Epoch: 2/12, completed (loss: 0.18414653837680817):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:34<54:33, 41.43s/it]Training Epoch: 2/12, completed (loss: 0.18414653837680817):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:49<49:09, 37.82s/it]Training Epoch: 2/12, completed (loss: 0.18365666270256042):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:49<49:09, 37.82s/it]Training Epoch: 2/12, completed (loss: 0.5051894187927246):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [58:04<49:09, 37.82s/it] Training Epoch: 2/12, completed (loss: 0.5051894187927246):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:18<45:17, 35.29s/it]Training Epoch: 2/12, completed (loss: 0.09734534472227097):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:18<45:17, 35.29s/it]Training Epoch: 2/12, completed (loss: 0.08034870773553848):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:33<45:17, 35.29s/it]Training Epoch: 2/12, completed (loss: 0.08034870773553848):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:48<42:31, 33.57s/it]Training Epoch: 2/12, completed (loss: 0.2070065140724182):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:48<42:31, 33.57s/it] Training Epoch: 2/12, completed (loss: 0.3508453667163849):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [59:03<42:31, 33.57s/it]Training Epoch: 2/12, completed (loss: 0.3508453667163849):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:17<40:25, 32.34s/it]Training Epoch: 2/12, completed (loss: 0.16535143554210663):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:17<40:25, 32.34s/it]Training Epoch: 2/12, completed (loss: 0.2599243223667145):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:32<40:25, 32.34s/it] Training Epoch: 2/12, completed (loss: 0.2599243223667145):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:46<38:45, 31.42s/it]Training Epoch: 2/12, completed (loss: 0.23843833804130554):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:47<38:45, 31.42s/it]Training Epoch: 2/12, completed (loss: 0.29417163133621216):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [1:00:01<38:45, 31.42s/it]Training Epoch: 2/12, completed (loss: 0.29417163133621216):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:16<37:30, 30.83s/it]Training Epoch: 2/12, completed (loss: 0.1278359293937683):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:16<37:30, 30.83s/it] Training Epoch: 2/12, completed (loss: 0.20831967890262604):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:31<37:30, 30.83s/it]Training Epoch: 2/12, completed (loss: 0.20831967890262604):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:45<36:26, 30.36s/it]Training Epoch: 2/12, completed (loss: 0.022905226796865463):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:45<36:26, 30.36s/it]Training Epoch: 2/12, completed (loss: 0.06772014498710632):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:01:00<36:26, 30.36s/it] Training Epoch: 2/12, completed (loss: 0.06772014498710632):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:14<35:33, 30.05s/it]Training Epoch: 2/12, completed (loss: 0.20374052226543427):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:15<35:33, 30.05s/it]Training Epoch: 2/12, completed (loss: 0.07577390968799591):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:29<35:33, 30.05s/it]Training Epoch: 2/12, completed (loss: 0.07577390968799591):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:44<34:49, 29.84s/it]Training Epoch: 2/12, completed (loss: 0.18221496045589447):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:44<34:49, 29.84s/it]Training Epoch: 2/12, completed (loss: 0.22726035118103027):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:59<34:49, 29.84s/it]Training Epoch: 2/12, completed (loss: 0.22726035118103027):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:13<34:08, 29.69s/it]Training Epoch: 2/12, completed (loss: 0.20475904643535614):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:13<34:08, 29.69s/it]Training Epoch: 2/12, completed (loss: 0.13333489000797272):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:28<34:08, 29.69s/it]Training Epoch: 2/12, completed (loss: 0.13333489000797272):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:42<33:31, 29.58s/it]Training Epoch: 2/12, completed (loss: 0.15811794996261597):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:43<33:31, 29.58s/it]Training Epoch: 2/12, completed (loss: 0.24466019868850708):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:57<33:31, 29.58s/it]Training Epoch: 2/12, completed (loss: 0.24466019868850708):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:12<32:58, 29.54s/it]Training Epoch: 2/12, completed (loss: 0.4162169098854065):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:12<32:58, 29.54s/it] Training Epoch: 2/12, completed (loss: 0.0977795422077179):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:27<32:58, 29.54s/it]Training Epoch: 2/12, completed (loss: 0.0977795422077179):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:41<32:26, 29.49s/it]Training Epoch: 2/12, completed (loss: 0.18490652740001678):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:41<32:26, 29.49s/it]Training Epoch: 2/12, completed (loss: 0.061915162950754166):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:56<32:26, 29.49s/it]Training Epoch: 2/12, completed (loss: 0.061915162950754166):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:10<31:51, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.2559993863105774):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:11<31:51, 29.41s/it]  Training Epoch: 2/12, completed (loss: 0.20082184672355652):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:25<31:51, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.20082184672355652):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:40<31:20, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.14921621978282928):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:40<31:20, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.15473657846450806):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:55<31:20, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.15473657846450806):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:09<30:49, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.1684187352657318):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:09<30:49, 29.35s/it] Training Epoch: 2/12, completed (loss: 0.12042868137359619):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:24<30:49, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.12042868137359619):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:38<30:17, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.035459067672491074):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:39<30:17, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.3089929521083832):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:53<30:17, 29.32s/it]  Training Epoch: 2/12, completed (loss: 0.3089929521083832):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:08<29:48, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.004813333973288536):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:08<29:48, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.221934974193573):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:23<29:48, 29.32s/it]   Training Epoch: 2/12, completed (loss: 0.221934974193573):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:37<29:19, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.29678237438201904):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:37<29:19, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.2573980689048767):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:52<29:19, 29.32s/it] Training Epoch: 2/12, completed (loss: 0.2573980689048767):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:06<28:50, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.09530039876699448):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:07<28:50, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.4202875792980194):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:21<28:50, 29.33s/it] Training Epoch: 2/12, completed (loss: 0.4202875792980194):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:36<28:20, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.05486925691366196):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:36<28:20, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.2422875612974167):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:51<28:20, 29.31s/it] Training Epoch: 2/12, completed (loss: 0.2422875612974167):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:05<27:52, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.2513933777809143):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:05<27:52, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.3053859770298004):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:20<27:52, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.3053859770298004):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:34<27:23, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.2867313027381897):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:35<27:23, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.2018534541130066):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:49<27:23, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.2018534541130066):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:04<26:55, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.12281142920255661):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:04<26:55, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.22143620252609253):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:19<26:55, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.22143620252609253):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:33<26:26, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.16579784452915192):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:33<26:26, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.11818806827068329):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:48<26:26, 29.38s/it]Training Epoch: 2/12, completed (loss: 0.11818806827068329):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:02<25:54, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.24997413158416748):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:03<25:54, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.19421742856502533):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:17<25:54, 29.33s/it]Training Epoch: 2/12, completed (loss: 0.19421742856502533):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:32<25:26, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.21347765624523163):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:32<25:26, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.27339306473731995):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:47<25:26, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.27339306473731995):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:01<25:00, 29.43s/it]Training Epoch: 2/12, completed (loss: 0.09943950176239014):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:02<25:00, 29.43s/it]Training Epoch: 2/12, completed (loss: 0.3180740177631378):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:16<25:00, 29.43s/it] Training Epoch: 2/12, completed (loss: 0.3180740177631378):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:31<24:29, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.02546682022511959):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:31<24:29, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.4695981442928314):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:46<24:29, 29.39s/it] Training Epoch: 2/12, completed (loss: 0.4695981442928314):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:00<24:00, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.21959611773490906):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:00<24:00, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.29352208971977234):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:15<24:00, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.29352208971977234):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:30<23:31, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.07435295730829239):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:30<23:31, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.0011006771819666028):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:44<23:31, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.0011006771819666028):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:59<22:58, 29.34s/it]Training Epoch: 2/12, completed (loss: 0.023205075412988663):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:59<22:58, 29.34s/it] Training Epoch: 2/12, completed (loss: 0.1834169626235962):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:14<22:58, 29.34s/it]  Training Epoch: 2/12, completed (loss: 0.1834169626235962):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:28<22:30, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.03215676546096802):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:28<22:30, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.05810708552598953):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:43<22:30, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.05810708552598953):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:57<22:00, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.3505437672138214):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:58<22:00, 29.35s/it] Training Epoch: 2/12, completed (loss: 0.25913554430007935):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:14:12<22:00, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.25913554430007935):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:27<21:33, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.15044158697128296):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:27<21:33, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.05548364296555519):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:42<21:33, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.05548364296555519):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:14:56<21:03, 29.37s/it] eval_ppl=tensor(1.7785, device='cuda:0') eval_epoch_loss=tensor(0.5758, device='cuda:0')
Eval epoch loss:  tensor(0.5758, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_2_173
Time while saving:  2023-10-25 19:54:39 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 2, step_id: 257

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:49,  7.92s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.91s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.86s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.87s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.88s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.88s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.90s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.91s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.93s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.91s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.97s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.95s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.93s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.93s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.94s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.92s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.92s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.88s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.92s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.93s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.92s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.93s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.95s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.91s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.90s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it]
Training Epoch: 2/12, completed (loss: 0.3815254271030426):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:54<21:03, 29.37s/it] Training Epoch: 2/12, completed (loss: 0.18540604412555695):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:19:09<21:03, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.18540604412555695):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:23<1:10:26, 100.62s/it]Training Epoch: 2/12, completed (loss: 0.056741900742053986):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:23<1:10:26, 100.62s/it]Training Epoch: 2/12, completed (loss: 0.17139489948749542):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:38<1:10:26, 100.62s/it] Training Epoch: 2/12, completed (loss: 0.17139489948749542):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:52<54:08, 79.22s/it]   Training Epoch: 2/12, completed (loss: 0.061204057186841965):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:53<54:08, 79.22s/it]Training Epoch: 2/12, completed (loss: 0.0010913168080151081):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:20:07<54:08, 79.22s/it]Training Epoch: 2/12, completed (loss: 0.0010913168080151081):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:22<42:48, 64.21s/it]Training Epoch: 2/12, completed (loss: 0.0749453753232956):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:22<42:48, 64.21s/it]   Training Epoch: 2/12, completed (loss: 0.18367980420589447):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:37<42:48, 64.21s/it]Training Epoch: 2/12, completed (loss: 0.18367980420589447):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:51<34:56, 53.74s/it]Training Epoch: 2/12, completed (loss: 0.17059502005577087):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:51<34:56, 53.74s/it]Training Epoch: 2/12, completed (loss: 0.24119976162910461):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:21:06<34:56, 53.74s/it]Training Epoch: 2/12, completed (loss: 0.24119976162910461):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:20<29:26, 46.48s/it]Training Epoch: 2/12, completed (loss: 0.5139248967170715):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:21<29:26, 46.48s/it] Training Epoch: 2/12, completed (loss: 0.05015687271952629):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:35<29:26, 46.48s/it]Training Epoch: 2/12, completed (loss: 0.05015687271952629):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:50<25:29, 41.34s/it]Training Epoch: 2/12, completed (loss: 0.1200278177857399):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:50<25:29, 41.34s/it] Training Epoch: 2/12, completed (loss: 0.11272695660591125):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:22:05<25:29, 41.34s/it]Training Epoch: 2/12, completed (loss: 0.11272695660591125):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:19<22:38, 37.75s/it]Training Epoch: 2/12, completed (loss: 0.24834489822387695):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:19<22:38, 37.75s/it]Training Epoch: 2/12, completed (loss: 0.06338168680667877):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:34<22:38, 37.75s/it]Training Epoch: 2/12, completed (loss: 0.06338168680667877):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:49<20:33, 35.26s/it]Training Epoch: 2/12, completed (loss: 0.04522376134991646):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:49<20:33, 35.26s/it]Training Epoch: 2/12, completed (loss: 0.0010299021378159523):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:23:03<20:33, 35.26s/it]Training Epoch: 2/12, completed (loss: 0.0010299021378159523):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:18<18:58, 33.48s/it]Training Epoch: 2/12, completed (loss: 0.027145560830831528):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:18<18:58, 33.48s/it] Training Epoch: 2/12, completed (loss: 0.1782507747411728):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:33<18:58, 33.48s/it]  Training Epoch: 2/12, completed (loss: 0.1782507747411728):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:47<17:43, 32.22s/it]Training Epoch: 2/12, completed (loss: 0.10944995284080505):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:47<17:43, 32.22s/it]Training Epoch: 2/12, completed (loss: 0.22285056114196777):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:24:02<17:43, 32.22s/it]Training Epoch: 2/12, completed (loss: 0.22285056114196777):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:17<16:44, 31.38s/it]Training Epoch: 2/12, completed (loss: 0.19159093499183655):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:17<16:44, 31.38s/it]Training Epoch: 2/12, completed (loss: 0.07531113177537918):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:32<16:44, 31.38s/it]Training Epoch: 2/12, completed (loss: 0.07531113177537918):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:46<15:56, 30.85s/it]Training Epoch: 2/12, completed (loss: 0.0380447581410408):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:46<15:56, 30.85s/it] Training Epoch: 2/12, completed (loss: 4.01585093641188e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:25:01<15:56, 30.85s/it]Training Epoch: 2/12, completed (loss: 4.01585093641188e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:15<15:10, 30.36s/it]Training Epoch: 2/12, completed (loss: 0.2253432422876358):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:16<15:10, 30.36s/it]  Training Epoch: 2/12, completed (loss: 0.3423154056072235):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:30<15:10, 30.36s/it]Training Epoch: 2/12, completed (loss: 0.3423154056072235):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:45<14:31, 30.06s/it]Training Epoch: 2/12, completed (loss: 0.2318396270275116):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:45<14:31, 30.06s/it]Training Epoch: 2/12, completed (loss: 0.09493091702461243):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:26:00<14:31, 30.06s/it]Training Epoch: 2/12, completed (loss: 0.09493091702461243):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:14<13:55, 29.84s/it]Training Epoch: 2/12, completed (loss: 0.4289085566997528):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:14<13:55, 29.84s/it] Training Epoch: 2/12, completed (loss: 0.25265806913375854):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:29<13:55, 29.84s/it]Training Epoch: 2/12, completed (loss: 0.25265806913375854):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:43<13:20, 29.64s/it]Training Epoch: 2/12, completed (loss: 0.08485016226768494):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:44<13:20, 29.64s/it]Training Epoch: 2/12, completed (loss: 0.1097395047545433):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:58<13:20, 29.64s/it] Training Epoch: 2/12, completed (loss: 0.1097395047545433):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:13<12:48, 29.57s/it]Training Epoch: 2/12, completed (loss: 0.08228959143161774):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:13<12:48, 29.57s/it]Training Epoch: 2/12, completed (loss: 0.08509271591901779):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:28<12:48, 29.57s/it]Training Epoch: 2/12, completed (loss: 0.08509271591901779):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:42<12:17, 29.50s/it]Training Epoch: 2/12, completed (loss: 0.2313792109489441):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:42<12:17, 29.50s/it] Training Epoch: 2/12, completed (loss: 0.1483973115682602):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:57<12:17, 29.50s/it]Training Epoch: 2/12, completed (loss: 0.1483973115682602):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:12<11:47, 29.49s/it]Training Epoch: 2/12, completed (loss: 0.005594505928456783):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:12<11:47, 29.49s/it]Training Epoch: 2/12, completed (loss: 0.06449922919273376):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:26<11:47, 29.49s/it] Training Epoch: 2/12, completed (loss: 0.06449922919273376):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:41<11:18, 29.48s/it]Training Epoch: 2/12, completed (loss: 0.1820639669895172):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:41<11:18, 29.48s/it] Training Epoch: 2/12, completed (loss: 0.2881069481372833):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:56<11:18, 29.48s/it]Training Epoch: 2/12, completed (loss: 0.2881069481372833):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:10<10:48, 29.46s/it]Training Epoch: 2/12, completed (loss: 0.18881262838840485):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:11<10:48, 29.46s/it]Training Epoch: 2/12, completed (loss: 0.34770873188972473):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:25<10:48, 29.46s/it]Training Epoch: 2/12, completed (loss: 0.34770873188972473):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:40<10:18, 29.43s/it]Training Epoch: 2/12, completed (loss: 0.41712725162506104):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:40<10:18, 29.43s/it]Training Epoch: 2/12, completed (loss: 0.43151143193244934):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:55<10:18, 29.43s/it]Training Epoch: 2/12, completed (loss: 0.43151143193244934):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:09<09:48, 29.42s/it]Training Epoch: 2/12, completed (loss: 0.33823519945144653):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:09<09:48, 29.42s/it]Training Epoch: 2/12, completed (loss: 0.3681216239929199):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:24<09:48, 29.42s/it] Training Epoch: 2/12, completed (loss: 0.3681216239929199):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:39<09:18, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.43806302547454834):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:39<09:18, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.2141193449497223):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:53<09:18, 29.41s/it] Training Epoch: 2/12, completed (loss: 0.2141193449497223):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:08<08:49, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.24020427465438843):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:08<08:49, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.17731235921382904):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:23<08:49, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.17731235921382904):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:37<08:20, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.16696809232234955):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:38<08:20, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.13905152678489685):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:52<08:20, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.13905152678489685):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:07<07:50, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.2651362717151642):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:07<07:50, 29.39s/it] Training Epoch: 2/12, completed (loss: 0.33465585112571716):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:22<07:50, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.33465585112571716):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:36<07:20, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.3972029387950897):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:36<07:20, 29.39s/it] Training Epoch: 2/12, completed (loss: 0.36158570647239685):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:51<07:20, 29.39s/it]Training Epoch: 2/12, completed (loss: 0.36158570647239685):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:05<06:51, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.09948335587978363):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:06<06:51, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.3550923764705658):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:20<06:51, 29.36s/it] Training Epoch: 2/12, completed (loss: 0.3550923764705658):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:35<06:22, 29.42s/it]Training Epoch: 2/12, completed (loss: 0.15237490832805634):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:35<06:22, 29.42s/it]Training Epoch: 2/12, completed (loss: 0.3445171117782593):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:50<06:22, 29.42s/it] Training Epoch: 2/12, completed (loss: 0.3445171117782593):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:04<05:52, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.10769634693861008):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:05<05:52, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.35525232553482056):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:19<05:52, 29.40s/it]Training Epoch: 2/12, completed (loss: 0.35525232553482056):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:34<05:23, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.10254999995231628):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:34<05:23, 29.41s/it]Training Epoch: 2/12, completed (loss: 0.0510244220495224):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:49<05:23, 29.41s/it] Training Epoch: 2/12, completed (loss: 0.0510244220495224):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:03<04:53, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.19157998263835907):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:03<04:53, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.08143223822116852):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:18<04:53, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.08143223822116852):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:32<04:24, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.12014473229646683):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:33<04:24, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.39163050055503845):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:47<04:24, 29.35s/it]Training Epoch: 2/12, completed (loss: 0.39163050055503845):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:02<03:54, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.17376890778541565):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:02<03:54, 29.31s/it]Training Epoch: 2/12, completed (loss: 0.4253283441066742):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:16<03:54, 29.31s/it] Training Epoch: 2/12, completed (loss: 0.4253283441066742):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:31<03:25, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.33412298560142517):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:31<03:25, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.16874733567237854):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:46<03:25, 29.36s/it]Training Epoch: 2/12, completed (loss: 0.16874733567237854):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:00<02:56, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.31555411219596863):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:01<02:56, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.29227155447006226):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:15<02:56, 29.37s/it]Training Epoch: 2/12, completed (loss: 0.29227155447006226):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:30<02:26, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.26102975010871887):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:30<02:26, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.14239339530467987):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:44<02:26, 29.32s/it]Training Epoch: 2/12, completed (loss: 0.14239339530467987):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:59<01:57, 29.27s/it]Training Epoch: 2/12, completed (loss: 0.24217863380908966):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:59<01:57, 29.27s/it]Training Epoch: 2/12, completed (loss: 0.08818139880895615):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:14<01:57, 29.27s/it]Training Epoch: 2/12, completed (loss: 0.08818139880895615):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:28<01:27, 29.22s/it]Training Epoch: 2/12, completed (loss: 0.27123570442199707):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:28<01:27, 29.22s/it]Training Epoch: 2/12, completed (loss: 0.11399184912443161):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:43<01:27, 29.22s/it]Training Epoch: 2/12, completed (loss: 0.11399184912443161):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:57<00:58, 29.18s/it]Training Epoch: 2/12, completed (loss: 0.1541038453578949):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:57<00:58, 29.18s/it] Training Epoch: 2/12, completed (loss: 0.31656259298324585):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:39:12<00:58, 29.18s/it]Training Epoch: 2/12, completed (loss: 0.31656259298324585):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:26<00:29, 29.23s/it]Training Epoch: 2/12, completed (loss: 0.199433833360672):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:27<00:29, 29.23s/it]  Training Epoch: 2/12, completed (loss: 0.2369879186153412):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:41<00:29, 29.23s/it]Training Epoch: 2/12, completed (loss: 0.2369879186153412): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:39:56<00:00, 29.24s/it] eval_ppl=tensor(1.7733, device='cuda:0') eval_epoch_loss=tensor(0.5729, device='cuda:0')
Eval epoch loss:  tensor(0.5729, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_2_257
Time while saving:  2023-10-25 20:19:10 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 2, step_id: 343

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:50,  7.94s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.90s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.87s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.84s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.88s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.89s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.88s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.88s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.89s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.89s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.92s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.90s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.92s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.91s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:58,  7.90s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.90s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.87s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:21<01:34,  7.87s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:29<01:26,  7.89s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:37<01:19,  7.91s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:45<01:11,  7.90s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.91s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.91s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.89s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.85s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:32<00:23,  7.86s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.92s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:48<00:07,  7.92s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:56<00:00,  7.90s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:56<00:00,  7.89s/it]
Training Epoch: 2/12, completed (loss: 0.00032930070301517844): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:53<00:00, 29.24s/it]Training Epoch: 2/12, completed (loss: 0.00032930070301517844): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:53<00:00, 36.24s/it]
 eval_ppl=tensor(1.7434, device='cuda:0') eval_epoch_loss=tensor(0.5558, device='cuda:0')
Eval epoch loss:  tensor(0.5558, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_2_343
Time while saving:  2023-10-25 20:44:09 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
Epoch ending time:  2023-10-25 20:44:09 IST+0530
Validation losses are: 
{'epoch_id': 0, 'ministep_id': 1, 'eval_epoch_loss': tensor(2.6360, device='cuda:0'), 'best_val_loss_yet': tensor(2.6360, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6698, device='cuda:0'), 'best_val_loss_yet': tensor(0.6698, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6023, device='cuda:0'), 'best_val_loss_yet': tensor(0.6023, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5568, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5643, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5634, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5644, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5524, device='cuda:0'), 'best_val_loss_yet': tensor(0.5524, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5513, device='cuda:0'), 'best_val_loss_yet': tensor(0.5513, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5386, device='cuda:0'), 'best_val_loss_yet': tensor(0.5386, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5370, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5769, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5758, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5729, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5558, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
$$$%%%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Epoch 2: train_perplexity=1.2218, train_epoch_loss=0.2003, epoch time 6233.4830818079645s
Epoch starting time:  2023-10-25 20:44:09 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 3:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training Epoch: 3/12, completed (loss: 0.026540668681263924):   0%|[34m          [0m| 0/172 [00:14<?, ?it/s]Training Epoch: 3/12, completed (loss: 0.026540668681263924):   1%|[34m          [0m| 1/172 [00:29<1:23:02, 29.14s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 3, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:50,  7.95s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.90s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:31,  7.85s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.85s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:08,  7.87s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.87s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.89s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.89s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.93s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.91s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.93s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.94s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:58,  7.93s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.92s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.91s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.88s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.90s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.92s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:45<01:11,  7.90s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.89s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.88s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.91s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.91s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.89s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.90s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.94s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it]
Training Epoch: 3/12, completed (loss: 0.09862740337848663):   1%|[34m          [0m| 1/172 [04:26<1:23:02, 29.14s/it] Training Epoch: 3/12, completed (loss: 0.11960221827030182):   1%|[34m          [0m| 1/172 [04:41<1:23:02, 29.14s/it]Training Epoch: 3/12, completed (loss: 0.11960221827030182):   1%|[34m          [0m| 2/172 [04:55<7:58:19, 168.82s/it]Training Epoch: 3/12, completed (loss: 0.20346015691757202):   1%|[34m          [0m| 2/172 [04:55<7:58:19, 168.82s/it]Training Epoch: 3/12, completed (loss: 0.0632188692688942):   1%|[34m          [0m| 2/172 [05:10<7:58:19, 168.82s/it] Training Epoch: 3/12, completed (loss: 0.0632188692688942):   2%|[34mâ–         [0m| 3/172 [05:25<4:56:12, 105.17s/it]Training Epoch: 3/12, completed (loss: 0.25194278359413147):   2%|[34mâ–         [0m| 3/172 [05:25<4:56:12, 105.17s/it]Training Epoch: 3/12, completed (loss: 0.19671191275119781):   2%|[34mâ–         [0m| 3/172 [05:39<4:56:12, 105.17s/it]Training Epoch: 3/12, completed (loss: 0.19671191275119781):   2%|[34mâ–         [0m| 4/172 [05:54<3:30:25, 75.15s/it] Training Epoch: 3/12, completed (loss: 0.06108720228075981):   2%|[34mâ–         [0m| 4/172 [05:54<3:30:25, 75.15s/it]Training Epoch: 3/12, completed (loss: 0.22548142075538635):   2%|[34mâ–         [0m| 4/172 [06:09<3:30:25, 75.15s/it]Training Epoch: 3/12, completed (loss: 0.22548142075538635):   3%|[34mâ–Ž         [0m| 5/172 [06:23<2:43:13, 58.65s/it]Training Epoch: 3/12, completed (loss: 0.4085882306098938):   3%|[34mâ–Ž         [0m| 5/172 [06:23<2:43:13, 58.65s/it] Training Epoch: 3/12, completed (loss: 0.27233853936195374):   3%|[34mâ–Ž         [0m| 5/172 [06:38<2:43:13, 58.65s/it]Training Epoch: 3/12, completed (loss: 0.27233853936195374):   3%|[34mâ–Ž         [0m| 6/172 [06:52<2:14:29, 48.61s/it]Training Epoch: 3/12, completed (loss: 0.012102184817194939):   3%|[34mâ–Ž         [0m| 6/172 [06:53<2:14:29, 48.61s/it]Training Epoch: 3/12, completed (loss: 0.2521878778934479):   3%|[34mâ–Ž         [0m| 6/172 [07:07<2:14:29, 48.61s/it]  Training Epoch: 3/12, completed (loss: 0.2521878778934479):   4%|[34mâ–         [0m| 7/172 [07:22<1:56:23, 42.32s/it]Training Epoch: 3/12, completed (loss: 0.05369385704398155):   4%|[34mâ–         [0m| 7/172 [07:22<1:56:23, 42.32s/it]Training Epoch: 3/12, completed (loss: 0.20670032501220703):   4%|[34mâ–         [0m| 7/172 [07:37<1:56:23, 42.32s/it]Training Epoch: 3/12, completed (loss: 0.20670032501220703):   5%|[34mâ–         [0m| 8/172 [07:51<1:44:21, 38.18s/it]Training Epoch: 3/12, completed (loss: 0.16697657108306885):   5%|[34mâ–         [0m| 8/172 [07:51<1:44:21, 38.18s/it]Training Epoch: 3/12, completed (loss: 0.3038678467273712):   5%|[34mâ–         [0m| 8/172 [08:06<1:44:21, 38.18s/it] Training Epoch: 3/12, completed (loss: 0.3038678467273712):   5%|[34mâ–Œ         [0m| 9/172 [08:20<1:36:19, 35.46s/it]Training Epoch: 3/12, completed (loss: 0.2048710137605667):   5%|[34mâ–Œ         [0m| 9/172 [08:21<1:36:19, 35.46s/it]Training Epoch: 3/12, completed (loss: 0.087297223508358):   5%|[34mâ–Œ         [0m| 9/172 [08:35<1:36:19, 35.46s/it] Training Epoch: 3/12, completed (loss: 0.087297223508358):   6%|[34mâ–Œ         [0m| 10/172 [08:49<1:30:18, 33.45s/it]Training Epoch: 3/12, completed (loss: 0.20698793232440948):   6%|[34mâ–Œ         [0m| 10/172 [08:50<1:30:18, 33.45s/it]Training Epoch: 3/12, completed (loss: 0.18147125840187073):   6%|[34mâ–Œ         [0m| 10/172 [09:04<1:30:18, 33.45s/it]Training Epoch: 3/12, completed (loss: 0.18147125840187073):   6%|[34mâ–‹         [0m| 11/172 [09:19<1:26:15, 32.15s/it]Training Epoch: 3/12, completed (loss: 0.1360989511013031):   6%|[34mâ–‹         [0m| 11/172 [09:19<1:26:15, 32.15s/it] Training Epoch: 3/12, completed (loss: 0.19027861952781677):   6%|[34mâ–‹         [0m| 11/172 [09:33<1:26:15, 32.15s/it]Training Epoch: 3/12, completed (loss: 0.19027861952781677):   7%|[34mâ–‹         [0m| 12/172 [09:48<1:23:18, 31.24s/it]Training Epoch: 3/12, completed (loss: 0.1507139354944229):   7%|[34mâ–‹         [0m| 12/172 [09:48<1:23:18, 31.24s/it] Training Epoch: 3/12, completed (loss: 0.07135960459709167):   7%|[34mâ–‹         [0m| 12/172 [10:02<1:23:18, 31.24s/it]Training Epoch: 3/12, completed (loss: 0.07135960459709167):   8%|[34mâ–Š         [0m| 13/172 [10:17<1:21:07, 30.62s/it]Training Epoch: 3/12, completed (loss: 0.045662276446819305):   8%|[34mâ–Š         [0m| 13/172 [10:17<1:21:07, 30.62s/it]Training Epoch: 3/12, completed (loss: 0.2972482144832611):   8%|[34mâ–Š         [0m| 13/172 [10:32<1:21:07, 30.62s/it]  Training Epoch: 3/12, completed (loss: 0.2972482144832611):   8%|[34mâ–Š         [0m| 14/172 [10:46<1:19:37, 30.24s/it]Training Epoch: 3/12, completed (loss: 0.32786065340042114):   8%|[34mâ–Š         [0m| 14/172 [10:47<1:19:37, 30.24s/it]Training Epoch: 3/12, completed (loss: 0.08980423957109451):   8%|[34mâ–Š         [0m| 14/172 [11:01<1:19:37, 30.24s/it]Training Epoch: 3/12, completed (loss: 0.08980423957109451):   9%|[34mâ–Š         [0m| 15/172 [11:16<1:18:21, 29.95s/it]Training Epoch: 3/12, completed (loss: 0.2082962989807129):   9%|[34mâ–Š         [0m| 15/172 [11:16<1:18:21, 29.95s/it] Training Epoch: 3/12, completed (loss: 0.08468366414308548):   9%|[34mâ–Š         [0m| 15/172 [11:31<1:18:21, 29.95s/it]Training Epoch: 3/12, completed (loss: 0.08468366414308548):   9%|[34mâ–‰         [0m| 16/172 [11:45<1:17:29, 29.80s/it]Training Epoch: 3/12, completed (loss: 0.14721815288066864):   9%|[34mâ–‰         [0m| 16/172 [11:45<1:17:29, 29.80s/it]Training Epoch: 3/12, completed (loss: 0.34684500098228455):   9%|[34mâ–‰         [0m| 16/172 [12:00<1:17:29, 29.80s/it]Training Epoch: 3/12, completed (loss: 0.34684500098228455):  10%|[34mâ–‰         [0m| 17/172 [12:14<1:16:39, 29.67s/it]Training Epoch: 3/12, completed (loss: 0.2369181364774704):  10%|[34mâ–‰         [0m| 17/172 [12:15<1:16:39, 29.67s/it] Training Epoch: 3/12, completed (loss: 0.1870468407869339):  10%|[34mâ–‰         [0m| 17/172 [12:29<1:16:39, 29.67s/it]Training Epoch: 3/12, completed (loss: 0.1870468407869339):  10%|[34mâ–ˆ         [0m| 18/172 [12:44<1:15:46, 29.53s/it]Training Epoch: 3/12, completed (loss: 0.21261076629161835):  10%|[34mâ–ˆ         [0m| 18/172 [12:44<1:15:46, 29.53s/it]Training Epoch: 3/12, completed (loss: 0.1688016951084137):  10%|[34mâ–ˆ         [0m| 18/172 [12:59<1:15:46, 29.53s/it] Training Epoch: 3/12, completed (loss: 0.1688016951084137):  11%|[34mâ–ˆ         [0m| 19/172 [13:13<1:15:08, 29.47s/it]Training Epoch: 3/12, completed (loss: 0.08849683403968811):  11%|[34mâ–ˆ         [0m| 19/172 [13:13<1:15:08, 29.47s/it]Training Epoch: 3/12, completed (loss: 0.3251354992389679):  11%|[34mâ–ˆ         [0m| 19/172 [13:28<1:15:08, 29.47s/it] Training Epoch: 3/12, completed (loss: 0.3251354992389679):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:42<1:14:28, 29.40s/it]Training Epoch: 3/12, completed (loss: 0.12292980402708054):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:42<1:14:28, 29.40s/it]Training Epoch: 3/12, completed (loss: 0.2813642919063568):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:57<1:14:28, 29.40s/it] Training Epoch: 3/12, completed (loss: 0.2813642919063568):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:12<1:13:58, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.06193462386727333):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:12<1:13:58, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.06132137402892113):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:26<1:13:58, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.06132137402892113):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:41<1:13:28, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.4565620720386505):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:41<1:13:28, 29.39s/it] Training Epoch: 3/12, completed (loss: 0.4002200663089752):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:56<1:13:28, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.4002200663089752):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:10<1:12:59, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.1268998384475708):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:11<1:12:59, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.30219754576683044):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:25<1:12:59, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.30219754576683044):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:40<1:12:27, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.37481749057769775):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:40<1:12:27, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.08130231499671936):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:55<1:12:27, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.08130231499671936):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:09<1:11:51, 29.33s/it]Training Epoch: 3/12, completed (loss: 0.031300466507673264):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:09<1:11:51, 29.33s/it]Training Epoch: 3/12, completed (loss: 0.17034760117530823):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:24<1:11:51, 29.33s/it] Training Epoch: 3/12, completed (loss: 0.17034760117530823):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:38<1:11:17, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.24444513022899628):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:38<1:11:17, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.14024336636066437):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:53<1:11:17, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.14024336636066437):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:07<1:10:43, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.2457650750875473):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:08<1:10:43, 29.27s/it] Training Epoch: 3/12, completed (loss: 0.19672536849975586):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:22<1:10:43, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.19672536849975586):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:37<1:10:14, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.049296632409095764):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:37<1:10:14, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.3551763892173767):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:51<1:10:14, 29.27s/it]  Training Epoch: 3/12, completed (loss: 0.3551763892173767):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:06<1:09:47, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.16733261942863464):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:06<1:09:47, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.21374784409999847):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:21<1:09:47, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.21374784409999847):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:35<1:09:18, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.3843599855899811):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:35<1:09:18, 29.28s/it] Training Epoch: 3/12, completed (loss: 0.02287682332098484):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:50<1:09:18, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.02287682332098484):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:05<1:08:51, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.08470969647169113):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:05<1:08:51, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.160274937748909):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:20<1:08:51, 29.30s/it]  Training Epoch: 3/12, completed (loss: 0.160274937748909):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:34<1:08:24, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.08234278112649918):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:34<1:08:24, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.1400829404592514):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:49<1:08:24, 29.32s/it] Training Epoch: 3/12, completed (loss: 0.1400829404592514):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:03<1:07:51, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.19161874055862427):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:03<1:07:51, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.28468045592308044):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:18<1:07:51, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.28468045592308044):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:32<1:07:23, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.2470928281545639):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:33<1:07:23, 29.30s/it] Training Epoch: 3/12, completed (loss: 0.1603771299123764):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:47<1:07:23, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.1603771299123764):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:02<1:06:57, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.030276404693722725):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:02<1:06:57, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.1400671750307083):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:17<1:06:57, 29.32s/it]  Training Epoch: 3/12, completed (loss: 0.1400671750307083):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:31<1:06:32, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.14079836010932922):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:31<1:06:32, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.05193420499563217):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:46<1:06:32, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.05193420499563217):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:01<1:06:04, 29.37s/it]Training Epoch: 3/12, completed (loss: 0.08239268511533737):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:01<1:06:04, 29.37s/it]Training Epoch: 3/12, completed (loss: 0.19912466406822205):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:15<1:06:04, 29.37s/it]Training Epoch: 3/12, completed (loss: 0.19912466406822205):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:30<1:05:27, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.03891459479928017):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:30<1:05:27, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.4149055480957031):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:45<1:05:27, 29.31s/it] Training Epoch: 3/12, completed (loss: 0.4149055480957031):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:59<1:04:58, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.07470771670341492):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [22:59<1:04:58, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.33768054842948914):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:14<1:04:58, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.33768054842948914):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:28<1:04:25, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.20157736539840698):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:29<1:04:25, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.18224769830703735):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:43<1:04:25, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.18224769830703735):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:58<1:03:58, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.1406269520521164):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:58<1:03:58, 29.30s/it] Training Epoch: 3/12, completed (loss: 0.04491168260574341):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:13<1:03:58, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.04491168260574341):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:27<1:03:32, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.1432613730430603):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:27<1:03:32, 29.32s/it] Training Epoch: 3/12, completed (loss: 0.12627966701984406):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:42<1:03:32, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.12627966701984406):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:56<1:03:02, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.07412181049585342):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:57<1:03:02, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.36380696296691895):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:11<1:03:02, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.36380696296691895):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:26<1:02:29, 29.29s/it] eval_ppl=tensor(1.7420, device='cuda:0') eval_epoch_loss=tensor(0.5550, device='cuda:0')
Eval epoch loss:  tensor(0.5550, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_3_1
Time while saving:  2023-10-25 20:48:36 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 3, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:53,  8.04s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:42,  7.95s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.89s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.86s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.88s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.91s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.89s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.91s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:30,  7.93s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.91s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.96s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.97s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.96s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.94s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.93s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.93s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.93s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.93s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.93s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.90s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.91s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.96s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.95s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it]
Training Epoch: 3/12, completed (loss: 0.2803937792778015):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:24<1:02:29, 29.29s/it] Training Epoch: 3/12, completed (loss: 0.1770368218421936):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:38<1:02:29, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.1770368218421936):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:53<3:32:59, 100.63s/it]Training Epoch: 3/12, completed (loss: 0.012890310026705265):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:53<3:32:59, 100.63s/it]Training Epoch: 3/12, completed (loss: 0.3337956666946411):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [30:07<3:32:59, 100.63s/it]  Training Epoch: 3/12, completed (loss: 0.3337956666946411):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:22<2:46:11, 79.14s/it] Training Epoch: 3/12, completed (loss: 0.16875047981739044):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:22<2:46:11, 79.14s/it]Training Epoch: 3/12, completed (loss: 0.13016003370285034):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:36<2:46:11, 79.14s/it]Training Epoch: 3/12, completed (loss: 0.13016003370285034):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:51<2:13:46, 64.21s/it]Training Epoch: 3/12, completed (loss: 0.13020583987236023):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:51<2:13:46, 64.21s/it]Training Epoch: 3/12, completed (loss: 0.3298965096473694):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [31:06<2:13:46, 64.21s/it] Training Epoch: 3/12, completed (loss: 0.3298965096473694):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:20<1:51:00, 53.72s/it]Training Epoch: 3/12, completed (loss: 0.11976702511310577):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:21<1:51:00, 53.72s/it]Training Epoch: 3/12, completed (loss: 0.08683962374925613):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:35<1:51:00, 53.72s/it]Training Epoch: 3/12, completed (loss: 0.08683962374925613):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:50<1:35:04, 46.38s/it]Training Epoch: 3/12, completed (loss: 0.00024073167878668755):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:50<1:35:04, 46.38s/it]Training Epoch: 3/12, completed (loss: 0.37357816100120544):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [32:04<1:35:04, 46.38s/it]   Training Epoch: 3/12, completed (loss: 0.37357816100120544):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:19<1:23:52, 41.25s/it]Training Epoch: 3/12, completed (loss: 0.1535692662000656):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:19<1:23:52, 41.25s/it] Training Epoch: 3/12, completed (loss: 0.28368574380874634):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:34<1:23:52, 41.25s/it]Training Epoch: 3/12, completed (loss: 0.28368574380874634):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:48<1:15:53, 37.63s/it]Training Epoch: 3/12, completed (loss: 0.020939139649271965):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:48<1:15:53, 37.63s/it]Training Epoch: 3/12, completed (loss: 0.25910747051239014):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [33:03<1:15:53, 37.63s/it] Training Epoch: 3/12, completed (loss: 0.25910747051239014):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:18<1:10:23, 35.19s/it]Training Epoch: 3/12, completed (loss: 0.14854249358177185):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:18<1:10:23, 35.19s/it]Training Epoch: 3/12, completed (loss: 0.43660005927085876):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:32<1:10:23, 35.19s/it]Training Epoch: 3/12, completed (loss: 0.43660005927085876):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:47<1:06:20, 33.45s/it]Training Epoch: 3/12, completed (loss: 0.08840275555849075):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:47<1:06:20, 33.45s/it]Training Epoch: 3/12, completed (loss: 0.11454269289970398):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [34:02<1:06:20, 33.45s/it]Training Epoch: 3/12, completed (loss: 0.11454269289970398):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:16<1:03:20, 32.21s/it]Training Epoch: 3/12, completed (loss: 0.1172041967511177):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:16<1:03:20, 32.21s/it] Training Epoch: 3/12, completed (loss: 0.20062682032585144):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:31<1:03:20, 32.21s/it]Training Epoch: 3/12, completed (loss: 0.20062682032585144):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:46<1:01:06, 31.34s/it]Training Epoch: 3/12, completed (loss: 0.08862859010696411):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:46<1:01:06, 31.34s/it]Training Epoch: 3/12, completed (loss: 0.06661015003919601):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [35:00<1:01:06, 31.34s/it]Training Epoch: 3/12, completed (loss: 0.06661015003919601):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:15<59:25, 30.74s/it]  Training Epoch: 3/12, completed (loss: 0.27517247200012207):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:15<59:25, 30.74s/it]Training Epoch: 3/12, completed (loss: 0.27219074964523315):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:30<59:25, 30.74s/it]Training Epoch: 3/12, completed (loss: 0.27219074964523315):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:44<58:09, 30.34s/it]Training Epoch: 3/12, completed (loss: 0.21633225679397583):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:45<58:09, 30.34s/it]Training Epoch: 3/12, completed (loss: 0.007873568683862686):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:59<58:09, 30.34s/it]Training Epoch: 3/12, completed (loss: 0.007873568683862686):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:14<57:06, 30.06s/it]Training Epoch: 3/12, completed (loss: 0.25215622782707214):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:14<57:06, 30.06s/it] Training Epoch: 3/12, completed (loss: 0.3106066882610321):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:29<57:06, 30.06s/it] Training Epoch: 3/12, completed (loss: 0.3106066882610321):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:43<56:18, 29.89s/it]Training Epoch: 3/12, completed (loss: 0.1540587991476059):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:43<56:18, 29.89s/it]Training Epoch: 3/12, completed (loss: 0.1540599912405014):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:58<56:18, 29.89s/it]Training Epoch: 3/12, completed (loss: 0.1540599912405014):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:12<55:24, 29.69s/it]Training Epoch: 3/12, completed (loss: 0.06483697146177292):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:13<55:24, 29.69s/it]Training Epoch: 3/12, completed (loss: 0.2816106975078583):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:27<55:24, 29.69s/it] Training Epoch: 3/12, completed (loss: 0.2816106975078583):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:42<54:45, 29.60s/it]Training Epoch: 3/12, completed (loss: 0.07373307645320892):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:42<54:45, 29.60s/it]Training Epoch: 3/12, completed (loss: 0.00026053047622554004):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:57<54:45, 29.60s/it]Training Epoch: 3/12, completed (loss: 0.00026053047622554004):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:11<54:09, 29.54s/it]Training Epoch: 3/12, completed (loss: 0.34380537271499634):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:11<54:09, 29.54s/it]   Training Epoch: 3/12, completed (loss: 0.4700779616832733):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:26<54:09, 29.54s/it] Training Epoch: 3/12, completed (loss: 0.4700779616832733):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:40<53:27, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.5134883522987366):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:41<53:27, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.06774673610925674):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:55<53:27, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.06774673610925674):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:10<52:57, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.15700390934944153):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:10<52:57, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.16081848740577698):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:25<52:57, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.16081848740577698):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:39<52:24, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.09181784838438034):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:39<52:24, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.24488674104213715):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:54<52:24, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.24488674104213715):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:08<51:50, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.09609303623437881):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:09<51:50, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.10106023401021957):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:23<51:50, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.10106023401021957):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:38<51:20, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.06849923729896545):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:38<51:20, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.12432841211557388):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:52<51:20, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.12432841211557388):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:07<50:49, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.11929860711097717):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:07<50:49, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.2635020315647125):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:22<50:49, 29.32s/it] Training Epoch: 3/12, completed (loss: 0.2635020315647125):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:36<50:13, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.005989172495901585):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:36<50:13, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.16034919023513794):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:51<50:13, 29.26s/it] Training Epoch: 3/12, completed (loss: 0.16034919023513794):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:05<49:46, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.4214238226413727):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:06<49:46, 29.28s/it] Training Epoch: 3/12, completed (loss: 0.19799034297466278):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:20<49:46, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.19799034297466278):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:35<49:20, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.30307185649871826):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:35<49:20, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.13918480277061462):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:50<49:20, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.13918480277061462):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:04<48:48, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.12205160409212112):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:04<48:48, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.3639601171016693):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:19<48:48, 29.28s/it] Training Epoch: 3/12, completed (loss: 0.3639601171016693):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:33<48:21, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.010550899431109428):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:34<48:21, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.2007351964712143):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:48<48:21, 29.31s/it]  Training Epoch: 3/12, completed (loss: 0.2007351964712143):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:03<47:49, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.20461376011371613):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:03<47:49, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.24587546288967133):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:17<47:49, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.24587546288967133):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:32<47:22, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.11262673884630203):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:32<47:22, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.06620286405086517):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:47<47:22, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.06620286405086517):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:01<46:53, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.19359923899173737):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:01<46:53, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.10726159811019897):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:16<46:53, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.10726159811019897):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:30<46:20, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.25375786423683167):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:31<46:20, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.035027872771024704):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:45<46:20, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.035027872771024704):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:00<45:51, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.1339895874261856):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:00<45:51, 29.27s/it]  Training Epoch: 3/12, completed (loss: 0.11912455409765244):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:15<45:51, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.11912455409765244):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:29<45:21, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.06322722136974335):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:29<45:21, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.21533966064453125):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:44<45:21, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.21533966064453125):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:58<44:48, 29.22s/it]Training Epoch: 3/12, completed (loss: 0.08422776311635971):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [46:58<44:48, 29.22s/it]Training Epoch: 3/12, completed (loss: 0.29958173632621765):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:13<44:48, 29.22s/it]Training Epoch: 3/12, completed (loss: 0.29958173632621765):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:27<44:22, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.0809118002653122):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:28<44:22, 29.25s/it] Training Epoch: 3/12, completed (loss: 0.09468715637922287):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:42<44:22, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.09468715637922287):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:57<43:53, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.19476021826267242):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [47:57<43:53, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.25815701484680176):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:12<43:53, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.25815701484680176):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:26<43:27, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.25261634588241577):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:26<43:27, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.21318764984607697):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:41<43:27, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.21318764984607697):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:55<42:58, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.2643565535545349):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:56<42:58, 29.30s/it] Training Epoch: 3/12, completed (loss: 0.1185872033238411):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [49:10<42:58, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.1185872033238411):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:25<42:29, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.4007614552974701):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:25<42:29, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.3199079632759094):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:40<42:29, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.3199079632759094):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:54<42:00, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.3173067569732666):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:54<42:00, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.3002372980117798):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [50:09<42:00, 29.31s/it]Training Epoch: 3/12, completed (loss: 0.3002372980117798):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [50:23<41:29, 29.28s/it] eval_ppl=tensor(1.8005, device='cuda:0') eval_epoch_loss=tensor(0.5881, device='cuda:0')
Eval epoch loss:  tensor(0.5881, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_3_87
Time while saving:  2023-10-25 21:13:33 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 3, step_id: 173

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.99s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.91s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.87s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.84s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:08,  7.87s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:00,  7.86s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.88s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.88s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.92s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.91s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.97s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.95s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.90s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.89s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.91s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.90s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.91s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:02,  7.87s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.87s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.90s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.90s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.90s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.94s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.91s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it]
Training Epoch: 3/12, completed (loss: 0.09188925474882126):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:21<41:29, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.031236441805958748):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:35<41:29, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.031236441805958748):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:50<2:20:39, 100.47s/it]Training Epoch: 3/12, completed (loss: 0.14664742350578308):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:50<2:20:39, 100.47s/it] Training Epoch: 3/12, completed (loss: 0.22809872031211853):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [55:05<2:20:39, 100.47s/it]Training Epoch: 3/12, completed (loss: 0.22809872031211853):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:19<1:49:29, 79.15s/it] Training Epoch: 3/12, completed (loss: 0.045888256281614304):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:20<1:49:29, 79.15s/it]Training Epoch: 3/12, completed (loss: 0.12663085758686066):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:34<1:49:29, 79.15s/it] Training Epoch: 3/12, completed (loss: 0.12663085758686066):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:49<1:27:52, 64.30s/it]Training Epoch: 3/12, completed (loss: 0.43507057428359985):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:49<1:27:52, 64.30s/it]Training Epoch: 3/12, completed (loss: 0.08483133465051651):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [56:04<1:27:52, 64.30s/it]Training Epoch: 3/12, completed (loss: 0.08483133465051651):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:18<1:12:43, 53.87s/it]Training Epoch: 3/12, completed (loss: 0.20717401802539825):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:19<1:12:43, 53.87s/it]Training Epoch: 3/12, completed (loss: 0.16328813135623932):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:33<1:12:43, 53.87s/it]Training Epoch: 3/12, completed (loss: 0.16328813135623932):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:48<1:02:01, 46.52s/it]Training Epoch: 3/12, completed (loss: 0.21842646598815918):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:48<1:02:01, 46.52s/it]Training Epoch: 3/12, completed (loss: 0.04101261496543884):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [57:03<1:02:01, 46.52s/it]Training Epoch: 3/12, completed (loss: 0.04101261496543884):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:17<54:34, 41.44s/it]  Training Epoch: 3/12, completed (loss: 0.2775093913078308):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:18<54:34, 41.44s/it] Training Epoch: 3/12, completed (loss: 0.17436747252941132):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:32<54:34, 41.44s/it]Training Epoch: 3/12, completed (loss: 0.17436747252941132):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:47<49:11, 37.84s/it]Training Epoch: 3/12, completed (loss: 0.1753361076116562):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:47<49:11, 37.84s/it] Training Epoch: 3/12, completed (loss: 0.48426878452301025):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [58:02<49:11, 37.84s/it]Training Epoch: 3/12, completed (loss: 0.48426878452301025):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:16<45:17, 35.30s/it]Training Epoch: 3/12, completed (loss: 0.05550305172801018):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:16<45:17, 35.30s/it]Training Epoch: 3/12, completed (loss: 0.03716108947992325):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:31<45:17, 35.30s/it]Training Epoch: 3/12, completed (loss: 0.03716108947992325):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:46<42:31, 33.57s/it]Training Epoch: 3/12, completed (loss: 0.1678159236907959):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:46<42:31, 33.57s/it] Training Epoch: 3/12, completed (loss: 0.29216623306274414):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [59:01<42:31, 33.57s/it]Training Epoch: 3/12, completed (loss: 0.29216623306274414):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:15<40:23, 32.31s/it]Training Epoch: 3/12, completed (loss: 0.12736690044403076):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:15<40:23, 32.31s/it]Training Epoch: 3/12, completed (loss: 0.21170435845851898):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:30<40:23, 32.31s/it]Training Epoch: 3/12, completed (loss: 0.21170435845851898):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:44<38:43, 31.39s/it]Training Epoch: 3/12, completed (loss: 0.16907534003257751):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:45<38:43, 31.39s/it]Training Epoch: 3/12, completed (loss: 0.28320202231407166):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:59<38:43, 31.39s/it]Training Epoch: 3/12, completed (loss: 0.28320202231407166):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:14<37:28, 30.80s/it]Training Epoch: 3/12, completed (loss: 0.08374813199043274):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:14<37:28, 30.80s/it]Training Epoch: 3/12, completed (loss: 0.175123393535614):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:29<37:28, 30.80s/it]  Training Epoch: 3/12, completed (loss: 0.175123393535614):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:43<36:24, 30.34s/it]Training Epoch: 3/12, completed (loss: 0.015860896557569504):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:43<36:24, 30.34s/it]Training Epoch: 3/12, completed (loss: 0.013972818851470947):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:58<36:24, 30.34s/it]Training Epoch: 3/12, completed (loss: 0.013972818851470947):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:12<35:30, 30.00s/it]Training Epoch: 3/12, completed (loss: 0.13056999444961548):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:12<35:30, 30.00s/it] Training Epoch: 3/12, completed (loss: 0.06153205409646034):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:27<35:30, 30.00s/it]Training Epoch: 3/12, completed (loss: 0.06153205409646034):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:41<34:44, 29.78s/it]Training Epoch: 3/12, completed (loss: 0.14546824991703033):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:42<34:44, 29.78s/it]Training Epoch: 3/12, completed (loss: 0.22413401305675507):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:56<34:44, 29.78s/it]Training Epoch: 3/12, completed (loss: 0.22413401305675507):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:11<34:04, 29.63s/it]Training Epoch: 3/12, completed (loss: 0.07667919248342514):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:11<34:04, 29.63s/it]Training Epoch: 3/12, completed (loss: 0.13542316854000092):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:26<34:04, 29.63s/it]Training Epoch: 3/12, completed (loss: 0.13542316854000092):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:40<33:26, 29.50s/it]Training Epoch: 3/12, completed (loss: 0.17857994139194489):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:40<33:26, 29.50s/it]Training Epoch: 3/12, completed (loss: 0.23812921345233917):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:55<33:26, 29.50s/it]Training Epoch: 3/12, completed (loss: 0.23812921345233917):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:09<32:53, 29.46s/it]Training Epoch: 3/12, completed (loss: 0.4821828007698059):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:10<32:53, 29.46s/it] Training Epoch: 3/12, completed (loss: 0.024887356907129288):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:24<32:53, 29.46s/it]Training Epoch: 3/12, completed (loss: 0.024887356907129288):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:39<32:21, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.20400118827819824):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:39<32:21, 29.42s/it] Training Epoch: 3/12, completed (loss: 0.05619525909423828):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:53<32:21, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.05619525909423828):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:08<31:48, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.19569474458694458):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:08<31:48, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.35681185126304626):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:23<31:48, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.35681185126304626):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:37<31:17, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.13605129718780518):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:37<31:17, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.132156103849411):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:52<31:17, 29.34s/it]  Training Epoch: 3/12, completed (loss: 0.132156103849411):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:06<30:47, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.10171937942504883):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:07<30:47, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.112027607858181):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:21<30:47, 29.32s/it]  Training Epoch: 3/12, completed (loss: 0.112027607858181):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:36<30:15, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.020571330562233925):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:36<30:15, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.26835817098617554):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:50<30:15, 29.28s/it] Training Epoch: 3/12, completed (loss: 0.26835817098617554):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:05<29:45, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.00021928909700363874):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:05<29:45, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.18759500980377197):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:20<29:45, 29.27s/it]   Training Epoch: 3/12, completed (loss: 0.18759500980377197):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:34<29:15, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.2775993049144745):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:34<29:15, 29.25s/it] Training Epoch: 3/12, completed (loss: 0.19836072623729706):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:49<29:15, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.19836072623729706):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:03<28:46, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.05664758011698723):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:04<28:46, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.4195701479911804):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:18<28:46, 29.27s/it] Training Epoch: 3/12, completed (loss: 0.4195701479911804):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:33<28:17, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.04422522708773613):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:33<28:17, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.16695231199264526):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:48<28:17, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.16695231199264526):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:02<27:49, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.238392174243927):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:02<27:49, 29.29s/it]  Training Epoch: 3/12, completed (loss: 0.2509710490703583):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:17<27:49, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.2509710490703583):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:31<27:20, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.27562442421913147):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:32<27:20, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.1859636753797531):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:46<27:20, 29.29s/it] Training Epoch: 3/12, completed (loss: 0.1859636753797531):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:01<26:51, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.06434620916843414):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:01<26:51, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.17782758176326752):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:15<26:51, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.17782758176326752):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:30<26:21, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.14276587963104248):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:30<26:21, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.08459977060556412):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:45<26:21, 29.29s/it]Training Epoch: 3/12, completed (loss: 0.08459977060556412):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:59<25:51, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.2417106032371521):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:09:59<25:51, 29.27s/it] Training Epoch: 3/12, completed (loss: 0.18157649040222168):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:14<25:51, 29.27s/it]Training Epoch: 3/12, completed (loss: 0.18157649040222168):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:28<25:22, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.1986740231513977):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:29<25:22, 29.28s/it] Training Epoch: 3/12, completed (loss: 0.26003497838974):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:43<25:22, 29.28s/it]  Training Epoch: 3/12, completed (loss: 0.26003497838974):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:58<24:57, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.08784610033035278):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:10:58<24:57, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.3036026060581207):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:13<24:57, 29.36s/it] Training Epoch: 3/12, completed (loss: 0.3036026060581207):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:27<24:25, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.017452342435717583):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:27<24:25, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.3843473196029663):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:42<24:25, 29.32s/it]  Training Epoch: 3/12, completed (loss: 0.3843473196029663):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:57<23:57, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.20850828289985657):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:11:57<23:57, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.2506956458091736):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:11<23:57, 29.34s/it] Training Epoch: 3/12, completed (loss: 0.2506956458091736):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:26<23:28, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.07068102806806564):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:26<23:28, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.0007070777355693281):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:41<23:28, 29.34s/it]Training Epoch: 3/12, completed (loss: 0.0007070777355693281):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:55<22:55, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.036062274128198624):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:12:55<22:55, 29.26s/it] Training Epoch: 3/12, completed (loss: 0.1567711979150772):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:10<22:55, 29.26s/it]  Training Epoch: 3/12, completed (loss: 0.1567711979150772):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:24<22:25, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.010109927505254745):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:24<22:25, 29.26s/it]Training Epoch: 3/12, completed (loss: 0.06682656705379486):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:39<22:25, 29.26s/it] Training Epoch: 3/12, completed (loss: 0.06682656705379486):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:53<21:55, 29.23s/it]Training Epoch: 3/12, completed (loss: 0.3464873433113098):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:54<21:55, 29.23s/it] Training Epoch: 3/12, completed (loss: 0.21640662848949432):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:14:08<21:55, 29.23s/it]Training Epoch: 3/12, completed (loss: 0.21640662848949432):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:23<21:29, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.1207074224948883):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:23<21:29, 29.30s/it] Training Epoch: 3/12, completed (loss: 0.03492547571659088):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:38<21:29, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.03492547571659088):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:14:52<20:59, 29.28s/it] eval_ppl=tensor(1.8680, device='cuda:0') eval_epoch_loss=tensor(0.6249, device='cuda:0')
Eval epoch loss:  tensor(0.6249, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_3_173
Time while saving:  2023-10-25 21:38:30 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 3, step_id: 257

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.97s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.90s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.86s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.83s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.89s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.88s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.90s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.90s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.92s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.89s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.93s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.94s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.96s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.90s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.89s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.87s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.91s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:45<01:11,  7.90s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.91s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.88s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.89s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.92s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.89s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.93s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.94s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.93s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it]
Training Epoch: 3/12, completed (loss: 0.34667959809303284):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:50<20:59, 29.28s/it]Training Epoch: 3/12, completed (loss: 0.1373376101255417):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:19:04<20:59, 29.28s/it] Training Epoch: 3/12, completed (loss: 0.1373376101255417):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:19<1:10:18, 100.44s/it]Training Epoch: 3/12, completed (loss: 0.050879962742328644):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:19<1:10:18, 100.44s/it]Training Epoch: 3/12, completed (loss: 0.11976063996553421):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:33<1:10:18, 100.44s/it] Training Epoch: 3/12, completed (loss: 0.11976063996553421):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:48<54:02, 79.07s/it]   Training Epoch: 3/12, completed (loss: 0.03995070606470108):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:48<54:02, 79.07s/it]Training Epoch: 3/12, completed (loss: 0.00022355873079504818):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:20:03<54:02, 79.07s/it]Training Epoch: 3/12, completed (loss: 0.00022355873079504818):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:17<42:43, 64.09s/it]Training Epoch: 3/12, completed (loss: 0.06848715990781784):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:17<42:43, 64.09s/it]   Training Epoch: 3/12, completed (loss: 0.14994169771671295):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:32<42:43, 64.09s/it]Training Epoch: 3/12, completed (loss: 0.14994169771671295):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:46<34:52, 53.64s/it]Training Epoch: 3/12, completed (loss: 0.07841075211763382):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:46<34:52, 53.64s/it]Training Epoch: 3/12, completed (loss: 0.23038095235824585):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:21:01<34:52, 53.64s/it]Training Epoch: 3/12, completed (loss: 0.23038095235824585):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:16<29:22, 46.39s/it]Training Epoch: 3/12, completed (loss: 0.42687055468559265):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:16<29:22, 46.39s/it]Training Epoch: 3/12, completed (loss: 0.04126335680484772):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:30<29:22, 46.39s/it]Training Epoch: 3/12, completed (loss: 0.04126335680484772):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:45<25:26, 41.25s/it]Training Epoch: 3/12, completed (loss: 0.08514890819787979):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:45<25:26, 41.25s/it]Training Epoch: 3/12, completed (loss: 0.12122973054647446):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:22:00<25:26, 41.25s/it]Training Epoch: 3/12, completed (loss: 0.12122973054647446):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:14<22:36, 37.68s/it]Training Epoch: 3/12, completed (loss: 0.21278992295265198):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:14<22:36, 37.68s/it]Training Epoch: 3/12, completed (loss: 0.0286213681101799):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:29<22:36, 37.68s/it] Training Epoch: 3/12, completed (loss: 0.0286213681101799):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:44<20:31, 35.18s/it]Training Epoch: 3/12, completed (loss: 0.02931150421500206):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:44<20:31, 35.18s/it]Training Epoch: 3/12, completed (loss: 0.0016869778046384454):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:58<20:31, 35.18s/it]Training Epoch: 3/12, completed (loss: 0.0016869778046384454):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:13<18:56, 33.42s/it]Training Epoch: 3/12, completed (loss: 0.02235400676727295):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:13<18:56, 33.42s/it]  Training Epoch: 3/12, completed (loss: 0.1803877353668213):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:28<18:56, 33.42s/it] Training Epoch: 3/12, completed (loss: 0.1803877353668213):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:42<17:41, 32.15s/it]Training Epoch: 3/12, completed (loss: 0.005852197762578726):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:42<17:41, 32.15s/it]Training Epoch: 3/12, completed (loss: 0.21514807641506195):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:57<17:41, 32.15s/it] Training Epoch: 3/12, completed (loss: 0.21514807641506195):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:11<16:41, 31.31s/it]Training Epoch: 3/12, completed (loss: 0.1407550573348999):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:12<16:41, 31.31s/it] Training Epoch: 3/12, completed (loss: 0.04686630517244339):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:26<16:41, 31.31s/it]Training Epoch: 3/12, completed (loss: 0.04686630517244339):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:41<15:53, 30.77s/it]Training Epoch: 3/12, completed (loss: 0.00026266503846272826):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:41<15:53, 30.77s/it]Training Epoch: 3/12, completed (loss: 4.5865952415624633e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:56<15:53, 30.77s/it]Training Epoch: 3/12, completed (loss: 4.5865952415624633e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:10<15:09, 30.31s/it]Training Epoch: 3/12, completed (loss: 0.22231709957122803):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:10<15:09, 30.31s/it]   Training Epoch: 3/12, completed (loss: 0.31648144125938416):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:25<15:09, 30.31s/it]Training Epoch: 3/12, completed (loss: 0.31648144125938416):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:40<14:30, 30.02s/it]Training Epoch: 3/12, completed (loss: 0.20541797578334808):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:40<14:30, 30.02s/it]Training Epoch: 3/12, completed (loss: 0.08172444254159927):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:54<14:30, 30.02s/it]Training Epoch: 3/12, completed (loss: 0.08172444254159927):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:09<13:54, 29.80s/it]Training Epoch: 3/12, completed (loss: 0.2932155430316925):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:09<13:54, 29.80s/it] Training Epoch: 3/12, completed (loss: 0.11897788196802139):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:24<13:54, 29.80s/it]Training Epoch: 3/12, completed (loss: 0.11897788196802139):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:38<13:19, 29.62s/it]Training Epoch: 3/12, completed (loss: 0.09078904986381531):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:38<13:19, 29.62s/it]Training Epoch: 3/12, completed (loss: 0.07399129867553711):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:53<13:19, 29.62s/it]Training Epoch: 3/12, completed (loss: 0.07399129867553711):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:07<12:47, 29.54s/it]Training Epoch: 3/12, completed (loss: 0.08793794363737106):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:08<12:47, 29.54s/it]Training Epoch: 3/12, completed (loss: 0.07972235977649689):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:22<12:47, 29.54s/it]Training Epoch: 3/12, completed (loss: 0.07972235977649689):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:37<12:16, 29.46s/it]Training Epoch: 3/12, completed (loss: 0.21355074644088745):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:37<12:16, 29.46s/it]Training Epoch: 3/12, completed (loss: 0.09380466490983963):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:52<12:16, 29.46s/it]Training Epoch: 3/12, completed (loss: 0.09380466490983963):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:06<11:46, 29.44s/it]Training Epoch: 3/12, completed (loss: 0.005598647985607386):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:06<11:46, 29.44s/it]Training Epoch: 3/12, completed (loss: 0.05184337496757507):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:21<11:46, 29.44s/it] Training Epoch: 3/12, completed (loss: 0.05184337496757507):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:35<11:16, 29.43s/it]Training Epoch: 3/12, completed (loss: 0.17108942568302155):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:36<11:16, 29.43s/it]Training Epoch: 3/12, completed (loss: 0.22898253798484802):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:50<11:16, 29.43s/it]Training Epoch: 3/12, completed (loss: 0.22898253798484802):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:05<10:47, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.15189990401268005):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:05<10:47, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.2814432680606842):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:20<10:47, 29.42s/it] Training Epoch: 3/12, completed (loss: 0.2814432680606842):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:34<10:17, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.32216233015060425):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:34<10:17, 29.42s/it]Training Epoch: 3/12, completed (loss: 0.3334082365036011):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:49<10:17, 29.42s/it] Training Epoch: 3/12, completed (loss: 0.3334082365036011):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:04<09:48, 29.41s/it]Training Epoch: 3/12, completed (loss: 0.27658823132514954):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:04<09:48, 29.41s/it]Training Epoch: 3/12, completed (loss: 0.38789764046669006):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:19<09:48, 29.41s/it]Training Epoch: 3/12, completed (loss: 0.38789764046669006):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:33<09:18, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.5030577182769775):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:33<09:18, 29.39s/it] Training Epoch: 3/12, completed (loss: 0.11068687587976456):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:48<09:18, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.11068687587976456):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:02<08:48, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.23335883021354675):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:03<08:48, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.17709146440029144):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:17<08:48, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.17709146440029144):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:32<08:19, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.15089000761508942):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:32<08:19, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.06384525448083878):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:47<08:19, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.06384525448083878):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:01<07:49, 29.37s/it]Training Epoch: 3/12, completed (loss: 0.23901133239269257):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:01<07:49, 29.37s/it]Training Epoch: 3/12, completed (loss: 0.24516715109348297):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:16<07:49, 29.37s/it]Training Epoch: 3/12, completed (loss: 0.24516715109348297):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:30<07:20, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.3041171729564667):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:31<07:20, 29.35s/it] Training Epoch: 3/12, completed (loss: 0.3570984899997711):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:45<07:20, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.3570984899997711):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:00<06:50, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.0018103675683960319):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:00<06:50, 29.32s/it]Training Epoch: 3/12, completed (loss: 0.2672384977340698):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:15<06:50, 29.32s/it]   Training Epoch: 3/12, completed (loss: 0.2672384977340698):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:29<06:22, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.16648007929325104):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:29<06:22, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.24986208975315094):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:44<06:22, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.24986208975315094):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:59<05:52, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.07957741618156433):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:33:59<05:52, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.31373897194862366):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:14<05:52, 29.39s/it]Training Epoch: 3/12, completed (loss: 0.31373897194862366):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:28<05:23, 29.41s/it]Training Epoch: 3/12, completed (loss: 0.0917045846581459):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:28<05:23, 29.41s/it] Training Epoch: 3/12, completed (loss: 0.08806082606315613):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:43<05:23, 29.41s/it]Training Epoch: 3/12, completed (loss: 0.08806082606315613):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:57<04:53, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.1635846495628357):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:34:57<04:53, 29.36s/it] Training Epoch: 3/12, completed (loss: 0.07234826683998108):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:12<04:53, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.07234826683998108):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:27<04:24, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.11381123960018158):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:27<04:24, 29.36s/it]Training Epoch: 3/12, completed (loss: 0.3614737093448639):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:42<04:24, 29.36s/it] Training Epoch: 3/12, completed (loss: 0.3614737093448639):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:56<03:54, 29.33s/it]Training Epoch: 3/12, completed (loss: 0.16228516399860382):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:35:56<03:54, 29.33s/it]Training Epoch: 3/12, completed (loss: 0.33211976289749146):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:11<03:54, 29.33s/it]Training Epoch: 3/12, completed (loss: 0.33211976289749146):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:25<03:25, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.3093843162059784):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:26<03:25, 29.38s/it] Training Epoch: 3/12, completed (loss: 0.16287830471992493):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:40<03:25, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.16287830471992493):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:55<02:56, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.2809831202030182):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:36:55<02:56, 29.38s/it] Training Epoch: 3/12, completed (loss: 0.17418046295642853):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:10<02:56, 29.38s/it]Training Epoch: 3/12, completed (loss: 0.17418046295642853):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:24<02:26, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.14971841871738434):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:24<02:26, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.11860395967960358):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:39<02:26, 29.35s/it]Training Epoch: 3/12, completed (loss: 0.11860395967960358):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:53<01:57, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.23531632125377655):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:37:53<01:57, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.09199424833059311):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:08<01:57, 29.30s/it]Training Epoch: 3/12, completed (loss: 0.09199424833059311):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:22<01:27, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.23545639216899872):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:23<01:27, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.08137590438127518):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:37<01:27, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.08137590438127518):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:52<00:58, 29.22s/it]Training Epoch: 3/12, completed (loss: 0.1606801599264145):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:52<00:58, 29.22s/it] Training Epoch: 3/12, completed (loss: 0.24056345224380493):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:39:06<00:58, 29.22s/it]Training Epoch: 3/12, completed (loss: 0.24056345224380493):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:21<00:29, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.17320071160793304):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:21<00:29, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.21849222481250763):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:36<00:29, 29.25s/it]Training Epoch: 3/12, completed (loss: 0.21849222481250763): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:39:50<00:00, 29.26s/it] eval_ppl=tensor(1.7877, device='cuda:0') eval_epoch_loss=tensor(0.5809, device='cuda:0')
Eval epoch loss:  tensor(0.5809, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_3_257
Time while saving:  2023-10-25 22:02:59 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 3, step_id: 343

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.98s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:40,  7.87s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:31,  7.83s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.84s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.85s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.89s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.90s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.91s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.91s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.91s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.94s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.93s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:58,  7.93s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.88s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.89s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.89s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.94s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.92s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.89s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.90s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.91s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.89s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.91s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.93s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.95s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it]
Training Epoch: 3/12, completed (loss: 3.078586087212898e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:48<00:00, 29.26s/it]Training Epoch: 3/12, completed (loss: 3.078586087212898e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:48<00:00, 36.21s/it]
 eval_ppl=tensor(1.7741, device='cuda:0') eval_epoch_loss=tensor(0.5733, device='cuda:0')
Eval epoch loss:  tensor(0.5733, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_3_343
Time while saving:  2023-10-25 22:27:57 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
Epoch ending time:  2023-10-25 22:27:58 IST+0530
Validation losses are: 
{'epoch_id': 0, 'ministep_id': 1, 'eval_epoch_loss': tensor(2.6360, device='cuda:0'), 'best_val_loss_yet': tensor(2.6360, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6698, device='cuda:0'), 'best_val_loss_yet': tensor(0.6698, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6023, device='cuda:0'), 'best_val_loss_yet': tensor(0.6023, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5568, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5643, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5634, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5644, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5524, device='cuda:0'), 'best_val_loss_yet': tensor(0.5524, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5513, device='cuda:0'), 'best_val_loss_yet': tensor(0.5513, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5386, device='cuda:0'), 'best_val_loss_yet': tensor(0.5386, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5370, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5769, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5758, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5729, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5558, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5550, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5881, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6249, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5809, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5733, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
$$$%%%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Epoch 3: train_perplexity=1.1891, train_epoch_loss=0.1732, epoch time 6228.50139477395s
Epoch starting time:  2023-10-25 22:27:58 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 4:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training Epoch: 4/12, completed (loss: 0.023053867742419243):   0%|[34m          [0m| 0/172 [00:14<?, ?it/s]Training Epoch: 4/12, completed (loss: 0.023053867742419243):   1%|[34m          [0m| 1/172 [00:29<1:23:15, 29.22s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 4, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:52,  8.01s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.92s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.87s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.82s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:00,  7.86s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.89s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.89s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.92s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.90s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.93s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.95s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:58,  7.93s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.92s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.91s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.89s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:29<01:26,  7.86s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:37<01:18,  7.90s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:45<01:11,  7.90s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.90s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.88s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.91s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.91s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.90s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.96s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.95s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.94s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it]
Training Epoch: 4/12, completed (loss: 0.08790089190006256):   1%|[34m          [0m| 1/172 [04:26<1:23:15, 29.22s/it] Training Epoch: 4/12, completed (loss: 0.06292138993740082):   1%|[34m          [0m| 1/172 [04:41<1:23:15, 29.22s/it]Training Epoch: 4/12, completed (loss: 0.06292138993740082):   1%|[34m          [0m| 2/172 [04:55<7:58:40, 168.95s/it]Training Epoch: 4/12, completed (loss: 0.19284699857234955):   1%|[34m          [0m| 2/172 [04:56<7:58:40, 168.95s/it]Training Epoch: 4/12, completed (loss: 0.06681527942419052):   1%|[34m          [0m| 2/172 [05:10<7:58:40, 168.95s/it]Training Epoch: 4/12, completed (loss: 0.06681527942419052):   2%|[34mâ–         [0m| 3/172 [05:25<4:56:27, 105.25s/it]Training Epoch: 4/12, completed (loss: 0.21601496636867523):   2%|[34mâ–         [0m| 3/172 [05:25<4:56:27, 105.25s/it]Training Epoch: 4/12, completed (loss: 0.18958216905593872):   2%|[34mâ–         [0m| 3/172 [05:40<4:56:27, 105.25s/it]Training Epoch: 4/12, completed (loss: 0.18958216905593872):   2%|[34mâ–         [0m| 4/172 [05:54<3:30:37, 75.22s/it] Training Epoch: 4/12, completed (loss: 0.027096087113022804):   2%|[34mâ–         [0m| 4/172 [05:54<3:30:37, 75.22s/it]Training Epoch: 4/12, completed (loss: 0.2187146246433258):   2%|[34mâ–         [0m| 4/172 [06:09<3:30:37, 75.22s/it]  Training Epoch: 4/12, completed (loss: 0.2187146246433258):   3%|[34mâ–Ž         [0m| 5/172 [06:24<2:43:24, 58.71s/it]Training Epoch: 4/12, completed (loss: 0.3583870828151703):   3%|[34mâ–Ž         [0m| 5/172 [06:24<2:43:24, 58.71s/it]Training Epoch: 4/12, completed (loss: 0.22346924245357513):   3%|[34mâ–Ž         [0m| 5/172 [06:38<2:43:24, 58.71s/it]Training Epoch: 4/12, completed (loss: 0.22346924245357513):   3%|[34mâ–Ž         [0m| 6/172 [06:53<2:14:37, 48.66s/it]Training Epoch: 4/12, completed (loss: 0.023418264463543892):   3%|[34mâ–Ž         [0m| 6/172 [06:53<2:14:37, 48.66s/it]Training Epoch: 4/12, completed (loss: 0.20267313718795776):   3%|[34mâ–Ž         [0m| 6/172 [07:08<2:14:37, 48.66s/it] Training Epoch: 4/12, completed (loss: 0.20267313718795776):   4%|[34mâ–         [0m| 7/172 [07:22<1:56:32, 42.38s/it]Training Epoch: 4/12, completed (loss: 0.05482213944196701):   4%|[34mâ–         [0m| 7/172 [07:22<1:56:32, 42.38s/it]Training Epoch: 4/12, completed (loss: 0.17777769267559052):   4%|[34mâ–         [0m| 7/172 [07:37<1:56:32, 42.38s/it]Training Epoch: 4/12, completed (loss: 0.17777769267559052):   5%|[34mâ–         [0m| 8/172 [07:52<1:44:31, 38.24s/it]Training Epoch: 4/12, completed (loss: 0.14216452836990356):   5%|[34mâ–         [0m| 8/172 [07:52<1:44:31, 38.24s/it]Training Epoch: 4/12, completed (loss: 0.296602725982666):   5%|[34mâ–         [0m| 8/172 [08:07<1:44:31, 38.24s/it]  Training Epoch: 4/12, completed (loss: 0.296602725982666):   5%|[34mâ–Œ         [0m| 9/172 [08:21<1:36:30, 35.53s/it]Training Epoch: 4/12, completed (loss: 0.1454494297504425):   5%|[34mâ–Œ         [0m| 9/172 [08:21<1:36:30, 35.53s/it]Training Epoch: 4/12, completed (loss: 0.07389005273580551):   5%|[34mâ–Œ         [0m| 9/172 [08:36<1:36:30, 35.53s/it]Training Epoch: 4/12, completed (loss: 0.07389005273580551):   6%|[34mâ–Œ         [0m| 10/172 [08:50<1:30:32, 33.53s/it]Training Epoch: 4/12, completed (loss: 0.20588083565235138):   6%|[34mâ–Œ         [0m| 10/172 [08:50<1:30:32, 33.53s/it]Training Epoch: 4/12, completed (loss: 0.1592990905046463):   6%|[34mâ–Œ         [0m| 10/172 [09:05<1:30:32, 33.53s/it] Training Epoch: 4/12, completed (loss: 0.1592990905046463):   6%|[34mâ–‹         [0m| 11/172 [09:19<1:26:26, 32.22s/it]Training Epoch: 4/12, completed (loss: 0.11401403695344925):   6%|[34mâ–‹         [0m| 11/172 [09:20<1:26:26, 32.22s/it]Training Epoch: 4/12, completed (loss: 0.19789613783359528):   6%|[34mâ–‹         [0m| 11/172 [09:34<1:26:26, 32.22s/it]Training Epoch: 4/12, completed (loss: 0.19789613783359528):   7%|[34mâ–‹         [0m| 12/172 [09:49<1:23:27, 31.30s/it]Training Epoch: 4/12, completed (loss: 0.16733847558498383):   7%|[34mâ–‹         [0m| 12/172 [09:49<1:23:27, 31.30s/it]Training Epoch: 4/12, completed (loss: 0.04459235072135925):   7%|[34mâ–‹         [0m| 12/172 [10:03<1:23:27, 31.30s/it]Training Epoch: 4/12, completed (loss: 0.04459235072135925):   8%|[34mâ–Š         [0m| 13/172 [10:18<1:21:16, 30.67s/it]Training Epoch: 4/12, completed (loss: 0.002264425391331315):   8%|[34mâ–Š         [0m| 13/172 [10:18<1:21:16, 30.67s/it]Training Epoch: 4/12, completed (loss: 0.23593054711818695):   8%|[34mâ–Š         [0m| 13/172 [10:33<1:21:16, 30.67s/it] Training Epoch: 4/12, completed (loss: 0.23593054711818695):   8%|[34mâ–Š         [0m| 14/172 [10:47<1:19:46, 30.29s/it]Training Epoch: 4/12, completed (loss: 0.2638924717903137):   8%|[34mâ–Š         [0m| 14/172 [10:47<1:19:46, 30.29s/it] Training Epoch: 4/12, completed (loss: 0.10107263177633286):   8%|[34mâ–Š         [0m| 14/172 [11:02<1:19:46, 30.29s/it]Training Epoch: 4/12, completed (loss: 0.10107263177633286):   9%|[34mâ–Š         [0m| 15/172 [11:17<1:18:30, 30.00s/it]Training Epoch: 4/12, completed (loss: 0.15067820250988007):   9%|[34mâ–Š         [0m| 15/172 [11:17<1:18:30, 30.00s/it]Training Epoch: 4/12, completed (loss: 0.01806989684700966):   9%|[34mâ–Š         [0m| 15/172 [11:32<1:18:30, 30.00s/it]Training Epoch: 4/12, completed (loss: 0.01806989684700966):   9%|[34mâ–‰         [0m| 16/172 [11:46<1:17:37, 29.86s/it]Training Epoch: 4/12, completed (loss: 0.1327762007713318):   9%|[34mâ–‰         [0m| 16/172 [11:46<1:17:37, 29.86s/it] Training Epoch: 4/12, completed (loss: 0.2709111273288727):   9%|[34mâ–‰         [0m| 16/172 [12:01<1:17:37, 29.86s/it]Training Epoch: 4/12, completed (loss: 0.2709111273288727):  10%|[34mâ–‰         [0m| 17/172 [12:16<1:16:50, 29.75s/it]Training Epoch: 4/12, completed (loss: 0.18319010734558105):  10%|[34mâ–‰         [0m| 17/172 [12:16<1:16:50, 29.75s/it]Training Epoch: 4/12, completed (loss: 0.13424015045166016):  10%|[34mâ–‰         [0m| 17/172 [12:30<1:16:50, 29.75s/it]Training Epoch: 4/12, completed (loss: 0.13424015045166016):  10%|[34mâ–ˆ         [0m| 18/172 [12:45<1:15:56, 29.59s/it]Training Epoch: 4/12, completed (loss: 0.21250125765800476):  10%|[34mâ–ˆ         [0m| 18/172 [12:45<1:15:56, 29.59s/it]Training Epoch: 4/12, completed (loss: 0.150421142578125):  10%|[34mâ–ˆ         [0m| 18/172 [13:00<1:15:56, 29.59s/it]  Training Epoch: 4/12, completed (loss: 0.150421142578125):  11%|[34mâ–ˆ         [0m| 19/172 [13:14<1:15:15, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.04261740297079086):  11%|[34mâ–ˆ         [0m| 19/172 [13:14<1:15:15, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.24798980355262756):  11%|[34mâ–ˆ         [0m| 19/172 [13:29<1:15:15, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.24798980355262756):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:43<1:14:30, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.04130330681800842):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:44<1:14:30, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.15274213254451752):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:58<1:14:30, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.15274213254451752):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:13<1:14:01, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.044360775500535965):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:13<1:14:01, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.05453065410256386):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:28<1:14:01, 29.41s/it] Training Epoch: 4/12, completed (loss: 0.05453065410256386):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:42<1:13:34, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.29654461145401):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:42<1:13:34, 29.43s/it]   Training Epoch: 4/12, completed (loss: 0.32435575127601624):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:57<1:13:34, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.32435575127601624):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:12<1:13:11, 29.47s/it]Training Epoch: 4/12, completed (loss: 0.0771847665309906):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:12<1:13:11, 29.47s/it] Training Epoch: 4/12, completed (loss: 0.26821085810661316):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:27<1:13:11, 29.47s/it]Training Epoch: 4/12, completed (loss: 0.26821085810661316):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:41<1:12:41, 29.47s/it]Training Epoch: 4/12, completed (loss: 0.32988807559013367):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:41<1:12:41, 29.47s/it]Training Epoch: 4/12, completed (loss: 0.03851195424795151):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:56<1:12:41, 29.47s/it]Training Epoch: 4/12, completed (loss: 0.03851195424795151):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:11<1:12:05, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.005532016512006521):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:11<1:12:05, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.1460241973400116):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:25<1:12:05, 29.43s/it]  Training Epoch: 4/12, completed (loss: 0.1460241973400116):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:40<1:11:32, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.21802636981010437):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:40<1:11:32, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.1295648217201233):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:55<1:11:32, 29.40s/it] Training Epoch: 4/12, completed (loss: 0.1295648217201233):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:09<1:10:58, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.13032187521457672):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:09<1:10:58, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.12678314745426178):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:24<1:10:58, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.12678314745426178):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:39<1:10:27, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.013254966586828232):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:39<1:10:27, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.33668985962867737):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:53<1:10:27, 29.36s/it] Training Epoch: 4/12, completed (loss: 0.33668985962867737):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:08<1:09:56, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.10725502669811249):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:08<1:09:56, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.2045837640762329):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:23<1:09:56, 29.35s/it] Training Epoch: 4/12, completed (loss: 0.2045837640762329):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:37<1:09:24, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.34974390268325806):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:37<1:09:24, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.009319155476987362):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:52<1:09:24, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.009319155476987362):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:06<1:08:52, 29.31s/it]Training Epoch: 4/12, completed (loss: 0.04663054645061493):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:07<1:08:52, 29.31s/it] Training Epoch: 4/12, completed (loss: 0.13181108236312866):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:21<1:08:52, 29.31s/it]Training Epoch: 4/12, completed (loss: 0.13181108236312866):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:36<1:08:27, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.07492625713348389):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:36<1:08:27, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.14335153996944427):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:51<1:08:27, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.14335153996944427):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:05<1:07:56, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.15679387748241425):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:05<1:07:56, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.24510568380355835):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:20<1:07:56, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.24510568380355835):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:34<1:07:29, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.18923388421535492):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:35<1:07:29, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.12187841534614563):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:49<1:07:29, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.12187841534614563):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:04<1:07:05, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.010957220569252968):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:04<1:07:05, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.1144006997346878):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:19<1:07:05, 29.38s/it]  Training Epoch: 4/12, completed (loss: 0.1144006997346878):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:33<1:06:39, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.083980493247509):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:34<1:06:39, 29.41s/it] Training Epoch: 4/12, completed (loss: 0.03608287498354912):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:48<1:06:39, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.03608287498354912):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:03<1:06:09, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.030104948207736015):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:03<1:06:09, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.08447720855474472):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:18<1:06:09, 29.40s/it] Training Epoch: 4/12, completed (loss: 0.08447720855474472):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:32<1:05:30, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.00024252408184111118):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:32<1:05:30, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.4008018374443054):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:47<1:05:30, 29.33s/it]    Training Epoch: 4/12, completed (loss: 0.4008018374443054):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:01<1:04:59, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.05031413957476616):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:01<1:04:59, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.28544896841049194):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:16<1:04:59, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.28544896841049194):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:30<1:04:26, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.1879422515630722):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:31<1:04:26, 29.30s/it] Training Epoch: 4/12, completed (loss: 0.13997304439544678):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:45<1:04:26, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.13997304439544678):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:00<1:04:00, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.1285826861858368):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:00<1:04:00, 29.32s/it] Training Epoch: 4/12, completed (loss: 0.011996351182460785):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:15<1:04:00, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.011996351182460785):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:29<1:03:35, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.08354064077138901):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:29<1:03:35, 29.35s/it] Training Epoch: 4/12, completed (loss: 0.07190167903900146):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:44<1:03:35, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.07190167903900146):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:59<1:03:04, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.05438883230090141):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:59<1:03:04, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.2853715717792511):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:13<1:03:04, 29.34s/it] Training Epoch: 4/12, completed (loss: 0.2853715717792511):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:28<1:02:34, 29.33s/it] eval_ppl=tensor(1.7702, device='cuda:0') eval_epoch_loss=tensor(0.5711, device='cuda:0')
Eval epoch loss:  tensor(0.5711, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_4_1
Time while saving:  2023-10-25 22:32:24 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 4, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.99s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:42,  7.96s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.89s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.84s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.90s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.93s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:02,  7.92s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.90s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:45,  7.90s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.91s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:30,  7.93s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.90s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.94s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.95s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.96s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.93s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.91s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.93s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.90s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.89s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.93s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.93s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.92s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.96s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.97s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.96s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it]
Training Epoch: 4/12, completed (loss: 0.2165592610836029):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:26<1:02:34, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.13004080951213837):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:41<1:02:34, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.13004080951213837):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:55<3:33:07, 100.69s/it]Training Epoch: 4/12, completed (loss: 0.002425840590149164):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:55<3:33:07, 100.69s/it]Training Epoch: 4/12, completed (loss: 0.31270766258239746):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [30:10<3:33:07, 100.69s/it] Training Epoch: 4/12, completed (loss: 0.31270766258239746):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:24<2:46:17, 79.19s/it] Training Epoch: 4/12, completed (loss: 0.0390297994017601):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:24<2:46:17, 79.19s/it] Training Epoch: 4/12, completed (loss: 0.06511542946100235):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:39<2:46:17, 79.19s/it]Training Epoch: 4/12, completed (loss: 0.06511542946100235):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:54<2:13:51, 64.25s/it]Training Epoch: 4/12, completed (loss: 0.13384461402893066):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:54<2:13:51, 64.25s/it]Training Epoch: 4/12, completed (loss: 0.3004710376262665):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [31:08<2:13:51, 64.25s/it] Training Epoch: 4/12, completed (loss: 0.3004710376262665):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:23<1:51:04, 53.75s/it]Training Epoch: 4/12, completed (loss: 0.08116365969181061):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:23<1:51:04, 53.75s/it]Training Epoch: 4/12, completed (loss: 0.07187458127737045):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:38<1:51:04, 53.75s/it]Training Epoch: 4/12, completed (loss: 0.07187458127737045):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:52<1:35:07, 46.40s/it]Training Epoch: 4/12, completed (loss: 0.0002232015976915136):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:52<1:35:07, 46.40s/it]Training Epoch: 4/12, completed (loss: 0.33850857615470886):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [32:07<1:35:07, 46.40s/it]  Training Epoch: 4/12, completed (loss: 0.33850857615470886):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:21<1:23:56, 41.28s/it]Training Epoch: 4/12, completed (loss: 0.13431420922279358):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:22<1:23:56, 41.28s/it]Training Epoch: 4/12, completed (loss: 0.25874754786491394):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:36<1:23:56, 41.28s/it]Training Epoch: 4/12, completed (loss: 0.25874754786491394):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:51<1:15:57, 37.67s/it]Training Epoch: 4/12, completed (loss: 0.0035483515821397305):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:51<1:15:57, 37.67s/it]Training Epoch: 4/12, completed (loss: 0.24022698402404785):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [33:06<1:15:57, 37.67s/it]  Training Epoch: 4/12, completed (loss: 0.24022698402404785):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:20<1:10:29, 35.25s/it]Training Epoch: 4/12, completed (loss: 0.08379387110471725):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:20<1:10:29, 35.25s/it]Training Epoch: 4/12, completed (loss: 0.41418570280075073):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:35<1:10:29, 35.25s/it]Training Epoch: 4/12, completed (loss: 0.41418570280075073):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:50<1:06:24, 33.48s/it]Training Epoch: 4/12, completed (loss: 0.03615783527493477):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:50<1:06:24, 33.48s/it]Training Epoch: 4/12, completed (loss: 0.09987830370664597):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [34:04<1:06:24, 33.48s/it]Training Epoch: 4/12, completed (loss: 0.09987830370664597):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:19<1:03:24, 32.24s/it]Training Epoch: 4/12, completed (loss: 0.08312185108661652):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:19<1:03:24, 32.24s/it]Training Epoch: 4/12, completed (loss: 0.11817978322505951):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:34<1:03:24, 32.24s/it]Training Epoch: 4/12, completed (loss: 0.11817978322505951):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:48<1:01:10, 31.37s/it]Training Epoch: 4/12, completed (loss: 0.020922960713505745):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:48<1:01:10, 31.37s/it]Training Epoch: 4/12, completed (loss: 0.044977590441703796):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [35:03<1:01:10, 31.37s/it]Training Epoch: 4/12, completed (loss: 0.044977590441703796):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:18<59:28, 30.76s/it]  Training Epoch: 4/12, completed (loss: 0.19675150513648987):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:18<59:28, 30.76s/it] Training Epoch: 4/12, completed (loss: 0.31770768761634827):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:32<59:28, 30.76s/it]Training Epoch: 4/12, completed (loss: 0.31770768761634827):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:47<58:10, 30.35s/it]Training Epoch: 4/12, completed (loss: 0.2096748799085617):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:47<58:10, 30.35s/it] Training Epoch: 4/12, completed (loss: 0.0089186392724514):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [36:02<58:10, 30.35s/it]Training Epoch: 4/12, completed (loss: 0.0089186392724514):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:16<57:05, 30.05s/it]Training Epoch: 4/12, completed (loss: 0.2324354201555252):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:17<57:05, 30.05s/it]Training Epoch: 4/12, completed (loss: 0.2910987138748169):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:31<57:05, 30.05s/it]Training Epoch: 4/12, completed (loss: 0.2910987138748169):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:46<56:17, 29.89s/it]Training Epoch: 4/12, completed (loss: 0.12548378109931946):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:46<56:17, 29.89s/it]Training Epoch: 4/12, completed (loss: 0.044759396463632584):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [37:01<56:17, 29.89s/it]Training Epoch: 4/12, completed (loss: 0.044759396463632584):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:15<55:22, 29.67s/it]Training Epoch: 4/12, completed (loss: 0.014038200490176678):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:15<55:22, 29.67s/it]Training Epoch: 4/12, completed (loss: 0.22690913081169128):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:30<55:22, 29.67s/it] Training Epoch: 4/12, completed (loss: 0.22690913081169128):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:44<54:43, 29.58s/it]Training Epoch: 4/12, completed (loss: 0.05180065706372261):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:45<54:43, 29.58s/it]Training Epoch: 4/12, completed (loss: 6.270789890550077e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:59<54:43, 29.58s/it]Training Epoch: 4/12, completed (loss: 6.270789890550077e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:14<54:07, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.3374271094799042):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:14<54:07, 29.52s/it]   Training Epoch: 4/12, completed (loss: 0.4396754801273346):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:29<54:07, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.4396754801273346):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:43<53:27, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.47949057817459106):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:43<53:27, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.058305010199546814):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:58<53:27, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.058305010199546814):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:12<52:59, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.13353706896305084):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:13<52:59, 29.44s/it] Training Epoch: 4/12, completed (loss: 0.14712294936180115):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:27<52:59, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.14712294936180115):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:42<52:28, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.07558201998472214):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:42<52:28, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.1956591010093689):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:57<52:28, 29.43s/it] Training Epoch: 4/12, completed (loss: 0.1956591010093689):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:11<51:58, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.11533144861459732):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:11<51:58, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.08580027520656586):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:26<51:58, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.08580027520656586):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:41<51:31, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.04960944503545761):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:41<51:31, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.04952668026089668):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:56<51:31, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.04952668026089668):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:10<51:01, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.0923643708229065):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:10<51:01, 29.44s/it] Training Epoch: 4/12, completed (loss: 0.2419881820678711):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:25<51:01, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.2419881820678711):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:39<50:25, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.0010366481728851795):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:40<50:25, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.1428908109664917):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:54<50:25, 29.37s/it]   Training Epoch: 4/12, completed (loss: 0.1428908109664917):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:09<49:56, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.35716375708580017):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:09<49:56, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.35480061173439026):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:24<49:56, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.35480061173439026):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:38<49:28, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.25075969099998474):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:38<49:28, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.0978747233748436):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:53<49:28, 29.39s/it] Training Epoch: 4/12, completed (loss: 0.0978747233748436):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:07<48:54, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.07241588085889816):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:08<48:54, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.3821505606174469):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:22<48:54, 29.35s/it] Training Epoch: 4/12, completed (loss: 0.3821505606174469):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:37<48:28, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.0010916320607066154):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:37<48:28, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.18625397980213165):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:52<48:28, 29.38s/it]  Training Epoch: 4/12, completed (loss: 0.18625397980213165):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:06<47:55, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.18931961059570312):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:06<47:55, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.26433324813842773):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:21<47:55, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.26433324813842773):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:35<47:27, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.05444801226258278):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:36<47:27, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.03114226646721363):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:50<47:27, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.03114226646721363):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:05<46:57, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.12117286771535873):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:05<46:57, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.07371518015861511):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:20<46:57, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.07371518015861511):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:34<46:24, 29.31s/it]Training Epoch: 4/12, completed (loss: 0.2182336002588272):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:34<46:24, 29.31s/it] Training Epoch: 4/12, completed (loss: 0.051528315991163254):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:49<46:24, 29.31s/it]Training Epoch: 4/12, completed (loss: 0.051528315991163254):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:03<45:56, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.11378417164087296):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:04<45:56, 29.32s/it] Training Epoch: 4/12, completed (loss: 0.1228928491473198):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:18<45:56, 29.32s/it] Training Epoch: 4/12, completed (loss: 0.1228928491473198):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:33<45:28, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.06706364452838898):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:33<45:28, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.18865883350372314):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:48<45:28, 29.33s/it]Training Epoch: 4/12, completed (loss: 0.18865883350372314):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:02<44:56, 29.31s/it]Training Epoch: 4/12, completed (loss: 0.036076612770557404):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:02<44:56, 29.31s/it]Training Epoch: 4/12, completed (loss: 0.2758580446243286):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:17<44:56, 29.31s/it]  Training Epoch: 4/12, completed (loss: 0.2758580446243286):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:31<44:31, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.09069587290287018):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:32<44:31, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.08214585483074188):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:46<44:31, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.08214585483074188):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:01<44:05, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.16151927411556244):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:01<44:05, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.24139338731765747):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:16<44:05, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.24139338731765747):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:30<43:37, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.2315424084663391):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:31<43:37, 29.41s/it] Training Epoch: 4/12, completed (loss: 0.20167423784732819):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:45<43:37, 29.41s/it]Training Epoch: 4/12, completed (loss: 0.20167423784732819):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [49:00<43:07, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.25557833909988403):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [49:00<43:07, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.09014847129583359):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [49:15<43:07, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.09014847129583359):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:29<42:35, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.38883844017982483):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:29<42:35, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.2807789146900177):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:44<42:35, 29.38s/it] Training Epoch: 4/12, completed (loss: 0.2807789146900177):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:58<42:06, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.24970465898513794):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:59<42:06, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.2832127511501312):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [50:13<42:06, 29.38s/it] Training Epoch: 4/12, completed (loss: 0.2832127511501312):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [50:28<41:36, 29.37s/it] eval_ppl=tensor(1.9679, device='cuda:0') eval_epoch_loss=tensor(0.6770, device='cuda:0')
Eval epoch loss:  tensor(0.6770, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_4_87
Time while saving:  2023-10-25 22:57:24 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 4, step_id: 173

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:52,  8.02s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:43,  7.98s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.92s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:25,  7.91s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.92s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.91s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.91s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:30,  7.93s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:35<02:22,  7.92s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:15,  7.96s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:51<02:07,  7.96s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.95s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.94s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.91s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.92s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.96s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.94s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.93s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.94s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.95s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.95s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:26<00:31,  7.93s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.96s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:50<00:07,  7.95s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:58<00:00,  7.93s/it]
Training Epoch: 4/12, completed (loss: 0.0808473527431488):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:26<41:36, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.017520183697342873):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:41<41:36, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.017520183697342873):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:55<2:21:06, 100.79s/it]Training Epoch: 4/12, completed (loss: 0.12812083959579468):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:55<2:21:06, 100.79s/it] Training Epoch: 4/12, completed (loss: 0.22801777720451355):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [55:10<2:21:06, 100.79s/it]Training Epoch: 4/12, completed (loss: 0.22801777720451355):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:25<1:49:45, 79.35s/it] Training Epoch: 4/12, completed (loss: 0.025395246222615242):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:25<1:49:45, 79.35s/it]Training Epoch: 4/12, completed (loss: 0.11664310097694397):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:40<1:49:45, 79.35s/it] Training Epoch: 4/12, completed (loss: 0.11664310097694397):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:54<1:27:57, 64.36s/it]Training Epoch: 4/12, completed (loss: 0.4187081456184387):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:54<1:27:57, 64.36s/it] Training Epoch: 4/12, completed (loss: 0.05391101539134979):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [56:09<1:27:57, 64.36s/it]Training Epoch: 4/12, completed (loss: 0.05391101539134979):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:23<1:12:44, 53.88s/it]Training Epoch: 4/12, completed (loss: 0.190270334482193):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:24<1:12:44, 53.88s/it]  Training Epoch: 4/12, completed (loss: 0.14500291645526886):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:38<1:12:44, 53.88s/it]Training Epoch: 4/12, completed (loss: 0.14500291645526886):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:53<1:02:00, 46.51s/it]Training Epoch: 4/12, completed (loss: 0.17925195395946503):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:53<1:02:00, 46.51s/it]Training Epoch: 4/12, completed (loss: 0.01772809401154518):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [57:08<1:02:00, 46.51s/it]Training Epoch: 4/12, completed (loss: 0.01772809401154518):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:22<54:30, 41.39s/it]  Training Epoch: 4/12, completed (loss: 0.30888479948043823):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:22<54:30, 41.39s/it]Training Epoch: 4/12, completed (loss: 0.15329255163669586):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:37<54:30, 41.39s/it]Training Epoch: 4/12, completed (loss: 0.15329255163669586):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:51<49:05, 37.77s/it]Training Epoch: 4/12, completed (loss: 0.15253528952598572):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:52<49:05, 37.77s/it]Training Epoch: 4/12, completed (loss: 0.45164844393730164):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [58:06<49:05, 37.77s/it]Training Epoch: 4/12, completed (loss: 0.45164844393730164):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:21<45:12, 35.23s/it]Training Epoch: 4/12, completed (loss: 0.038197629153728485):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:21<45:12, 35.23s/it]Training Epoch: 4/12, completed (loss: 0.02889733947813511):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:36<45:12, 35.23s/it] Training Epoch: 4/12, completed (loss: 0.02889733947813511):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:50<42:26, 33.51s/it]Training Epoch: 4/12, completed (loss: 0.15093348920345306):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:50<42:26, 33.51s/it]Training Epoch: 4/12, completed (loss: 0.21500377357006073):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [59:05<42:26, 33.51s/it]Training Epoch: 4/12, completed (loss: 0.21500377357006073):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:20<40:19, 32.26s/it]Training Epoch: 4/12, completed (loss: 0.07167093455791473):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:20<40:19, 32.26s/it]Training Epoch: 4/12, completed (loss: 0.18347768485546112):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:34<40:19, 32.26s/it]Training Epoch: 4/12, completed (loss: 0.18347768485546112):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:49<38:40, 31.35s/it]Training Epoch: 4/12, completed (loss: 0.08237333595752716):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:49<38:40, 31.35s/it]Training Epoch: 4/12, completed (loss: 0.27324649691581726):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [1:00:04<38:40, 31.35s/it]Training Epoch: 4/12, completed (loss: 0.27324649691581726):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:18<37:25, 30.76s/it]Training Epoch: 4/12, completed (loss: 0.04990038648247719):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:18<37:25, 30.76s/it]Training Epoch: 4/12, completed (loss: 0.13004419207572937):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:33<37:25, 30.76s/it]Training Epoch: 4/12, completed (loss: 0.13004419207572937):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:47<36:20, 30.29s/it]Training Epoch: 4/12, completed (loss: 0.0025003536138683558):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:48<36:20, 30.29s/it]Training Epoch: 4/12, completed (loss: 0.0005204997141845524):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:01:02<36:20, 30.29s/it]Training Epoch: 4/12, completed (loss: 0.0005204997141845524):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:17<35:29, 29.99s/it]Training Epoch: 4/12, completed (loss: 0.08286314457654953):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:17<35:29, 29.99s/it]  Training Epoch: 4/12, completed (loss: 0.04763050749897957):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:32<35:29, 29.99s/it]Training Epoch: 4/12, completed (loss: 0.04763050749897957):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:46<34:44, 29.78s/it]Training Epoch: 4/12, completed (loss: 0.1565704196691513):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:46<34:44, 29.78s/it] Training Epoch: 4/12, completed (loss: 0.17901024222373962):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:02:01<34:44, 29.78s/it]Training Epoch: 4/12, completed (loss: 0.17901024222373962):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:15<34:04, 29.63s/it]Training Epoch: 4/12, completed (loss: 0.036929450929164886):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:16<34:04, 29.63s/it]Training Epoch: 4/12, completed (loss: 0.041494060307741165):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:30<34:04, 29.63s/it]Training Epoch: 4/12, completed (loss: 0.041494060307741165):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:45<33:27, 29.51s/it]Training Epoch: 4/12, completed (loss: 0.15280306339263916):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:45<33:27, 29.51s/it] Training Epoch: 4/12, completed (loss: 0.21875517070293427):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:59<33:27, 29.51s/it]Training Epoch: 4/12, completed (loss: 0.21875517070293427):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:14<32:54, 29.48s/it]Training Epoch: 4/12, completed (loss: 0.24363915622234344):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:14<32:54, 29.48s/it]Training Epoch: 4/12, completed (loss: 0.004600894637405872):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:29<32:54, 29.48s/it]Training Epoch: 4/12, completed (loss: 0.004600894637405872):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:43<32:23, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.13197246193885803):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:44<32:23, 29.44s/it] Training Epoch: 4/12, completed (loss: 0.06074666604399681):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:58<32:23, 29.44s/it]Training Epoch: 4/12, completed (loss: 0.06074666604399681):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:12<31:49, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.1867300570011139):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:13<31:49, 29.37s/it] Training Epoch: 4/12, completed (loss: 0.18185347318649292):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:27<31:49, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.18185347318649292):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:42<31:18, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.09717955440282822):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:42<31:18, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.12679901719093323):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:57<31:18, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.12679901719093323):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:11<30:46, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.0779871940612793):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:11<30:46, 29.32s/it] Training Epoch: 4/12, completed (loss: 0.09934129565954208):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:26<30:46, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.09934129565954208):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:40<30:15, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.001884486060589552):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:40<30:15, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.13663625717163086):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:55<30:15, 29.28s/it] Training Epoch: 4/12, completed (loss: 0.13663625717163086):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:10<29:46, 29.28s/it]Training Epoch: 4/12, completed (loss: 1.0725547326728702e-05):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:10<29:46, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.20074689388275146):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:24<29:46, 29.28s/it]   Training Epoch: 4/12, completed (loss: 0.20074689388275146):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:39<29:16, 29.27s/it]Training Epoch: 4/12, completed (loss: 0.3029846251010895):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:39<29:16, 29.27s/it] Training Epoch: 4/12, completed (loss: 0.16677778959274292):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:54<29:16, 29.27s/it]Training Epoch: 4/12, completed (loss: 0.16677778959274292):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:08<28:47, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.03304009512066841):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:08<28:47, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.4424280822277069):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:23<28:47, 29.28s/it] Training Epoch: 4/12, completed (loss: 0.4424280822277069):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:37<28:17, 29.27s/it]Training Epoch: 4/12, completed (loss: 0.0017158190021291375):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:38<28:17, 29.27s/it]Training Epoch: 4/12, completed (loss: 0.10513521730899811):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:52<28:17, 29.27s/it]  Training Epoch: 4/12, completed (loss: 0.10513521730899811):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:07<27:50, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.21789686381816864):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:07<27:50, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.21829749643802643):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:22<27:50, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.21829749643802643):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:36<27:22, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.2604457437992096):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:36<27:22, 29.32s/it] Training Epoch: 4/12, completed (loss: 0.1799340397119522):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:51<27:22, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.1799340397119522):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:05<26:52, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.023701051250100136):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:06<26:52, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.15921203792095184):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:20<26:52, 29.32s/it] Training Epoch: 4/12, completed (loss: 0.15921203792095184):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:35<26:23, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.17440342903137207):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:35<26:23, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.07591947168111801):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:50<26:23, 29.32s/it]Training Epoch: 4/12, completed (loss: 0.07591947168111801):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:04<25:52, 29.29s/it]Training Epoch: 4/12, completed (loss: 0.2532024383544922):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:04<25:52, 29.29s/it] Training Epoch: 4/12, completed (loss: 0.1536312848329544):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:19<25:52, 29.29s/it]Training Epoch: 4/12, completed (loss: 0.1536312848329544):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:33<25:23, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.16566255688667297):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:33<25:23, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.2389204055070877):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:48<25:23, 29.30s/it] Training Epoch: 4/12, completed (loss: 0.2389204055070877):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:03<24:57, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.0776023119688034):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:03<24:57, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.25192227959632874):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:18<24:57, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.25192227959632874):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:32<24:27, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.011174572631716728):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:32<24:27, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.2926495671272278):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:47<24:27, 29.35s/it]  Training Epoch: 4/12, completed (loss: 0.2926495671272278):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:01<23:58, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.16734789311885834):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:02<23:58, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.2738869786262512):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:16<23:58, 29.36s/it] Training Epoch: 4/12, completed (loss: 0.2738869786262512):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:31<23:29, 29.36s/it]Training Epoch: 4/12, completed (loss: 0.03980768471956253):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:31<23:29, 29.36s/it]Training Epoch: 4/12, completed (loss: 4.876542152487673e-05):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:46<23:29, 29.36s/it]Training Epoch: 4/12, completed (loss: 4.876542152487673e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:00<22:55, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.0009855509269982576):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:00<22:55, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.13847973942756653):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:15<22:55, 29.28s/it]  Training Epoch: 4/12, completed (loss: 0.13847973942756653):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:29<22:27, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.003614910878241062):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:29<22:27, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.1050708070397377):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:44<22:27, 29.30s/it]  Training Epoch: 4/12, completed (loss: 0.1050708070397377):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:59<21:57, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.3450488746166229):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:59<21:57, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.1835811287164688):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:14:13<21:57, 29.28s/it]Training Epoch: 4/12, completed (loss: 0.1835811287164688):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:28<21:31, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.1098107323050499):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:28<21:31, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.06458268314599991):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:43<21:31, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.06458268314599991):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:14:57<21:01, 29.34s/it] eval_ppl=tensor(1.9137, device='cuda:0') eval_epoch_loss=tensor(0.6490, device='cuda:0')
Eval epoch loss:  tensor(0.6490, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_4_173
Time while saving:  2023-10-25 23:22:24 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 4, step_id: 257

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.97s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.92s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.86s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.86s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.89s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.91s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:00,  7.87s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.88s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.87s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:37,  7.87s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:31,  7.99s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.93s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.96s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.93s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:58,  7.93s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.92s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.91s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.89s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.91s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.93s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.91s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.90s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.93s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.93s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.92s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.96s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it]
Training Epoch: 4/12, completed (loss: 0.3313290476799011):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:55<21:01, 29.34s/it] Training Epoch: 4/12, completed (loss: 0.1297338604927063):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:19:10<21:01, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.1297338604927063):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:24<1:10:23, 100.57s/it]Training Epoch: 4/12, completed (loss: 0.02158278040587902):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:24<1:10:23, 100.57s/it]Training Epoch: 4/12, completed (loss: 0.11947617679834366):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:39<1:10:23, 100.57s/it]Training Epoch: 4/12, completed (loss: 0.11947617679834366):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:53<54:06, 79.18s/it]   Training Epoch: 4/12, completed (loss: 0.028411610051989555):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:54<54:06, 79.18s/it]Training Epoch: 4/12, completed (loss: 2.5767481929506175e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:20:08<54:06, 79.18s/it]Training Epoch: 4/12, completed (loss: 2.5767481929506175e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:23<42:46, 64.17s/it]Training Epoch: 4/12, completed (loss: 0.04700914025306702):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:23<42:46, 64.17s/it]   Training Epoch: 4/12, completed (loss: 0.10626638680696487):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:37<42:46, 64.17s/it]Training Epoch: 4/12, completed (loss: 0.10626638680696487):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:52<34:54, 53.71s/it]Training Epoch: 4/12, completed (loss: 0.035897620022296906):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:52<34:54, 53.71s/it]Training Epoch: 4/12, completed (loss: 0.21591903269290924):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:21:07<34:54, 53.71s/it] Training Epoch: 4/12, completed (loss: 0.21591903269290924):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:21<29:25, 46.45s/it]Training Epoch: 4/12, completed (loss: 0.37146592140197754):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:22<29:25, 46.45s/it]Training Epoch: 4/12, completed (loss: 0.04231971502304077):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:36<29:25, 46.45s/it]Training Epoch: 4/12, completed (loss: 0.04231971502304077):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:51<25:28, 41.31s/it]Training Epoch: 4/12, completed (loss: 0.08881333470344543):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:51<25:28, 41.31s/it]Training Epoch: 4/12, completed (loss: 0.08499833941459656):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:22:05<25:28, 41.31s/it]Training Epoch: 4/12, completed (loss: 0.08499833941459656):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:20<22:38, 37.73s/it]Training Epoch: 4/12, completed (loss: 0.19482876360416412):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:20<22:38, 37.73s/it]Training Epoch: 4/12, completed (loss: 0.11101530492305756):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:35<22:38, 37.73s/it]Training Epoch: 4/12, completed (loss: 0.11101530492305756):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:49<20:33, 35.23s/it]Training Epoch: 4/12, completed (loss: 0.02100495621562004):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:50<20:33, 35.23s/it]Training Epoch: 4/12, completed (loss: 0.011354326270520687):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:23:04<20:33, 35.23s/it]Training Epoch: 4/12, completed (loss: 0.011354326270520687):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:19<18:57, 33.46s/it]Training Epoch: 4/12, completed (loss: 0.03374022990465164):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:19<18:57, 33.46s/it] Training Epoch: 4/12, completed (loss: 0.16896449029445648):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:34<18:57, 33.46s/it]Training Epoch: 4/12, completed (loss: 0.16896449029445648):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:48<17:42, 32.18s/it]Training Epoch: 4/12, completed (loss: 0.003412496531382203):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:48<17:42, 32.18s/it]Training Epoch: 4/12, completed (loss: 0.22614672780036926):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:24:03<17:42, 32.18s/it] Training Epoch: 4/12, completed (loss: 0.22614672780036926):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:17<16:42, 31.34s/it]Training Epoch: 4/12, completed (loss: 0.1397775560617447):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:18<16:42, 31.34s/it] Training Epoch: 4/12, completed (loss: 0.04162270203232765):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:32<16:42, 31.34s/it]Training Epoch: 4/12, completed (loss: 0.04162270203232765):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:47<15:54, 30.79s/it]Training Epoch: 4/12, completed (loss: 0.00017542581190355122):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:47<15:54, 30.79s/it]Training Epoch: 4/12, completed (loss: 6.357574602589011e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:25:02<15:54, 30.79s/it] Training Epoch: 4/12, completed (loss: 6.357574602589011e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:16<15:09, 30.31s/it]Training Epoch: 4/12, completed (loss: 0.21720416843891144):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:16<15:09, 30.31s/it]  Training Epoch: 4/12, completed (loss: 0.24012251198291779):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:31<15:09, 30.31s/it]Training Epoch: 4/12, completed (loss: 0.24012251198291779):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:45<14:30, 30.01s/it]Training Epoch: 4/12, completed (loss: 0.19750413298606873):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:46<14:30, 30.01s/it]Training Epoch: 4/12, completed (loss: 0.06738366931676865):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:26:00<14:30, 30.01s/it]Training Epoch: 4/12, completed (loss: 0.06738366931676865):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:15<13:54, 29.80s/it]Training Epoch: 4/12, completed (loss: 0.26903605461120605):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:15<13:54, 29.80s/it]Training Epoch: 4/12, completed (loss: 0.09674204140901566):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:29<13:54, 29.80s/it]Training Epoch: 4/12, completed (loss: 0.09674204140901566):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:44<13:19, 29.61s/it]Training Epoch: 4/12, completed (loss: 0.01628822833299637):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:44<13:19, 29.61s/it]Training Epoch: 4/12, completed (loss: 0.04276534169912338):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:59<13:19, 29.61s/it]Training Epoch: 4/12, completed (loss: 0.04276534169912338):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:13<12:47, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.05149129405617714):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:13<12:47, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.041828833520412445):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:28<12:47, 29.52s/it]Training Epoch: 4/12, completed (loss: 0.041828833520412445):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:42<12:16, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.22315703332424164):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:43<12:16, 29.46s/it] Training Epoch: 4/12, completed (loss: 0.05379854887723923):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:57<12:16, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.05379854887723923):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:12<11:46, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.0036795425694435835):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:12<11:46, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.022733820602297783):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:27<11:46, 29.46s/it] Training Epoch: 4/12, completed (loss: 0.022733820602297783):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:41<11:17, 29.45s/it]Training Epoch: 4/12, completed (loss: 0.14253267645835876):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:42<11:17, 29.45s/it] Training Epoch: 4/12, completed (loss: 0.1976604461669922):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:56<11:17, 29.45s/it] Training Epoch: 4/12, completed (loss: 0.1976604461669922):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:11<10:47, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.11554113775491714):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:11<10:47, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.23268060386180878):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:26<10:47, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.23268060386180878):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:40<10:17, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.27792099118232727):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:40<10:17, 29.43s/it]Training Epoch: 4/12, completed (loss: 0.2010018229484558):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:55<10:17, 29.43s/it] Training Epoch: 4/12, completed (loss: 0.2010018229484558):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:10<09:48, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.21369363367557526):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:10<09:48, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.3708637058734894):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:24<09:48, 29.42s/it] Training Epoch: 4/12, completed (loss: 0.3708637058734894):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:39<09:18, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.345582515001297):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:39<09:18, 29.39s/it] Training Epoch: 4/12, completed (loss: 0.043965693563222885):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:54<09:18, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.043965693563222885):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:08<08:48, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.1670340895652771):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:08<08:48, 29.38s/it]  Training Epoch: 4/12, completed (loss: 0.15068532526493073):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:23<08:48, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.15068532526493073):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:38<08:19, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.12654490768909454):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:38<08:19, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.03542032837867737):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:52<08:19, 29.39s/it]Training Epoch: 4/12, completed (loss: 0.03542032837867737):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:07<07:50, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.20568037033081055):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:07<07:50, 29.38s/it]Training Epoch: 4/12, completed (loss: 0.1977693736553192):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:22<07:50, 29.38s/it] Training Epoch: 4/12, completed (loss: 0.1977693736553192):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:36<07:20, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.21359896659851074):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:37<07:20, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.28698834776878357):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:51<07:20, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.28698834776878357):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:06<06:50, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.0014749831752851605):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:06<06:50, 29.34s/it]Training Epoch: 4/12, completed (loss: 0.20128199458122253):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:21<06:50, 29.34s/it]  Training Epoch: 4/12, completed (loss: 0.20128199458122253):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:35<06:23, 29.48s/it]Training Epoch: 4/12, completed (loss: 0.1314268559217453):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:36<06:23, 29.48s/it] Training Epoch: 4/12, completed (loss: 0.26779302954673767):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:50<06:23, 29.48s/it]Training Epoch: 4/12, completed (loss: 0.26779302954673767):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:05<05:53, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.08123950660228729):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:05<05:53, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.24698875844478607):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:20<05:53, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.24698875844478607):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:34<05:24, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.09490875899791718):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:34<05:24, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.023418821394443512):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:49<05:24, 29.46s/it]Training Epoch: 4/12, completed (loss: 0.023418821394443512):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:04<04:54, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.15846475958824158):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:04<04:54, 29.42s/it] Training Epoch: 4/12, completed (loss: 0.1312229484319687):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:19<04:54, 29.42s/it] Training Epoch: 4/12, completed (loss: 0.1312229484319687):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:33<04:24, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.07756956666707993):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:33<04:24, 29.40s/it]Training Epoch: 4/12, completed (loss: 0.3086720108985901):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:48<04:24, 29.40s/it] Training Epoch: 4/12, completed (loss: 0.3086720108985901):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:02<03:54, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.15670302510261536):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:02<03:54, 29.37s/it]Training Epoch: 4/12, completed (loss: 0.3946177363395691):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:17<03:54, 29.37s/it] Training Epoch: 4/12, completed (loss: 0.3946177363395691):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:32<03:25, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.3068121671676636):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:32<03:25, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.14562013745307922):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:47<03:25, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.14562013745307922):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:01<02:56, 29.49s/it]Training Epoch: 4/12, completed (loss: 0.3015744686126709):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:02<02:56, 29.49s/it] Training Epoch: 4/12, completed (loss: 0.09822101145982742):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:16<02:56, 29.49s/it]Training Epoch: 4/12, completed (loss: 0.09822101145982742):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:31<02:27, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.08765310049057007):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:31<02:27, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.13503070175647736):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:45<02:27, 29.42s/it]Training Epoch: 4/12, completed (loss: 0.13503070175647736):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:00<01:57, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.23213675618171692):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:00<01:57, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.013586437329649925):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:15<01:57, 29.35s/it]Training Epoch: 4/12, completed (loss: 0.013586437329649925):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:29<01:27, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.1841304898262024):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:29<01:27, 29.30s/it]  Training Epoch: 4/12, completed (loss: 0.013209443539381027):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:44<01:27, 29.30s/it]Training Epoch: 4/12, completed (loss: 0.013209443539381027):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:58<00:58, 29.26s/it]Training Epoch: 4/12, completed (loss: 0.13881734013557434):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:58<00:58, 29.26s/it] Training Epoch: 4/12, completed (loss: 0.19704578816890717):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:39:13<00:58, 29.26s/it]Training Epoch: 4/12, completed (loss: 0.19704578816890717):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:28<00:29, 29.29s/it]Training Epoch: 4/12, completed (loss: 0.1651259958744049):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:28<00:29, 29.29s/it] Training Epoch: 4/12, completed (loss: 0.2659434974193573):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:43<00:29, 29.29s/it]Training Epoch: 4/12, completed (loss: 0.2659434974193573): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:39:57<00:00, 29.29s/it] eval_ppl=tensor(1.8917, device='cuda:0') eval_epoch_loss=tensor(0.6375, device='cuda:0')
Eval epoch loss:  tensor(0.6375, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_4_257
Time while saving:  2023-10-25 23:46:53 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 4, step_id: 343

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:48,  7.87s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:40,  7.88s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.85s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.86s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.93s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.93s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.94s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:31,  7.95s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.93s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.96s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.97s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.97s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.95s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.95s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.94s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.94s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.91s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.91s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.88s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.92s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.92s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.92s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.93s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.94s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it]
Training Epoch: 4/12, completed (loss: 9.678750757302623e-06): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:55<00:00, 29.29s/it]Training Epoch: 4/12, completed (loss: 9.678750757302623e-06): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:55<00:00, 36.25s/it]
 eval_ppl=tensor(1.8723, device='cuda:0') eval_epoch_loss=tensor(0.6272, device='cuda:0')
Eval epoch loss:  tensor(0.6272, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_4_343
Time while saving:  2023-10-26 00:11:53 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
Epoch ending time:  2023-10-26 00:11:53 IST+0530
Validation losses are: 
{'epoch_id': 0, 'ministep_id': 1, 'eval_epoch_loss': tensor(2.6360, device='cuda:0'), 'best_val_loss_yet': tensor(2.6360, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6698, device='cuda:0'), 'best_val_loss_yet': tensor(0.6698, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6023, device='cuda:0'), 'best_val_loss_yet': tensor(0.6023, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5568, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5643, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5634, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5644, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5524, device='cuda:0'), 'best_val_loss_yet': tensor(0.5524, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5513, device='cuda:0'), 'best_val_loss_yet': tensor(0.5513, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5386, device='cuda:0'), 'best_val_loss_yet': tensor(0.5386, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5370, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5769, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5758, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5729, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5558, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5550, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5881, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6249, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5809, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5733, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5711, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6770, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6490, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.6375, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.6272, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
$$$%%%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Epoch 4: train_perplexity=1.1560, train_epoch_loss=0.1449, epoch time 6235.732353152009s
Epoch starting time:  2023-10-26 00:11:53 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 5:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training Epoch: 5/12, completed (loss: 0.02371995709836483):   0%|[34m          [0m| 0/172 [00:14<?, ?it/s]Training Epoch: 5/12, completed (loss: 0.02371995709836483):   1%|[34m          [0m| 1/172 [00:29<1:23:21, 29.25s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 5, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:53,  8.07s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:43,  7.98s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.91s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.85s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.91s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.92s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.91s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:45,  7.89s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:31,  7.95s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:35<02:22,  7.93s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:14,  7.93s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.94s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.95s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.92s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.92s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.93s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.93s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.93s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.94s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.96s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.95s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:26<00:31,  7.92s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.93s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.94s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it]
Training Epoch: 5/12, completed (loss: 0.08602939546108246):   1%|[34m          [0m| 1/172 [04:27<1:23:21, 29.25s/it]Training Epoch: 5/12, completed (loss: 0.01581190526485443):   1%|[34m          [0m| 1/172 [04:42<1:23:21, 29.25s/it]Training Epoch: 5/12, completed (loss: 0.01581190526485443):   1%|[34m          [0m| 2/172 [04:56<7:59:32, 169.25s/it]Training Epoch: 5/12, completed (loss: 0.1539216935634613):   1%|[34m          [0m| 2/172 [04:56<7:59:32, 169.25s/it] Training Epoch: 5/12, completed (loss: 0.07786407321691513):   1%|[34m          [0m| 2/172 [05:11<7:59:32, 169.25s/it]Training Epoch: 5/12, completed (loss: 0.07786407321691513):   2%|[34mâ–         [0m| 3/172 [05:25<4:56:53, 105.40s/it]Training Epoch: 5/12, completed (loss: 0.1672831028699875):   2%|[34mâ–         [0m| 3/172 [05:26<4:56:53, 105.40s/it] Training Epoch: 5/12, completed (loss: 0.19102001190185547):   2%|[34mâ–         [0m| 3/172 [05:40<4:56:53, 105.40s/it]Training Epoch: 5/12, completed (loss: 0.19102001190185547):   2%|[34mâ–         [0m| 4/172 [05:55<3:30:53, 75.32s/it] Training Epoch: 5/12, completed (loss: 0.018429525196552277):   2%|[34mâ–         [0m| 4/172 [05:55<3:30:53, 75.32s/it]Training Epoch: 5/12, completed (loss: 0.210371196269989):   2%|[34mâ–         [0m| 4/172 [06:09<3:30:53, 75.32s/it]   Training Epoch: 5/12, completed (loss: 0.210371196269989):   3%|[34mâ–Ž         [0m| 5/172 [06:24<2:43:31, 58.75s/it]Training Epoch: 5/12, completed (loss: 0.3833603858947754):   3%|[34mâ–Ž         [0m| 5/172 [06:24<2:43:31, 58.75s/it]Training Epoch: 5/12, completed (loss: 0.21904435753822327):   3%|[34mâ–Ž         [0m| 5/172 [06:39<2:43:31, 58.75s/it]Training Epoch: 5/12, completed (loss: 0.21904435753822327):   3%|[34mâ–Ž         [0m| 6/172 [06:53<2:14:42, 48.69s/it]Training Epoch: 5/12, completed (loss: 0.0059889559634029865):   3%|[34mâ–Ž         [0m| 6/172 [06:53<2:14:42, 48.69s/it]Training Epoch: 5/12, completed (loss: 0.2686483860015869):   3%|[34mâ–Ž         [0m| 6/172 [07:08<2:14:42, 48.69s/it]   Training Epoch: 5/12, completed (loss: 0.2686483860015869):   4%|[34mâ–         [0m| 7/172 [07:23<1:56:35, 42.40s/it]Training Epoch: 5/12, completed (loss: 0.05420706421136856):   4%|[34mâ–         [0m| 7/172 [07:23<1:56:35, 42.40s/it]Training Epoch: 5/12, completed (loss: 0.15944457054138184):   4%|[34mâ–         [0m| 7/172 [07:37<1:56:35, 42.40s/it]Training Epoch: 5/12, completed (loss: 0.15944457054138184):   5%|[34mâ–         [0m| 8/172 [07:52<1:44:32, 38.25s/it]Training Epoch: 5/12, completed (loss: 0.12464810162782669):   5%|[34mâ–         [0m| 8/172 [07:52<1:44:32, 38.25s/it]Training Epoch: 5/12, completed (loss: 0.29977044463157654):   5%|[34mâ–         [0m| 8/172 [08:07<1:44:32, 38.25s/it]Training Epoch: 5/12, completed (loss: 0.29977044463157654):   5%|[34mâ–Œ         [0m| 9/172 [08:22<1:36:30, 35.52s/it]Training Epoch: 5/12, completed (loss: 0.14535260200500488):   5%|[34mâ–Œ         [0m| 9/172 [08:22<1:36:30, 35.52s/it]Training Epoch: 5/12, completed (loss: 0.04768439382314682):   5%|[34mâ–Œ         [0m| 9/172 [08:36<1:36:30, 35.52s/it]Training Epoch: 5/12, completed (loss: 0.04768439382314682):   6%|[34mâ–Œ         [0m| 10/172 [08:51<1:30:32, 33.53s/it]Training Epoch: 5/12, completed (loss: 0.19880929589271545):   6%|[34mâ–Œ         [0m| 10/172 [08:51<1:30:32, 33.53s/it]Training Epoch: 5/12, completed (loss: 0.13372725248336792):   6%|[34mâ–Œ         [0m| 10/172 [09:05<1:30:32, 33.53s/it]Training Epoch: 5/12, completed (loss: 0.13372725248336792):   6%|[34mâ–‹         [0m| 11/172 [09:20<1:26:26, 32.22s/it]Training Epoch: 5/12, completed (loss: 0.08417735248804092):   6%|[34mâ–‹         [0m| 11/172 [09:20<1:26:26, 32.22s/it]Training Epoch: 5/12, completed (loss: 0.17602649331092834):   6%|[34mâ–‹         [0m| 11/172 [09:35<1:26:26, 32.22s/it]Training Epoch: 5/12, completed (loss: 0.17602649331092834):   7%|[34mâ–‹         [0m| 12/172 [09:49<1:23:28, 31.30s/it]Training Epoch: 5/12, completed (loss: 0.13072246313095093):   7%|[34mâ–‹         [0m| 12/172 [09:49<1:23:28, 31.30s/it]Training Epoch: 5/12, completed (loss: 0.05697508901357651):   7%|[34mâ–‹         [0m| 12/172 [10:04<1:23:28, 31.30s/it]Training Epoch: 5/12, completed (loss: 0.05697508901357651):   8%|[34mâ–Š         [0m| 13/172 [10:18<1:21:15, 30.66s/it]Training Epoch: 5/12, completed (loss: 0.003144201124086976):   8%|[34mâ–Š         [0m| 13/172 [10:18<1:21:15, 30.66s/it]Training Epoch: 5/12, completed (loss: 0.2428867369890213):   8%|[34mâ–Š         [0m| 13/172 [10:33<1:21:15, 30.66s/it]  Training Epoch: 5/12, completed (loss: 0.2428867369890213):   8%|[34mâ–Š         [0m| 14/172 [10:48<1:19:42, 30.27s/it]Training Epoch: 5/12, completed (loss: 0.2791227102279663):   8%|[34mâ–Š         [0m| 14/172 [10:48<1:19:42, 30.27s/it]Training Epoch: 5/12, completed (loss: 0.04496903717517853):   8%|[34mâ–Š         [0m| 14/172 [11:02<1:19:42, 30.27s/it]Training Epoch: 5/12, completed (loss: 0.04496903717517853):   9%|[34mâ–Š         [0m| 15/172 [11:17<1:18:23, 29.96s/it]Training Epoch: 5/12, completed (loss: 0.09296148270368576):   9%|[34mâ–Š         [0m| 15/172 [11:17<1:18:23, 29.96s/it]Training Epoch: 5/12, completed (loss: 0.034150853753089905):   9%|[34mâ–Š         [0m| 15/172 [11:32<1:18:23, 29.96s/it]Training Epoch: 5/12, completed (loss: 0.034150853753089905):   9%|[34mâ–‰         [0m| 16/172 [11:46<1:17:28, 29.80s/it]Training Epoch: 5/12, completed (loss: 0.110586978495121):   9%|[34mâ–‰         [0m| 16/172 [11:46<1:17:28, 29.80s/it]   Training Epoch: 5/12, completed (loss: 0.23711761832237244):   9%|[34mâ–‰         [0m| 16/172 [12:01<1:17:28, 29.80s/it]Training Epoch: 5/12, completed (loss: 0.23711761832237244):  10%|[34mâ–‰         [0m| 17/172 [12:16<1:16:38, 29.67s/it]Training Epoch: 5/12, completed (loss: 0.14485488831996918):  10%|[34mâ–‰         [0m| 17/172 [12:16<1:16:38, 29.67s/it]Training Epoch: 5/12, completed (loss: 0.12787742912769318):  10%|[34mâ–‰         [0m| 17/172 [12:30<1:16:38, 29.67s/it]Training Epoch: 5/12, completed (loss: 0.12787742912769318):  10%|[34mâ–ˆ         [0m| 18/172 [12:45<1:15:46, 29.52s/it]Training Epoch: 5/12, completed (loss: 0.20156331360340118):  10%|[34mâ–ˆ         [0m| 18/172 [12:45<1:15:46, 29.52s/it]Training Epoch: 5/12, completed (loss: 0.11013542115688324):  10%|[34mâ–ˆ         [0m| 18/172 [13:00<1:15:46, 29.52s/it]Training Epoch: 5/12, completed (loss: 0.11013542115688324):  11%|[34mâ–ˆ         [0m| 19/172 [13:14<1:15:08, 29.47s/it]Training Epoch: 5/12, completed (loss: 0.02824375405907631):  11%|[34mâ–ˆ         [0m| 19/172 [13:14<1:15:08, 29.47s/it]Training Epoch: 5/12, completed (loss: 0.25564849376678467):  11%|[34mâ–ˆ         [0m| 19/172 [13:29<1:15:08, 29.47s/it]Training Epoch: 5/12, completed (loss: 0.25564849376678467):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:43<1:14:26, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.010095033794641495):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:44<1:14:26, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.1047392338514328):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:58<1:14:26, 29.38s/it]  Training Epoch: 5/12, completed (loss: 0.1047392338514328):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:13<1:13:55, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.017347795888781548):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:13<1:13:55, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.042463019490242004):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:28<1:13:55, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.042463019490242004):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:42<1:13:29, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.25551727414131165):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:42<1:13:29, 29.40s/it] Training Epoch: 5/12, completed (loss: 0.2514672577381134):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:57<1:13:29, 29.40s/it] Training Epoch: 5/12, completed (loss: 0.2514672577381134):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:12<1:13:04, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.0489322803914547):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:12<1:13:04, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.2608562707901001):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:27<1:13:04, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.2608562707901001):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:41<1:12:35, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.30103951692581177):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:41<1:12:35, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.02627561427652836):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:56<1:12:35, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.02627561427652836):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:10<1:12:02, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.0022089513950049877):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:11<1:12:02, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.13261905312538147):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:25<1:12:02, 29.41s/it]  Training Epoch: 5/12, completed (loss: 0.13261905312538147):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:40<1:11:30, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.1953164041042328):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:40<1:11:30, 29.39s/it] Training Epoch: 5/12, completed (loss: 0.10406993329524994):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:55<1:11:30, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.10406993329524994):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:09<1:10:57, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.08266036212444305):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:09<1:10:57, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.11785998195409775):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:24<1:10:57, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.11785998195409775):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:38<1:10:25, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.0015447905752807856):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:39<1:10:25, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.33477088809013367):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:53<1:10:25, 29.34s/it]  Training Epoch: 5/12, completed (loss: 0.33477088809013367):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:08<1:09:53, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.0963892862200737):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:08<1:09:53, 29.32s/it] Training Epoch: 5/12, completed (loss: 0.20344753563404083):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:22<1:09:53, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.20344753563404083):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:37<1:09:20, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.3537847399711609):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:37<1:09:20, 29.30s/it] Training Epoch: 5/12, completed (loss: 0.0039378805086016655):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:52<1:09:20, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.0039378805086016655):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:06<1:08:53, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.023565033450722694):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:06<1:08:53, 29.31s/it] Training Epoch: 5/12, completed (loss: 0.11478320509195328):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:21<1:08:53, 29.31s/it] Training Epoch: 5/12, completed (loss: 0.11478320509195328):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:36<1:08:29, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.04784693196415901):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:36<1:08:29, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.12918560206890106):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:50<1:08:29, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.12918560206890106):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:05<1:07:58, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.13250792026519775):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:05<1:07:58, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.19244801998138428):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:20<1:07:58, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.19244801998138428):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:34<1:07:32, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.1574096828699112):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:35<1:07:32, 29.37s/it] Training Epoch: 5/12, completed (loss: 0.07651485502719879):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:49<1:07:32, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.07651485502719879):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:04<1:07:03, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.008192024193704128):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:04<1:07:03, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.10884810239076614):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:19<1:07:03, 29.37s/it] Training Epoch: 5/12, completed (loss: 0.10884810239076614):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:33<1:06:36, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.056472551077604294):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:33<1:06:36, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.10935627669095993):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:48<1:06:36, 29.38s/it] Training Epoch: 5/12, completed (loss: 0.10935627669095993):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:02<1:06:03, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.012049657292664051):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:03<1:06:03, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.08843311667442322):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:17<1:06:03, 29.36s/it] Training Epoch: 5/12, completed (loss: 0.08843311667442322):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:32<1:05:24, 29.29s/it]Training Epoch: 5/12, completed (loss: 7.271426511579193e-06):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:32<1:05:24, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.371379554271698):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:47<1:05:24, 29.29s/it]    Training Epoch: 5/12, completed (loss: 0.371379554271698):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:01<1:04:53, 29.28s/it]Training Epoch: 5/12, completed (loss: 0.042257193475961685):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:01<1:04:53, 29.28s/it]Training Epoch: 5/12, completed (loss: 0.1878546178340912):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:16<1:04:53, 29.28s/it]  Training Epoch: 5/12, completed (loss: 0.1878546178340912):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:30<1:04:21, 29.26s/it]Training Epoch: 5/12, completed (loss: 0.11875397711992264):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:30<1:04:21, 29.26s/it]Training Epoch: 5/12, completed (loss: 0.09253953397274017):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:45<1:04:21, 29.26s/it]Training Epoch: 5/12, completed (loss: 0.09253953397274017):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:00<1:03:59, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.08296918869018555):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:00<1:03:59, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.0003858865238726139):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:14<1:03:59, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.0003858865238726139):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:29<1:03:35, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.0946010872721672):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:29<1:03:35, 29.35s/it]   Training Epoch: 5/12, completed (loss: 0.03556838259100914):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:44<1:03:35, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.03556838259100914):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:58<1:03:08, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.03862769529223442):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:59<1:03:08, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.26678192615509033):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:13<1:03:08, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.26678192615509033):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:28<1:02:38, 29.37s/it] eval_ppl=tensor(1.8618, device='cuda:0') eval_epoch_loss=tensor(0.6215, device='cuda:0')
Eval epoch loss:  tensor(0.6215, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_5_1
Time while saving:  2023-10-26 00:16:21 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 5, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:54,  8.08s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:43,  7.98s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.88s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.86s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.89s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.89s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.91s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:30,  7.94s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.91s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:15,  7.96s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.96s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:58,  7.93s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.92s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.90s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.91s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.90s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.91s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.92s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.89s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.87s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.89s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.91s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.87s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.91s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.95s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it]
Training Epoch: 5/12, completed (loss: 0.14491620659828186):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:26<1:02:38, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.10538281500339508):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:40<1:02:38, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.10538281500339508):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:55<3:32:56, 100.60s/it]Training Epoch: 5/12, completed (loss: 0.0007415309082716703):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:55<3:32:56, 100.60s/it]Training Epoch: 5/12, completed (loss: 0.29580992460250854):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [30:09<3:32:56, 100.60s/it]  Training Epoch: 5/12, completed (loss: 0.29580992460250854):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:24<2:46:11, 79.14s/it] Training Epoch: 5/12, completed (loss: 0.009745324030518532):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:24<2:46:11, 79.14s/it]Training Epoch: 5/12, completed (loss: 0.05045272409915924):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:38<2:46:11, 79.14s/it] Training Epoch: 5/12, completed (loss: 0.05045272409915924):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:53<2:13:47, 64.22s/it]Training Epoch: 5/12, completed (loss: 0.12602315843105316):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:53<2:13:47, 64.22s/it]Training Epoch: 5/12, completed (loss: 0.2804366648197174):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [31:08<2:13:47, 64.22s/it] Training Epoch: 5/12, completed (loss: 0.2804366648197174):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:22<1:51:02, 53.73s/it]Training Epoch: 5/12, completed (loss: 0.04040513560175896):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:22<1:51:02, 53.73s/it]Training Epoch: 5/12, completed (loss: 0.018590768799185753):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:37<1:51:02, 53.73s/it]Training Epoch: 5/12, completed (loss: 0.018590768799185753):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:52<1:35:10, 46.42s/it]Training Epoch: 5/12, completed (loss: 0.0006985356449149549):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:52<1:35:10, 46.42s/it]Training Epoch: 5/12, completed (loss: 0.3412526845932007):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [32:07<1:35:10, 46.42s/it]   Training Epoch: 5/12, completed (loss: 0.3412526845932007):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:21<1:23:58, 41.30s/it]Training Epoch: 5/12, completed (loss: 0.12737853825092316):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:21<1:23:58, 41.30s/it]Training Epoch: 5/12, completed (loss: 0.23445278406143188):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:36<1:23:58, 41.30s/it]Training Epoch: 5/12, completed (loss: 0.23445278406143188):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:50<1:16:00, 37.69s/it]Training Epoch: 5/12, completed (loss: 0.0062724570743739605):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:50<1:16:00, 37.69s/it]Training Epoch: 5/12, completed (loss: 0.18154531717300415):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [33:05<1:16:00, 37.69s/it]  Training Epoch: 5/12, completed (loss: 0.18154531717300415):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:20<1:10:29, 35.25s/it]Training Epoch: 5/12, completed (loss: 0.025975437834858894):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:20<1:10:29, 35.25s/it]Training Epoch: 5/12, completed (loss: 0.407641738653183):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:35<1:10:29, 35.25s/it]   Training Epoch: 5/12, completed (loss: 0.407641738653183):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:49<1:06:24, 33.48s/it]Training Epoch: 5/12, completed (loss: 0.022523147985339165):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:49<1:06:24, 33.48s/it]Training Epoch: 5/12, completed (loss: 0.023697568103671074):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [34:04<1:06:24, 33.48s/it]Training Epoch: 5/12, completed (loss: 0.023697568103671074):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:18<1:03:20, 32.21s/it]Training Epoch: 5/12, completed (loss: 0.07794544100761414):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:19<1:03:20, 32.21s/it] Training Epoch: 5/12, completed (loss: 0.09889713674783707):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:33<1:03:20, 32.21s/it]Training Epoch: 5/12, completed (loss: 0.09889713674783707):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:48<1:01:06, 31.34s/it]Training Epoch: 5/12, completed (loss: 0.02010333351790905):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:48<1:01:06, 31.34s/it]Training Epoch: 5/12, completed (loss: 0.01872539333999157):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [35:03<1:01:06, 31.34s/it]Training Epoch: 5/12, completed (loss: 0.01872539333999157):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:17<59:26, 30.75s/it]  Training Epoch: 5/12, completed (loss: 0.1360880583524704):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:17<59:26, 30.75s/it] Training Epoch: 5/12, completed (loss: 0.26179176568984985):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:32<59:26, 30.75s/it]Training Epoch: 5/12, completed (loss: 0.26179176568984985):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:47<58:11, 30.36s/it]Training Epoch: 5/12, completed (loss: 0.1929876059293747):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:47<58:11, 30.36s/it] Training Epoch: 5/12, completed (loss: 2.6064364647027105e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [36:02<58:11, 30.36s/it]Training Epoch: 5/12, completed (loss: 2.6064364647027105e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:16<57:10, 30.10s/it]Training Epoch: 5/12, completed (loss: 0.2254457026720047):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:16<57:10, 30.10s/it]    Training Epoch: 5/12, completed (loss: 0.27255362272262573):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:31<57:10, 30.10s/it]Training Epoch: 5/12, completed (loss: 0.27255362272262573):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:46<56:23, 29.95s/it]Training Epoch: 5/12, completed (loss: 0.09518779069185257):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:46<56:23, 29.95s/it]Training Epoch: 5/12, completed (loss: 0.036191675812006):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [37:00<56:23, 29.95s/it]  Training Epoch: 5/12, completed (loss: 0.036191675812006):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:15<55:30, 29.73s/it]Training Epoch: 5/12, completed (loss: 0.0530070886015892):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:15<55:30, 29.73s/it]Training Epoch: 5/12, completed (loss: 0.1665264517068863):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:30<55:30, 29.73s/it]Training Epoch: 5/12, completed (loss: 0.1665264517068863):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:44<54:50, 29.64s/it]Training Epoch: 5/12, completed (loss: 0.06530539691448212):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:44<54:50, 29.64s/it]Training Epoch: 5/12, completed (loss: 1.2508953659562394e-05):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:59<54:50, 29.64s/it]Training Epoch: 5/12, completed (loss: 1.2508953659562394e-05):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:14<54:14, 29.58s/it]Training Epoch: 5/12, completed (loss: 0.32836610078811646):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:14<54:14, 29.58s/it]   Training Epoch: 5/12, completed (loss: 0.41304147243499756):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:29<54:14, 29.58s/it]Training Epoch: 5/12, completed (loss: 0.41304147243499756):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:43<53:33, 29.48s/it]Training Epoch: 5/12, completed (loss: 0.4455724358558655):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:43<53:33, 29.48s/it] Training Epoch: 5/12, completed (loss: 0.028381673619151115):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:58<53:33, 29.48s/it]Training Epoch: 5/12, completed (loss: 0.028381673619151115):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:12<53:01, 29.45s/it]Training Epoch: 5/12, completed (loss: 0.1179366335272789):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:13<53:01, 29.45s/it]  Training Epoch: 5/12, completed (loss: 0.13445571064949036):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:27<53:01, 29.45s/it]Training Epoch: 5/12, completed (loss: 0.13445571064949036):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:42<52:27, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.04930393397808075):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:42<52:27, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.1791844666004181):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:57<52:27, 29.41s/it] Training Epoch: 5/12, completed (loss: 0.1791844666004181):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:11<51:53, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.06474769860506058):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:11<51:53, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.0749417170882225):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:26<51:53, 29.37s/it] Training Epoch: 5/12, completed (loss: 0.0749417170882225):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:40<51:23, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.01804381050169468):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:41<51:23, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.010155193507671356):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:55<51:23, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.010155193507671356):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:10<50:50, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.07568379491567612):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:10<50:50, 29.33s/it] Training Epoch: 5/12, completed (loss: 0.14832699298858643):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:24<50:50, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.14832699298858643):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:39<50:16, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.0009257376077584922):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:39<50:16, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.11154594272375107):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:54<50:16, 29.29s/it]  Training Epoch: 5/12, completed (loss: 0.11154594272375107):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:08<49:50, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.31589943170547485):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:08<49:50, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.2092926949262619):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:23<49:50, 29.32s/it] Training Epoch: 5/12, completed (loss: 0.2092926949262619):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:38<49:22, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.19170774519443512):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:38<49:22, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.04810009151697159):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:52<49:22, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.04810009151697159):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:07<48:50, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.039582591503858566):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:07<48:50, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.36788228154182434):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:22<48:50, 29.30s/it] Training Epoch: 5/12, completed (loss: 0.36788228154182434):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:36<48:23, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.01191588956862688):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:36<48:23, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.1766049861907959):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:51<48:23, 29.33s/it] Training Epoch: 5/12, completed (loss: 0.1766049861907959):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:05<47:51, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.18011260032653809):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:06<47:51, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.20040220022201538):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:20<47:51, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.20040220022201538):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:35<47:23, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.04136135056614876):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:35<47:23, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.0071678380481898785):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:50<47:23, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.0071678380481898785):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:04<46:53, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.10545475035905838):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:04<46:53, 29.31s/it]  Training Epoch: 5/12, completed (loss: 0.03660137206315994):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:19<46:53, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.03660137206315994):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:33<46:21, 29.28s/it]Training Epoch: 5/12, completed (loss: 0.2330557405948639):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:33<46:21, 29.28s/it] Training Epoch: 5/12, completed (loss: 0.006382132414728403):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:48<46:21, 29.28s/it]Training Epoch: 5/12, completed (loss: 0.006382132414728403):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:03<45:52, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.0991961732506752):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:03<45:52, 29.29s/it]  Training Epoch: 5/12, completed (loss: 0.07796566188335419):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:17<45:52, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.07796566188335419):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:32<45:23, 29.28s/it]Training Epoch: 5/12, completed (loss: 0.19579599797725677):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:32<45:23, 29.28s/it]Training Epoch: 5/12, completed (loss: 0.15255749225616455):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:47<45:23, 29.28s/it]Training Epoch: 5/12, completed (loss: 0.15255749225616455):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:01<44:49, 29.23s/it]Training Epoch: 5/12, completed (loss: 0.050284404307603836):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:01<44:49, 29.23s/it]Training Epoch: 5/12, completed (loss: 0.25512588024139404):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:16<44:49, 29.23s/it] Training Epoch: 5/12, completed (loss: 0.25512588024139404):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:30<44:23, 29.27s/it]Training Epoch: 5/12, completed (loss: 0.024051742628216743):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:30<44:23, 29.27s/it]Training Epoch: 5/12, completed (loss: 0.12374642491340637):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:45<44:23, 29.27s/it] Training Epoch: 5/12, completed (loss: 0.12374642491340637):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:00<43:55, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.10527824610471725):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:00<43:55, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.25186434388160706):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:14<43:55, 29.29s/it]Training Epoch: 5/12, completed (loss: 0.25186434388160706):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:29<43:28, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.18053174018859863):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:29<43:28, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.12971584498882294):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:44<43:28, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.12971584498882294):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:58<43:00, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.2981671392917633):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:58<43:00, 29.32s/it] Training Epoch: 5/12, completed (loss: 0.07503310590982437):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [49:13<43:00, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.07503310590982437):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:28<42:31, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.3746733069419861):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:28<42:31, 29.33s/it] Training Epoch: 5/12, completed (loss: 0.23752710223197937):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:43<42:31, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.23752710223197937):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:57<42:02, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.20187000930309296):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:57<42:02, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.26393717527389526):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [50:12<42:02, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.26393717527389526):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [50:26<41:31, 29.31s/it] eval_ppl=tensor(2.1166, device='cuda:0') eval_epoch_loss=tensor(0.7498, device='cuda:0')
Eval epoch loss:  tensor(0.7498, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_5_87
Time while saving:  2023-10-26 00:41:19 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 5, step_id: 173

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:51,  7.97s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.93s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.89s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.87s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:08,  7.86s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.88s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.91s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.89s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:37,  7.89s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.92s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.92s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.96s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.96s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.97s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.92s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.93s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.93s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.93s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.89s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.92s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.94s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.92s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.93s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.97s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.95s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it]
Training Epoch: 5/12, completed (loss: 0.07315120100975037):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:24<41:31, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.00914845522493124):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:39<41:31, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.00914845522493124):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:53<2:20:54, 100.65s/it]Training Epoch: 5/12, completed (loss: 0.08683398365974426):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:54<2:20:54, 100.65s/it]Training Epoch: 5/12, completed (loss: 0.1861373782157898):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [55:08<2:20:54, 100.65s/it] Training Epoch: 5/12, completed (loss: 0.1861373782157898):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:23<1:49:37, 79.25s/it] Training Epoch: 5/12, completed (loss: 0.027451563626527786):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:23<1:49:37, 79.25s/it]Training Epoch: 5/12, completed (loss: 0.08221233636140823):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:38<1:49:37, 79.25s/it] Training Epoch: 5/12, completed (loss: 0.08221233636140823):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:52<1:27:51, 64.29s/it]Training Epoch: 5/12, completed (loss: 0.43114161491394043):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:52<1:27:51, 64.29s/it]Training Epoch: 5/12, completed (loss: 0.04457476735115051):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [56:07<1:27:51, 64.29s/it]Training Epoch: 5/12, completed (loss: 0.04457476735115051):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:22<1:12:42, 53.86s/it]Training Epoch: 5/12, completed (loss: 0.15711547434329987):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:22<1:12:42, 53.86s/it]Training Epoch: 5/12, completed (loss: 0.12268433719873428):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:37<1:12:42, 53.86s/it]Training Epoch: 5/12, completed (loss: 0.12268433719873428):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:51<1:02:02, 46.53s/it]Training Epoch: 5/12, completed (loss: 0.13471576571464539):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:51<1:02:02, 46.53s/it]Training Epoch: 5/12, completed (loss: 0.010336925275623798):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [57:06<1:02:02, 46.53s/it]Training Epoch: 5/12, completed (loss: 0.010336925275623798):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:21<54:34, 41.45s/it]  Training Epoch: 5/12, completed (loss: 0.2532144784927368):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:21<54:34, 41.45s/it]  Training Epoch: 5/12, completed (loss: 0.14055867493152618):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:35<54:34, 41.45s/it]Training Epoch: 5/12, completed (loss: 0.14055867493152618):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:50<49:12, 37.85s/it]Training Epoch: 5/12, completed (loss: 0.15097887814044952):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:50<49:12, 37.85s/it]Training Epoch: 5/12, completed (loss: 0.39728647470474243):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [58:05<49:12, 37.85s/it]Training Epoch: 5/12, completed (loss: 0.39728647470474243):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:19<45:19, 35.31s/it]Training Epoch: 5/12, completed (loss: 0.011242848820984364):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:20<45:19, 35.31s/it]Training Epoch: 5/12, completed (loss: 0.020872194319963455):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:34<45:19, 35.31s/it]Training Epoch: 5/12, completed (loss: 0.020872194319963455):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:49<42:33, 33.60s/it]Training Epoch: 5/12, completed (loss: 0.1416429877281189):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:49<42:33, 33.60s/it]  Training Epoch: 5/12, completed (loss: 0.20830151438713074):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [59:04<42:33, 33.60s/it]Training Epoch: 5/12, completed (loss: 0.20830151438713074):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:18<40:25, 32.33s/it]Training Epoch: 5/12, completed (loss: 0.02584812417626381):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:19<40:25, 32.33s/it]Training Epoch: 5/12, completed (loss: 0.17054080963134766):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:33<40:25, 32.33s/it]Training Epoch: 5/12, completed (loss: 0.17054080963134766):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:48<38:44, 31.41s/it]Training Epoch: 5/12, completed (loss: 0.0604792982339859):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:48<38:44, 31.41s/it] Training Epoch: 5/12, completed (loss: 0.2592339813709259):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [1:00:03<38:44, 31.41s/it]Training Epoch: 5/12, completed (loss: 0.2592339813709259):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:17<37:29, 30.81s/it]Training Epoch: 5/12, completed (loss: 0.03695526719093323):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:17<37:29, 30.81s/it]Training Epoch: 5/12, completed (loss: 0.08153370022773743):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:32<37:29, 30.81s/it]Training Epoch: 5/12, completed (loss: 0.08153370022773743):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:46<36:24, 30.33s/it]Training Epoch: 5/12, completed (loss: 0.001971667166799307):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:46<36:24, 30.33s/it]Training Epoch: 5/12, completed (loss: 4.929371425532736e-05):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:01:01<36:24, 30.33s/it]Training Epoch: 5/12, completed (loss: 4.929371425532736e-05):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:16<35:30, 30.01s/it]Training Epoch: 5/12, completed (loss: 0.08542126417160034):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:16<35:30, 30.01s/it]  Training Epoch: 5/12, completed (loss: 0.03439256176352501):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:30<35:30, 30.01s/it]Training Epoch: 5/12, completed (loss: 0.03439256176352501):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:45<34:46, 29.80s/it]Training Epoch: 5/12, completed (loss: 0.08862122893333435):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:45<34:46, 29.80s/it]Training Epoch: 5/12, completed (loss: 0.12759459018707275):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:02:00<34:46, 29.80s/it]Training Epoch: 5/12, completed (loss: 0.12759459018707275):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:14<34:06, 29.66s/it]Training Epoch: 5/12, completed (loss: 0.031485456973314285):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:14<34:06, 29.66s/it]Training Epoch: 5/12, completed (loss: 0.04593263566493988):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:29<34:06, 29.66s/it] Training Epoch: 5/12, completed (loss: 0.04593263566493988):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:43<33:29, 29.55s/it]Training Epoch: 5/12, completed (loss: 0.2452639937400818):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:44<33:29, 29.55s/it] Training Epoch: 5/12, completed (loss: 0.1899595856666565):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:58<33:29, 29.55s/it]Training Epoch: 5/12, completed (loss: 0.1899595856666565):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:13<32:58, 29.53s/it]Training Epoch: 5/12, completed (loss: 0.1470041573047638):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:13<32:58, 29.53s/it]Training Epoch: 5/12, completed (loss: 0.006440968252718449):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:28<32:58, 29.53s/it]Training Epoch: 5/12, completed (loss: 0.006440968252718449):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:42<32:25, 29.48s/it]Training Epoch: 5/12, completed (loss: 0.1286923885345459):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:43<32:25, 29.48s/it]  Training Epoch: 5/12, completed (loss: 0.0428713858127594):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:57<32:25, 29.48s/it]Training Epoch: 5/12, completed (loss: 0.0428713858127594):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:12<31:51, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.16639234125614166):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:12<31:51, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.07983026653528214):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:26<31:51, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.07983026653528214):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:41<31:21, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.07194115221500397):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:41<31:21, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.10274740308523178):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:56<31:21, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.10274740308523178):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:10<30:50, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.05370767042040825):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:10<30:50, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.09669081121683121):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:25<30:50, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.09669081121683121):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:40<30:18, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.0014587708283215761):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:40<30:18, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.09811385720968246):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:54<30:18, 29.34s/it]  Training Epoch: 5/12, completed (loss: 0.09811385720968246):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:09<29:49, 29.33s/it]Training Epoch: 5/12, completed (loss: 7.998170985956676e-06):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:09<29:49, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.1659211963415146):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:24<29:49, 29.33s/it]   Training Epoch: 5/12, completed (loss: 0.1659211963415146):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:38<29:19, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.2778993546962738):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:38<29:19, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.13367000222206116):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:53<29:19, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.13367000222206116):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:07<28:50, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.028397027403116226):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:08<28:50, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.3886015713214874):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:22<28:50, 29.33s/it]  Training Epoch: 5/12, completed (loss: 0.3886015713214874):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:37<28:20, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.001258596545085311):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:37<28:20, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.09518293291330338):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:52<28:20, 29.32s/it] Training Epoch: 5/12, completed (loss: 0.09518293291330338):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:06<27:53, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.20449306070804596):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:06<27:53, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.17154629528522491):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:21<27:53, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.17154629528522491):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:36<27:24, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.2515478730201721):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:36<27:24, 29.37s/it] Training Epoch: 5/12, completed (loss: 0.2767336666584015):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:51<27:24, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.2767336666584015):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:05<26:55, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.03051375411450863):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:05<26:55, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.17741012573242188):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:20<26:55, 29.37s/it]Training Epoch: 5/12, completed (loss: 0.17741012573242188):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:34<26:26, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.14420123398303986):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:35<26:26, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.13628754019737244):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:49<26:26, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.13628754019737244):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:04<25:55, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.20528331398963928):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:04<25:55, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.14128601551055908):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:19<25:55, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.14128601551055908):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:33<25:26, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.13591593503952026):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:33<25:26, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.23898877203464508):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:48<25:26, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.23898877203464508):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:03<25:01, 29.44s/it]Training Epoch: 5/12, completed (loss: 0.060917891561985016):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:03<25:01, 29.44s/it]Training Epoch: 5/12, completed (loss: 0.2935384511947632):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:18<25:01, 29.44s/it]  Training Epoch: 5/12, completed (loss: 0.2935384511947632):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:32<24:30, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.005756503902375698):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:32<24:30, 29.41s/it]Training Epoch: 5/12, completed (loss: 0.3015337288379669):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:47<24:30, 29.41s/it]  Training Epoch: 5/12, completed (loss: 0.3015337288379669):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:01<24:01, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.15365464985370636):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:02<24:01, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.19047199189662933):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:16<24:01, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.19047199189662933):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:31<23:32, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.02125186286866665):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:31<23:32, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.0010397826554253697):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:46<23:32, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.0010397826554253697):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:00<22:58, 29.34s/it]Training Epoch: 5/12, completed (loss: 4.077344783581793e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:00<22:58, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.11947501450777054):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:15<22:58, 29.34s/it]  Training Epoch: 5/12, completed (loss: 0.11947501450777054):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:29<22:29, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.00042298485641367733):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:30<22:29, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.08114992827177048):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:44<22:29, 29.35s/it]   Training Epoch: 5/12, completed (loss: 0.08114992827177048):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:59<21:58, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.3429126739501953):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:13:59<21:58, 29.31s/it] Training Epoch: 5/12, completed (loss: 0.08700703084468842):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:14:14<21:58, 29.31s/it]Training Epoch: 5/12, completed (loss: 0.08700703084468842):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:28<21:31, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.10089698433876038):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:28<21:31, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.01403846126049757):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:43<21:31, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.01403846126049757):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:14:57<21:01, 29.35s/it] eval_ppl=tensor(2.0013, device='cuda:0') eval_epoch_loss=tensor(0.6938, device='cuda:0')
Eval epoch loss:  tensor(0.6938, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_5_173
Time while saving:  2023-10-26 01:06:18 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 5, step_id: 257

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:48,  7.89s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:39,  7.85s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:31,  7.83s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.83s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.89s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.91s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.92s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:31,  7.95s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.93s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.96s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.98s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.95s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.93s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.92s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.94s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.96s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.91s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.91s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.92s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.94s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.94s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.91s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.91s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.95s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.95s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it]
Training Epoch: 5/12, completed (loss: 0.2964482605457306):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:56<21:01, 29.35s/it] Training Epoch: 5/12, completed (loss: 0.07193449884653091):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:19:10<21:01, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.07193449884653091):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:24<1:10:27, 100.66s/it]Training Epoch: 5/12, completed (loss: 0.01832440122961998):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:25<1:10:27, 100.66s/it]Training Epoch: 5/12, completed (loss: 0.06083398684859276):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:39<1:10:27, 100.66s/it]Training Epoch: 5/12, completed (loss: 0.06083398684859276):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:54<54:09, 79.25s/it]   Training Epoch: 5/12, completed (loss: 0.011924488469958305):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:54<54:09, 79.25s/it]Training Epoch: 5/12, completed (loss: 6.79611912346445e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:20:09<54:09, 79.25s/it]Training Epoch: 5/12, completed (loss: 6.79611912346445e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:23<42:49, 64.23s/it]Training Epoch: 5/12, completed (loss: 0.03689286485314369):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:23<42:49, 64.23s/it] Training Epoch: 5/12, completed (loss: 0.09176243841648102):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:38<42:49, 64.23s/it]Training Epoch: 5/12, completed (loss: 0.09176243841648102):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:52<34:56, 53.76s/it]Training Epoch: 5/12, completed (loss: 0.03133432939648628):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:52<34:56, 53.76s/it]Training Epoch: 5/12, completed (loss: 0.1982191503047943):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:21:07<34:56, 53.76s/it] Training Epoch: 5/12, completed (loss: 0.1982191503047943):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:22<29:26, 46.48s/it]Training Epoch: 5/12, completed (loss: 0.3227168619632721):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:22<29:26, 46.48s/it]Training Epoch: 5/12, completed (loss: 0.03845261037349701):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:37<29:26, 46.48s/it]Training Epoch: 5/12, completed (loss: 0.03845261037349701):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:51<25:29, 41.33s/it]Training Epoch: 5/12, completed (loss: 0.05761583149433136):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:51<25:29, 41.33s/it]Training Epoch: 5/12, completed (loss: 0.057574186474084854):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:22:06<25:29, 41.33s/it]Training Epoch: 5/12, completed (loss: 0.057574186474084854):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:20<22:38, 37.74s/it]Training Epoch: 5/12, completed (loss: 0.18960638344287872):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:21<22:38, 37.74s/it] Training Epoch: 5/12, completed (loss: 0.0814892128109932):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:35<22:38, 37.74s/it] Training Epoch: 5/12, completed (loss: 0.0814892128109932):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:50<20:33, 35.24s/it]Training Epoch: 5/12, completed (loss: 0.008064872585237026):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:50<20:33, 35.24s/it]Training Epoch: 5/12, completed (loss: 0.010247891768813133):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:23:05<20:33, 35.24s/it]Training Epoch: 5/12, completed (loss: 0.010247891768813133):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:19<18:58, 33.48s/it]Training Epoch: 5/12, completed (loss: 0.015160739421844482):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:19<18:58, 33.48s/it]Training Epoch: 5/12, completed (loss: 0.14450868964195251):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:34<18:58, 33.48s/it] Training Epoch: 5/12, completed (loss: 0.14450868964195251):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:48<17:42, 32.21s/it]Training Epoch: 5/12, completed (loss: 0.0020465718116611242):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:49<17:42, 32.21s/it]Training Epoch: 5/12, completed (loss: 0.2015824168920517):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:24:03<17:42, 32.21s/it]   Training Epoch: 5/12, completed (loss: 0.2015824168920517):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:18<16:43, 31.37s/it]Training Epoch: 5/12, completed (loss: 0.19846493005752563):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:18<16:43, 31.37s/it]Training Epoch: 5/12, completed (loss: 0.0571216382086277):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:33<16:43, 31.37s/it] Training Epoch: 5/12, completed (loss: 0.0571216382086277):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:47<15:55, 30.82s/it]Training Epoch: 5/12, completed (loss: 3.4330907510593534e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:48<15:55, 30.82s/it]Training Epoch: 5/12, completed (loss: 4.2208303057122976e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:25:02<15:55, 30.82s/it]Training Epoch: 5/12, completed (loss: 4.2208303057122976e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:17<15:10, 30.35s/it]Training Epoch: 5/12, completed (loss: 0.2098148912191391):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:17<15:10, 30.35s/it]    Training Epoch: 5/12, completed (loss: 0.21865147352218628):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:32<15:10, 30.35s/it]Training Epoch: 5/12, completed (loss: 0.21865147352218628):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:46<14:31, 30.05s/it]Training Epoch: 5/12, completed (loss: 0.1959746778011322):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:46<14:31, 30.05s/it] Training Epoch: 5/12, completed (loss: 0.0500592403113842):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:26:01<14:31, 30.05s/it]Training Epoch: 5/12, completed (loss: 0.0500592403113842):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:15<13:55, 29.83s/it]Training Epoch: 5/12, completed (loss: 0.3119589388370514):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:16<13:55, 29.83s/it]Training Epoch: 5/12, completed (loss: 0.0908828005194664):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:30<13:55, 29.83s/it]Training Epoch: 5/12, completed (loss: 0.0908828005194664):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:45<13:20, 29.64s/it]Training Epoch: 5/12, completed (loss: 0.03645120561122894):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:45<13:20, 29.64s/it]Training Epoch: 5/12, completed (loss: 0.036163412034511566):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:59<13:20, 29.64s/it]Training Epoch: 5/12, completed (loss: 0.036163412034511566):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:14<12:48, 29.56s/it]Training Epoch: 5/12, completed (loss: 0.08858111500740051):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:14<12:48, 29.56s/it] Training Epoch: 5/12, completed (loss: 0.03411068394780159):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:29<12:48, 29.56s/it]Training Epoch: 5/12, completed (loss: 0.03411068394780159):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:43<12:17, 29.51s/it]Training Epoch: 5/12, completed (loss: 0.20453956723213196):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:43<12:17, 29.51s/it]Training Epoch: 5/12, completed (loss: 0.05105356499552727):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:58<12:17, 29.51s/it]Training Epoch: 5/12, completed (loss: 0.05105356499552727):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:13<11:47, 29.48s/it]Training Epoch: 5/12, completed (loss: 0.003032244509086013):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:13<11:47, 29.48s/it]Training Epoch: 5/12, completed (loss: 0.011994821950793266):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:27<11:47, 29.48s/it]Training Epoch: 5/12, completed (loss: 0.011994821950793266):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:42<11:17, 29.46s/it]Training Epoch: 5/12, completed (loss: 0.13491594791412354):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:42<11:17, 29.46s/it] Training Epoch: 5/12, completed (loss: 0.17023023962974548):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:57<11:17, 29.46s/it]Training Epoch: 5/12, completed (loss: 0.17023023962974548):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:11<10:47, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.10354629158973694):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:12<10:47, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.22209809720516205):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:26<10:47, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.22209809720516205):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:41<10:18, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.25252416729927063):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:41<10:18, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.17643356323242188):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:56<10:18, 29.43s/it]Training Epoch: 5/12, completed (loss: 0.17643356323242188):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:10<09:48, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.19760586321353912):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:10<09:48, 29.42s/it]Training Epoch: 5/12, completed (loss: 0.2780503034591675):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:25<09:48, 29.42s/it] Training Epoch: 5/12, completed (loss: 0.2780503034591675):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:40<09:18, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.22120554745197296):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:40<09:18, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.31552809476852417):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:54<09:18, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.31552809476852417):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:09<08:48, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.1555357128381729):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:09<08:48, 29.39s/it] Training Epoch: 5/12, completed (loss: 0.1180022805929184):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:24<08:48, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.1180022805929184):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:38<08:19, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.11164829134941101):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:39<08:19, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.01930438168346882):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:53<08:19, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.01930438168346882):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:08<07:49, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.17022591829299927):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:08<07:49, 29.35s/it]Training Epoch: 5/12, completed (loss: 0.1515098661184311):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:23<07:49, 29.35s/it] Training Epoch: 5/12, completed (loss: 0.1515098661184311):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:37<07:20, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.19391918182373047):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:37<07:20, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.2963416576385498):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:52<07:20, 29.34s/it] Training Epoch: 5/12, completed (loss: 0.2963416576385498):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:06<06:50, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.001304088975302875):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:06<06:50, 29.32s/it]Training Epoch: 5/12, completed (loss: 0.15233251452445984):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:21<06:50, 29.32s/it] Training Epoch: 5/12, completed (loss: 0.15233251452445984):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:36<06:22, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.10269873589277267):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:36<06:22, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.21567252278327942):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:51<06:22, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.21567252278327942):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:05<05:52, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.051253508776426315):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:05<05:52, 29.39s/it]Training Epoch: 5/12, completed (loss: 0.24288029968738556):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:20<05:52, 29.39s/it] Training Epoch: 5/12, completed (loss: 0.24288029968738556):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:35<05:23, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.07943287491798401):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:35<05:23, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.020862966775894165):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:49<05:23, 29.40s/it]Training Epoch: 5/12, completed (loss: 0.020862966775894165):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:04<04:53, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.11361321061849594):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:04<04:53, 29.36s/it] Training Epoch: 5/12, completed (loss: 0.027750186622142792):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:19<04:53, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.027750186622142792):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:33<04:24, 29.36s/it]Training Epoch: 5/12, completed (loss: 0.12189988046884537):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:33<04:24, 29.36s/it] Training Epoch: 5/12, completed (loss: 0.2650427222251892):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:48<04:24, 29.36s/it] Training Epoch: 5/12, completed (loss: 0.2650427222251892):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:02<03:54, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.12384676188230515):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:03<03:54, 29.33s/it]Training Epoch: 5/12, completed (loss: 0.3276478350162506):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:17<03:54, 29.33s/it] Training Epoch: 5/12, completed (loss: 0.3276478350162506):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:32<03:25, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.27385589480400085):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:32<03:25, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.1282501518726349):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:47<03:25, 29.38s/it] Training Epoch: 5/12, completed (loss: 0.1282501518726349):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:01<02:56, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.2540780007839203):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:02<02:56, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.11760083585977554):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:16<02:56, 29.38s/it]Training Epoch: 5/12, completed (loss: 0.11760083585977554):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:31<02:26, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.028731904923915863):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:31<02:26, 29.34s/it]Training Epoch: 5/12, completed (loss: 0.12655606865882874):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:45<02:26, 29.34s/it] Training Epoch: 5/12, completed (loss: 0.12655606865882874):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:00<01:57, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.25578969717025757):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:00<01:57, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.0006552920676767826):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:15<01:57, 29.30s/it]Training Epoch: 5/12, completed (loss: 0.0006552920676767826):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:29<01:27, 29.26s/it]Training Epoch: 5/12, completed (loss: 0.18206706643104553):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:29<01:27, 29.26s/it]  Training Epoch: 5/12, completed (loss: 0.006209808401763439):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:44<01:27, 29.26s/it]Training Epoch: 5/12, completed (loss: 0.006209808401763439):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:58<00:58, 29.21s/it]Training Epoch: 5/12, completed (loss: 0.06345246732234955):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:38:58<00:58, 29.21s/it] Training Epoch: 5/12, completed (loss: 0.17058701813220978):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:39:13<00:58, 29.21s/it]Training Epoch: 5/12, completed (loss: 0.17058701813220978):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:27<00:29, 29.25s/it]Training Epoch: 5/12, completed (loss: 0.1483338177204132):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:28<00:29, 29.25s/it] Training Epoch: 5/12, completed (loss: 0.15407542884349823):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:42<00:29, 29.25s/it]Training Epoch: 5/12, completed (loss: 0.15407542884349823): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:39:57<00:00, 29.27s/it] eval_ppl=tensor(2.0289, device='cuda:0') eval_epoch_loss=tensor(0.7075, device='cuda:0')
Eval epoch loss:  tensor(0.7075, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_5_257
Time while saving:  2023-10-26 01:30:49 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 5, step_id: 343

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:48,  7.87s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:39,  7.84s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:31,  7.84s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.81s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:18,  7.92s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.94s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.91s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.93s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.93s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.92s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:14,  7.93s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:06,  7.93s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.94s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:50,  7.92s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.90s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.88s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.89s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.91s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.91s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.90s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.90s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.89s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.89s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.89s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.95s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.91s/it]
Training Epoch: 5/12, completed (loss: 1.128022722696187e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:54<00:00, 29.27s/it]Training Epoch: 5/12, completed (loss: 1.128022722696187e-05): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:43:54<00:00, 36.25s/it]
 eval_ppl=tensor(2.0551, device='cuda:0') eval_epoch_loss=tensor(0.7203, device='cuda:0')
Eval epoch loss:  tensor(0.7203, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_5_343
Time while saving:  2023-10-26 01:55:48 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
Epoch ending time:  2023-10-26 01:55:48 IST+0530
Validation losses are: 
{'epoch_id': 0, 'ministep_id': 1, 'eval_epoch_loss': tensor(2.6360, device='cuda:0'), 'best_val_loss_yet': tensor(2.6360, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6698, device='cuda:0'), 'best_val_loss_yet': tensor(0.6698, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6023, device='cuda:0'), 'best_val_loss_yet': tensor(0.6023, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5568, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5643, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5634, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5644, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5524, device='cuda:0'), 'best_val_loss_yet': tensor(0.5524, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5513, device='cuda:0'), 'best_val_loss_yet': tensor(0.5513, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5386, device='cuda:0'), 'best_val_loss_yet': tensor(0.5386, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5370, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5769, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5758, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5729, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5558, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5550, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5881, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6249, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5809, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5733, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5711, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6770, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6490, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.6375, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.6272, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.6215, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.7498, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6938, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.7075, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.7203, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
$$$%%%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Epoch 5: train_perplexity=1.1347, train_epoch_loss=0.1263, epoch time 6235.15887735202s
Epoch starting time:  2023-10-26 01:55:49 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 6:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training Epoch: 6/12, completed (loss: 0.007484413217753172):   0%|[34m          [0m| 0/172 [00:14<?, ?it/s]Training Epoch: 6/12, completed (loss: 0.007484413217753172):   1%|[34m          [0m| 1/172 [00:29<1:23:18, 29.23s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 6, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:50,  7.95s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.91s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.87s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:23,  7.84s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.88s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.89s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.89s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.90s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:10<02:45,  7.89s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:26<02:30,  7.95s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.93s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.95s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.95s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:42,  7.91s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.92s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.91s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.92s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:10,  7.88s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:53<01:03,  7.89s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:01<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:09<00:47,  7.93s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:17<00:39,  7.92s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.90s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:33<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:41<00:15,  7.95s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.94s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it]
Training Epoch: 6/12, completed (loss: 0.07355549931526184):   1%|[34m          [0m| 1/172 [04:27<1:23:18, 29.23s/it] Training Epoch: 6/12, completed (loss: 0.030915873125195503):   1%|[34m          [0m| 1/172 [04:41<1:23:18, 29.23s/it]Training Epoch: 6/12, completed (loss: 0.030915873125195503):   1%|[34m          [0m| 2/172 [04:56<7:58:57, 169.04s/it]Training Epoch: 6/12, completed (loss: 0.13623350858688354):   1%|[34m          [0m| 2/172 [04:56<7:58:57, 169.04s/it] Training Epoch: 6/12, completed (loss: 0.07080616801977158):   1%|[34m          [0m| 2/172 [05:11<7:58:57, 169.04s/it]Training Epoch: 6/12, completed (loss: 0.07080616801977158):   2%|[34mâ–         [0m| 3/172 [05:25<4:56:34, 105.29s/it]Training Epoch: 6/12, completed (loss: 0.1407773494720459):   2%|[34mâ–         [0m| 3/172 [05:25<4:56:34, 105.29s/it] Training Epoch: 6/12, completed (loss: 0.18688665330410004):   2%|[34mâ–         [0m| 3/172 [05:40<4:56:34, 105.29s/it]Training Epoch: 6/12, completed (loss: 0.18688665330410004):   2%|[34mâ–         [0m| 4/172 [05:54<3:30:39, 75.23s/it] Training Epoch: 6/12, completed (loss: 0.027028555050492287):   2%|[34mâ–         [0m| 4/172 [05:54<3:30:39, 75.23s/it]Training Epoch: 6/12, completed (loss: 0.16790567338466644):   2%|[34mâ–         [0m| 4/172 [06:09<3:30:39, 75.23s/it] Training Epoch: 6/12, completed (loss: 0.16790567338466644):   3%|[34mâ–Ž         [0m| 5/172 [06:24<2:43:23, 58.71s/it]Training Epoch: 6/12, completed (loss: 0.35269439220428467):   3%|[34mâ–Ž         [0m| 5/172 [06:24<2:43:23, 58.71s/it]Training Epoch: 6/12, completed (loss: 0.16608133912086487):   3%|[34mâ–Ž         [0m| 5/172 [06:38<2:43:23, 58.71s/it]Training Epoch: 6/12, completed (loss: 0.16608133912086487):   3%|[34mâ–Ž         [0m| 6/172 [06:53<2:14:36, 48.66s/it]Training Epoch: 6/12, completed (loss: 0.0005734412698075175):   3%|[34mâ–Ž         [0m| 6/172 [06:53<2:14:36, 48.66s/it]Training Epoch: 6/12, completed (loss: 0.1804044544696808):   3%|[34mâ–Ž         [0m| 6/172 [07:08<2:14:36, 48.66s/it]   Training Epoch: 6/12, completed (loss: 0.1804044544696808):   4%|[34mâ–         [0m| 7/172 [07:22<1:56:32, 42.38s/it]Training Epoch: 6/12, completed (loss: 0.02567468024790287):   4%|[34mâ–         [0m| 7/172 [07:22<1:56:32, 42.38s/it]Training Epoch: 6/12, completed (loss: 0.13755430281162262):   4%|[34mâ–         [0m| 7/172 [07:37<1:56:32, 42.38s/it]Training Epoch: 6/12, completed (loss: 0.13755430281162262):   5%|[34mâ–         [0m| 8/172 [07:52<1:44:29, 38.23s/it]Training Epoch: 6/12, completed (loss: 0.12923437356948853):   5%|[34mâ–         [0m| 8/172 [07:52<1:44:29, 38.23s/it]Training Epoch: 6/12, completed (loss: 0.2932097017765045):   5%|[34mâ–         [0m| 8/172 [08:07<1:44:29, 38.23s/it] Training Epoch: 6/12, completed (loss: 0.2932097017765045):   5%|[34mâ–Œ         [0m| 9/172 [08:21<1:36:26, 35.50s/it]Training Epoch: 6/12, completed (loss: 0.09186874330043793):   5%|[34mâ–Œ         [0m| 9/172 [08:21<1:36:26, 35.50s/it]Training Epoch: 6/12, completed (loss: 0.031204286962747574):   5%|[34mâ–Œ         [0m| 9/172 [08:36<1:36:26, 35.50s/it]Training Epoch: 6/12, completed (loss: 0.031204286962747574):   6%|[34mâ–Œ         [0m| 10/172 [08:50<1:30:30, 33.52s/it]Training Epoch: 6/12, completed (loss: 0.19525320827960968):   6%|[34mâ–Œ         [0m| 10/172 [08:50<1:30:30, 33.52s/it] Training Epoch: 6/12, completed (loss: 0.11336902529001236):   6%|[34mâ–Œ         [0m| 10/172 [09:05<1:30:30, 33.52s/it]Training Epoch: 6/12, completed (loss: 0.11336902529001236):   6%|[34mâ–‹         [0m| 11/172 [09:19<1:26:26, 32.22s/it]Training Epoch: 6/12, completed (loss: 0.07586875557899475):   6%|[34mâ–‹         [0m| 11/172 [09:20<1:26:26, 32.22s/it]Training Epoch: 6/12, completed (loss: 0.22791679203510284):   6%|[34mâ–‹         [0m| 11/172 [09:34<1:26:26, 32.22s/it]Training Epoch: 6/12, completed (loss: 0.22791679203510284):   7%|[34mâ–‹         [0m| 12/172 [09:49<1:23:27, 31.30s/it]Training Epoch: 6/12, completed (loss: 0.06137653812766075):   7%|[34mâ–‹         [0m| 12/172 [09:49<1:23:27, 31.30s/it]Training Epoch: 6/12, completed (loss: 0.030260497704148293):   7%|[34mâ–‹         [0m| 12/172 [10:03<1:23:27, 31.30s/it]Training Epoch: 6/12, completed (loss: 0.030260497704148293):   8%|[34mâ–Š         [0m| 13/172 [10:18<1:21:15, 30.67s/it]Training Epoch: 6/12, completed (loss: 0.0022488052491098642):   8%|[34mâ–Š         [0m| 13/172 [10:18<1:21:15, 30.67s/it]Training Epoch: 6/12, completed (loss: 0.18567973375320435):   8%|[34mâ–Š         [0m| 13/172 [10:33<1:21:15, 30.67s/it]  Training Epoch: 6/12, completed (loss: 0.18567973375320435):   8%|[34mâ–Š         [0m| 14/172 [10:47<1:19:42, 30.27s/it]Training Epoch: 6/12, completed (loss: 0.2771756052970886):   8%|[34mâ–Š         [0m| 14/172 [10:47<1:19:42, 30.27s/it] Training Epoch: 6/12, completed (loss: 0.029219692572951317):   8%|[34mâ–Š         [0m| 14/172 [11:02<1:19:42, 30.27s/it]Training Epoch: 6/12, completed (loss: 0.029219692572951317):   9%|[34mâ–Š         [0m| 15/172 [11:16<1:18:22, 29.95s/it]Training Epoch: 6/12, completed (loss: 0.13304966688156128):   9%|[34mâ–Š         [0m| 15/172 [11:17<1:18:22, 29.95s/it] Training Epoch: 6/12, completed (loss: 0.030090181156992912):   9%|[34mâ–Š         [0m| 15/172 [11:31<1:18:22, 29.95s/it]Training Epoch: 6/12, completed (loss: 0.030090181156992912):   9%|[34mâ–‰         [0m| 16/172 [11:46<1:17:28, 29.80s/it]Training Epoch: 6/12, completed (loss: 0.08935172110795975):   9%|[34mâ–‰         [0m| 16/172 [11:46<1:17:28, 29.80s/it] Training Epoch: 6/12, completed (loss: 0.209081768989563):   9%|[34mâ–‰         [0m| 16/172 [12:01<1:17:28, 29.80s/it]  Training Epoch: 6/12, completed (loss: 0.209081768989563):  10%|[34mâ–‰         [0m| 17/172 [12:15<1:16:40, 29.68s/it]Training Epoch: 6/12, completed (loss: 0.10172504931688309):  10%|[34mâ–‰         [0m| 17/172 [12:15<1:16:40, 29.68s/it]Training Epoch: 6/12, completed (loss: 0.16596217453479767):  10%|[34mâ–‰         [0m| 17/172 [12:30<1:16:40, 29.68s/it]Training Epoch: 6/12, completed (loss: 0.16596217453479767):  10%|[34mâ–ˆ         [0m| 18/172 [12:44<1:15:45, 29.52s/it]Training Epoch: 6/12, completed (loss: 0.2115139365196228):  10%|[34mâ–ˆ         [0m| 18/172 [12:45<1:15:45, 29.52s/it] Training Epoch: 6/12, completed (loss: 0.11003585159778595):  10%|[34mâ–ˆ         [0m| 18/172 [12:59<1:15:45, 29.52s/it]Training Epoch: 6/12, completed (loss: 0.11003585159778595):  11%|[34mâ–ˆ         [0m| 19/172 [13:14<1:15:07, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.03483711928129196):  11%|[34mâ–ˆ         [0m| 19/172 [13:14<1:15:07, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.18164467811584473):  11%|[34mâ–ˆ         [0m| 19/172 [13:29<1:15:07, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.18164467811584473):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:43<1:14:24, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.006605440750718117):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:43<1:14:24, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.08858143538236618):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:58<1:14:24, 29.37s/it] Training Epoch: 6/12, completed (loss: 0.08858143538236618):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:12<1:13:55, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.014204546809196472):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:12<1:13:55, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.0017294061835855246):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:27<1:13:55, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.0017294061835855246):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:42<1:13:24, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.10557907819747925):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:42<1:13:24, 29.37s/it]  Training Epoch: 6/12, completed (loss: 0.22335350513458252):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:57<1:13:24, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.22335350513458252):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:11<1:13:00, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.044557709246873856):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:11<1:13:00, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.23296518623828888):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:26<1:13:00, 29.40s/it] Training Epoch: 6/12, completed (loss: 0.23296518623828888):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:40<1:12:28, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.29885342717170715):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:41<1:12:28, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.01222603302448988):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:55<1:12:28, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.01222603302448988):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:10<1:11:53, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.011662131175398827):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:10<1:11:53, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.11820577830076218):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:25<1:11:53, 29.34s/it] Training Epoch: 6/12, completed (loss: 0.11820577830076218):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:39<1:11:21, 29.32s/it]Training Epoch: 6/12, completed (loss: 0.1842479109764099):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:39<1:11:21, 29.32s/it] Training Epoch: 6/12, completed (loss: 0.10134435445070267):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:54<1:11:21, 29.32s/it]Training Epoch: 6/12, completed (loss: 0.10134435445070267):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:08<1:10:48, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.07116224616765976):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:08<1:10:48, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.09501194953918457):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:23<1:10:48, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.09501194953918457):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:37<1:10:19, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.002330980496481061):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:38<1:10:19, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.3183436095714569):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:52<1:10:19, 29.30s/it]  Training Epoch: 6/12, completed (loss: 0.3183436095714569):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:07<1:09:49, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.07732829451560974):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:07<1:09:49, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.2038464993238449):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:22<1:09:49, 29.30s/it] Training Epoch: 6/12, completed (loss: 0.2038464993238449):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:36<1:09:18, 29.29s/it]Training Epoch: 6/12, completed (loss: 0.3511331379413605):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:36<1:09:18, 29.29s/it]Training Epoch: 6/12, completed (loss: 0.004251684062182903):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:51<1:09:18, 29.29s/it]Training Epoch: 6/12, completed (loss: 0.004251684062182903):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:05<1:08:48, 29.28s/it]Training Epoch: 6/12, completed (loss: 0.017587613314390182):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:06<1:08:48, 29.28s/it]Training Epoch: 6/12, completed (loss: 0.10244400799274445):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:20<1:08:48, 29.28s/it] Training Epoch: 6/12, completed (loss: 0.10244400799274445):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:35<1:08:22, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.045265451073646545):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:35<1:08:22, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.12909533083438873):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:49<1:08:22, 29.30s/it] Training Epoch: 6/12, completed (loss: 0.12909533083438873):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:04<1:07:51, 29.29s/it]Training Epoch: 6/12, completed (loss: 0.11648385226726532):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:04<1:07:51, 29.29s/it]Training Epoch: 6/12, completed (loss: 0.1586752086877823):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:19<1:07:51, 29.29s/it] Training Epoch: 6/12, completed (loss: 0.1586752086877823):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:33<1:07:25, 29.32s/it]Training Epoch: 6/12, completed (loss: 0.12701591849327087):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:34<1:07:25, 29.32s/it]Training Epoch: 6/12, completed (loss: 0.05660199746489525):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:48<1:07:25, 29.32s/it]Training Epoch: 6/12, completed (loss: 0.05660199746489525):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:03<1:06:57, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.0037350535858422518):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:03<1:06:57, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.08566881716251373):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:18<1:06:57, 29.33s/it]  Training Epoch: 6/12, completed (loss: 0.08566881716251373):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:32<1:06:34, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.04574061185121536):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:32<1:06:34, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.021522223949432373):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:47<1:06:34, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.021522223949432373):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:02<1:06:06, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.00916473101824522):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:02<1:06:06, 29.38s/it] Training Epoch: 6/12, completed (loss: 0.03333635255694389):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:16<1:06:06, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.03333635255694389):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:31<1:05:30, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.0016096875770017505):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:31<1:05:30, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.33672088384628296):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:46<1:05:30, 29.33s/it]  Training Epoch: 6/12, completed (loss: 0.33672088384628296):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:00<1:05:00, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.024759814143180847):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:00<1:05:00, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.1660824716091156):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:15<1:05:00, 29.33s/it]  Training Epoch: 6/12, completed (loss: 0.1660824716091156):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:29<1:04:29, 29.31s/it]Training Epoch: 6/12, completed (loss: 0.06588399410247803):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:30<1:04:29, 29.31s/it]Training Epoch: 6/12, completed (loss: 0.08358944207429886):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:44<1:04:29, 29.31s/it]Training Epoch: 6/12, completed (loss: 0.08358944207429886):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:59<1:04:03, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.0672885924577713):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [23:59<1:04:03, 29.34s/it] Training Epoch: 6/12, completed (loss: 0.0005127679323777556):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:14<1:04:03, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.0005127679323777556):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:28<1:03:38, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.012783519923686981):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:28<1:03:38, 29.37s/it] Training Epoch: 6/12, completed (loss: 0.032586634159088135):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:43<1:03:38, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.032586634159088135):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:57<1:03:06, 29.35s/it]Training Epoch: 6/12, completed (loss: 0.03449992462992668):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [24:58<1:03:06, 29.35s/it] Training Epoch: 6/12, completed (loss: 0.2091251164674759):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:12<1:03:06, 29.35s/it] Training Epoch: 6/12, completed (loss: 0.2091251164674759):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:27<1:02:35, 29.34s/it] eval_ppl=tensor(2.0444, device='cuda:0') eval_epoch_loss=tensor(0.7151, device='cuda:0')
Eval epoch loss:  tensor(0.7151, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_6_1
Time while saving:  2023-10-26 02:00:16 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 6, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:52,  8.00s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:42,  7.95s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.91s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:25,  7.89s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.92s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.94s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:02,  7.92s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.91s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:31,  7.95s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:35<02:22,  7.94s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:15,  7.96s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:51<02:07,  7.96s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:59<01:59,  7.97s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:07<01:51,  7.95s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.93s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.91s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:26,  7.90s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.92s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.93s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.91s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.94s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.93s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:26<00:31,  7.92s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.93s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.98s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:50<00:07,  7.96s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:58<00:00,  7.94s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:58<00:00,  7.93s/it]
Training Epoch: 6/12, completed (loss: 0.07484780251979828):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:25<1:02:35, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.07512319087982178):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:40<1:02:35, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.07512319087982178):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:54<3:33:16, 100.76s/it]Training Epoch: 6/12, completed (loss: 0.001195835298858583):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [29:54<3:33:16, 100.76s/it]Training Epoch: 6/12, completed (loss: 0.282164067029953):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 45/172 [30:09<3:33:16, 100.76s/it]   Training Epoch: 6/12, completed (loss: 0.282164067029953):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:23<2:46:25, 79.25s/it] Training Epoch: 6/12, completed (loss: 0.0038943870458751917):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:23<2:46:25, 79.25s/it]Training Epoch: 6/12, completed (loss: 0.010732539929449558):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 46/172 [30:38<2:46:25, 79.25s/it] Training Epoch: 6/12, completed (loss: 0.010732539929449558):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:53<2:13:57, 64.30s/it]Training Epoch: 6/12, completed (loss: 0.10418260097503662):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [30:53<2:13:57, 64.30s/it] Training Epoch: 6/12, completed (loss: 0.24199463427066803):  27%|[34mâ–ˆâ–ˆâ–‹       [0m| 47/172 [31:08<2:13:57, 64.30s/it]Training Epoch: 6/12, completed (loss: 0.24199463427066803):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:22<1:51:09, 53.79s/it]Training Epoch: 6/12, completed (loss: 0.00955934077501297):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:22<1:51:09, 53.79s/it]Training Epoch: 6/12, completed (loss: 0.009867178276181221):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 48/172 [31:37<1:51:09, 53.79s/it]Training Epoch: 6/12, completed (loss: 0.009867178276181221):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:51<1:35:11, 46.44s/it]Training Epoch: 6/12, completed (loss: 1.096078813134227e-05):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [31:51<1:35:11, 46.44s/it]Training Epoch: 6/12, completed (loss: 0.3016774654388428):  28%|[34mâ–ˆâ–ˆâ–Š       [0m| 49/172 [32:06<1:35:11, 46.44s/it]   Training Epoch: 6/12, completed (loss: 0.3016774654388428):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:21<1:23:58, 41.30s/it]Training Epoch: 6/12, completed (loss: 0.10017699003219604):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:21<1:23:58, 41.30s/it]Training Epoch: 6/12, completed (loss: 0.21121913194656372):  29%|[34mâ–ˆâ–ˆâ–‰       [0m| 50/172 [32:35<1:23:58, 41.30s/it]Training Epoch: 6/12, completed (loss: 0.21121913194656372):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:50<1:15:58, 37.67s/it]Training Epoch: 6/12, completed (loss: 0.0001328751677647233):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [32:50<1:15:58, 37.67s/it]Training Epoch: 6/12, completed (loss: 0.15020902454853058):  30%|[34mâ–ˆâ–ˆâ–‰       [0m| 51/172 [33:05<1:15:58, 37.67s/it]  Training Epoch: 6/12, completed (loss: 0.15020902454853058):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:19<1:10:27, 35.23s/it]Training Epoch: 6/12, completed (loss: 0.01291967649012804):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:19<1:10:27, 35.23s/it]Training Epoch: 6/12, completed (loss: 0.3251233398914337):  30%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 52/172 [33:34<1:10:27, 35.23s/it] Training Epoch: 6/12, completed (loss: 0.3251233398914337):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:49<1:06:22, 33.46s/it]Training Epoch: 6/12, completed (loss: 0.016393359750509262):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [33:49<1:06:22, 33.46s/it]Training Epoch: 6/12, completed (loss: 0.00890841893851757):  31%|[34mâ–ˆâ–ˆâ–ˆ       [0m| 53/172 [34:04<1:06:22, 33.46s/it] Training Epoch: 6/12, completed (loss: 0.00890841893851757):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:18<1:03:22, 32.22s/it]Training Epoch: 6/12, completed (loss: 0.052231527864933014):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:18<1:03:22, 32.22s/it]Training Epoch: 6/12, completed (loss: 0.08587086945772171):  31%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 54/172 [34:33<1:03:22, 32.22s/it] Training Epoch: 6/12, completed (loss: 0.08587086945772171):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:47<1:01:08, 31.36s/it]Training Epoch: 6/12, completed (loss: 0.008613076992332935):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [34:48<1:01:08, 31.36s/it]Training Epoch: 6/12, completed (loss: 0.006622808054089546):  32%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 55/172 [35:02<1:01:08, 31.36s/it]Training Epoch: 6/12, completed (loss: 0.006622808054089546):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:17<59:27, 30.75s/it]  Training Epoch: 6/12, completed (loss: 0.0990695208311081):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:17<59:27, 30.75s/it]  Training Epoch: 6/12, completed (loss: 0.21561649441719055):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 56/172 [35:32<59:27, 30.75s/it]Training Epoch: 6/12, completed (loss: 0.21561649441719055):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:46<58:09, 30.35s/it]Training Epoch: 6/12, completed (loss: 0.1835542470216751):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [35:46<58:09, 30.35s/it] Training Epoch: 6/12, completed (loss: 4.21447039116174e-05):  33%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 57/172 [36:01<58:09, 30.35s/it]Training Epoch: 6/12, completed (loss: 4.21447039116174e-05):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:15<57:05, 30.05s/it]Training Epoch: 6/12, completed (loss: 0.10822927951812744):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:16<57:05, 30.05s/it] Training Epoch: 6/12, completed (loss: 0.26438191533088684):  34%|[34mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 58/172 [36:30<57:05, 30.05s/it]Training Epoch: 6/12, completed (loss: 0.26438191533088684):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:45<56:18, 29.90s/it]Training Epoch: 6/12, completed (loss: 0.08719059079885483):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [36:45<56:18, 29.90s/it]Training Epoch: 6/12, completed (loss: 0.03753317892551422):  34%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 59/172 [37:00<56:18, 29.90s/it]Training Epoch: 6/12, completed (loss: 0.03753317892551422):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:14<55:25, 29.69s/it]Training Epoch: 6/12, completed (loss: 0.006345066707581282):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:14<55:25, 29.69s/it]Training Epoch: 6/12, completed (loss: 0.13128170371055603):  35%|[34mâ–ˆâ–ˆâ–ˆâ–      [0m| 60/172 [37:29<55:25, 29.69s/it] Training Epoch: 6/12, completed (loss: 0.13128170371055603):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:44<54:48, 29.63s/it]Training Epoch: 6/12, completed (loss: 0.048822805285453796):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:44<54:48, 29.63s/it]Training Epoch: 6/12, completed (loss: 8.38245341583388e-06):  35%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 61/172 [37:59<54:48, 29.63s/it]Training Epoch: 6/12, completed (loss: 8.38245341583388e-06):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:13<54:11, 29.56s/it]Training Epoch: 6/12, completed (loss: 0.30822765827178955):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:13<54:11, 29.56s/it] Training Epoch: 6/12, completed (loss: 0.4062214195728302):  36%|[34mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 62/172 [38:28<54:11, 29.56s/it] Training Epoch: 6/12, completed (loss: 0.4062214195728302):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:42<53:32, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.3949471414089203):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:43<53:32, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.027343688532710075):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 63/172 [38:57<53:32, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.027343688532710075):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:12<53:03, 29.48s/it]Training Epoch: 6/12, completed (loss: 0.10737105458974838):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:12<53:03, 29.48s/it] Training Epoch: 6/12, completed (loss: 0.12634854018688202):  37%|[34mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 64/172 [39:27<53:03, 29.48s/it]Training Epoch: 6/12, completed (loss: 0.12634854018688202):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:41<52:30, 29.44s/it]Training Epoch: 6/12, completed (loss: 0.04440436139702797):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:41<52:30, 29.44s/it]Training Epoch: 6/12, completed (loss: 0.13340505957603455):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 65/172 [39:56<52:30, 29.44s/it]Training Epoch: 6/12, completed (loss: 0.13340505957603455):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:10<51:57, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.08365855365991592):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:11<51:57, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.04546433314681053):  38%|[34mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 66/172 [40:25<51:57, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.04546433314681053):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:40<51:27, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.01779637672007084):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:40<51:27, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.00578833743929863):  39%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 67/172 [40:55<51:27, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.00578833743929863):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:09<50:57, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.06709747016429901):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:09<50:57, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.10193291306495667):  40%|[34mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 68/172 [41:24<50:57, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.10193291306495667):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:39<50:24, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.0024760642554610968):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:39<50:24, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.09743897616863251):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 69/172 [41:53<50:24, 29.36s/it]  Training Epoch: 6/12, completed (loss: 0.09743897616863251):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:08<49:56, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.37131020426750183):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:08<49:56, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.16643518209457397):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 70/172 [42:23<49:56, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.16643518209457397):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:37<49:29, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.15677107870578766):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:38<49:29, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.11376173794269562):  41%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 71/172 [42:52<49:29, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.11376173794269562):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:07<48:58, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.04003071039915085):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:07<48:58, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.34172698855400085):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 72/172 [43:22<48:58, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.34172698855400085):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:36<48:32, 29.42s/it]Training Epoch: 6/12, completed (loss: 4.9676546041155234e-05):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:36<48:32, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.18876725435256958):  42%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 73/172 [43:51<48:32, 29.42s/it]   Training Epoch: 6/12, completed (loss: 0.18876725435256958):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:06<47:59, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.1676834672689438):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:06<47:59, 29.38s/it] Training Epoch: 6/12, completed (loss: 0.15358756482601166):  43%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 74/172 [44:20<47:59, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.15358756482601166):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:35<47:31, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.01358222309499979):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:35<47:31, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.003279432188719511):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 75/172 [44:50<47:31, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.003279432188719511):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:04<47:01, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.07037156075239182):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:05<47:01, 29.39s/it] Training Epoch: 6/12, completed (loss: 0.03412036597728729):  44%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 76/172 [45:19<47:01, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.03412036597728729):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:34<46:29, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.2388962060213089):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:34<46:29, 29.36s/it] Training Epoch: 6/12, completed (loss: 0.007307013496756554):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 77/172 [45:49<46:29, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.007307013496756554):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:03<46:00, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.09325969964265823):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:03<46:00, 29.36s/it] Training Epoch: 6/12, completed (loss: 0.08710863441228867):  45%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 78/172 [46:18<46:00, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.08710863441228867):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:32<45:30, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.011133839376270771):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:33<45:30, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.13495677709579468):  46%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 79/172 [46:47<45:30, 29.36s/it] Training Epoch: 6/12, completed (loss: 0.13495677709579468):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:02<44:56, 29.31s/it]Training Epoch: 6/12, completed (loss: 0.06549649685621262):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:02<44:56, 29.31s/it]Training Epoch: 6/12, completed (loss: 0.22067584097385406):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 80/172 [47:17<44:56, 29.31s/it]Training Epoch: 6/12, completed (loss: 0.22067584097385406):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:31<44:29, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.01718956045806408):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:31<44:29, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.05748828500509262):  47%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 81/172 [47:46<44:29, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.05748828500509262):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:00<44:01, 29.35s/it]Training Epoch: 6/12, completed (loss: 0.09213735163211823):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:01<44:01, 29.35s/it]Training Epoch: 6/12, completed (loss: 0.21984367072582245):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 82/172 [48:15<44:01, 29.35s/it]Training Epoch: 6/12, completed (loss: 0.21984367072582245):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:30<43:32, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.14902402460575104):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:30<43:32, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.12342371791601181):  48%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 83/172 [48:45<43:32, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.12342371791601181):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:59<43:04, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.26110538840293884):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [48:59<43:04, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.04864772781729698):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 84/172 [49:14<43:04, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.04864772781729698):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:28<42:35, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.36040592193603516):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:29<42:35, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.2348313182592392):  49%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 85/172 [49:43<42:35, 29.37s/it] Training Epoch: 6/12, completed (loss: 0.2348313182592392):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:58<42:06, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.18553099036216736):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [49:58<42:06, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.241017684340477):  50%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 86/172 [50:13<42:06, 29.38s/it]  Training Epoch: 6/12, completed (loss: 0.241017684340477):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [50:27<41:36, 29.37s/it] eval_ppl=tensor(2.1619, device='cuda:0') eval_epoch_loss=tensor(0.7710, device='cuda:0')
Eval epoch loss:  tensor(0.7710, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_6_87
Time while saving:  2023-10-26 02:25:14 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 6, step_id: 173

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:53,  8.04s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:43,  7.97s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.92s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:25,  7.89s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.88s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.92s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:02,  7.92s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.94s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.94s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.94s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:31,  7.96s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:35<02:25,  8.11s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:17,  8.08s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:51<02:09,  8.06s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:59<02:00,  8.04s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:07<01:52,  8.00s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:15<01:43,  7.96s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:23<01:35,  7.95s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:31<01:27,  7.94s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:39<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:47<01:11,  7.94s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:55<01:03,  7.92s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:03<00:55,  7.94s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:11<00:47,  7.99s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:19<00:39,  7.98s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:27<00:31,  7.96s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:35<00:23,  7.96s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:43<00:15,  7.95s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:51<00:08,  8.07s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:59<00:00,  8.03s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:59<00:00,  7.98s/it]
Training Epoch: 6/12, completed (loss: 0.04959993436932564):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:27<41:36, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.004542409908026457):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 87/172 [54:42<41:36, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.004542409908026457):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:56<2:21:41, 101.21s/it]Training Epoch: 6/12, completed (loss: 0.060139212757349014):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [54:56<2:21:41, 101.21s/it]Training Epoch: 6/12, completed (loss: 0.17953617870807648):  51%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 88/172 [55:11<2:21:41, 101.21s/it] Training Epoch: 6/12, completed (loss: 0.17953617870807648):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:25<1:50:11, 79.66s/it] Training Epoch: 6/12, completed (loss: 0.06944259256124496):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:26<1:50:11, 79.66s/it]Training Epoch: 6/12, completed (loss: 0.07069995999336243):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 89/172 [55:40<1:50:11, 79.66s/it]Training Epoch: 6/12, completed (loss: 0.07069995999336243):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:55<1:28:16, 64.59s/it]Training Epoch: 6/12, completed (loss: 0.4097026288509369):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [55:55<1:28:16, 64.59s/it] Training Epoch: 6/12, completed (loss: 0.043628398329019547):  52%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 90/172 [56:10<1:28:16, 64.59s/it]Training Epoch: 6/12, completed (loss: 0.043628398329019547):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:24<1:12:58, 54.06s/it]Training Epoch: 6/12, completed (loss: 0.12981745600700378):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:25<1:12:58, 54.06s/it] Training Epoch: 6/12, completed (loss: 0.10497751832008362):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 91/172 [56:39<1:12:58, 54.06s/it]Training Epoch: 6/12, completed (loss: 0.10497751832008362):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:54<1:02:12, 46.66s/it]Training Epoch: 6/12, completed (loss: 0.10321494936943054):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [56:54<1:02:12, 46.66s/it]Training Epoch: 6/12, completed (loss: 0.009131778962910175):  53%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 92/172 [57:09<1:02:12, 46.66s/it]Training Epoch: 6/12, completed (loss: 0.009131778962910175):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:23<54:40, 41.53s/it]  Training Epoch: 6/12, completed (loss: 0.24772906303405762):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:24<54:40, 41.53s/it] Training Epoch: 6/12, completed (loss: 0.13351918756961823):  54%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 93/172 [57:38<54:40, 41.53s/it]Training Epoch: 6/12, completed (loss: 0.13351918756961823):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:53<49:15, 37.89s/it]Training Epoch: 6/12, completed (loss: 0.12589460611343384):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [57:53<49:15, 37.89s/it]Training Epoch: 6/12, completed (loss: 0.38790613412857056):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 94/172 [58:08<49:15, 37.89s/it]Training Epoch: 6/12, completed (loss: 0.38790613412857056):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:22<45:22, 35.35s/it]Training Epoch: 6/12, completed (loss: 0.0067781624384224415):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:22<45:22, 35.35s/it]Training Epoch: 6/12, completed (loss: 0.012822028249502182):  55%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 95/172 [58:37<45:22, 35.35s/it] Training Epoch: 6/12, completed (loss: 0.012822028249502182):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:52<42:34, 33.61s/it]Training Epoch: 6/12, completed (loss: 0.12598749995231628):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [58:52<42:34, 33.61s/it] Training Epoch: 6/12, completed (loss: 0.19322827458381653):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 96/172 [59:07<42:34, 33.61s/it]Training Epoch: 6/12, completed (loss: 0.19322827458381653):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:21<40:26, 32.36s/it]Training Epoch: 6/12, completed (loss: 0.022254647687077522):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:21<40:26, 32.36s/it]Training Epoch: 6/12, completed (loss: 0.160639688372612):  56%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 97/172 [59:36<40:26, 32.36s/it]   Training Epoch: 6/12, completed (loss: 0.160639688372612):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:50<38:48, 31.46s/it]Training Epoch: 6/12, completed (loss: 0.028448231518268585):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [59:51<38:48, 31.46s/it]Training Epoch: 6/12, completed (loss: 0.2309822142124176):  57%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 98/172 [1:00:05<38:48, 31.46s/it]Training Epoch: 6/12, completed (loss: 0.2309822142124176):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:20<37:33, 30.86s/it]Training Epoch: 6/12, completed (loss: 0.026922451332211494):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:20<37:33, 30.86s/it]Training Epoch: 6/12, completed (loss: 0.07373098284006119):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 99/172 [1:00:35<37:33, 30.86s/it] Training Epoch: 6/12, completed (loss: 0.07373098284006119):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:49<36:28, 30.40s/it]Training Epoch: 6/12, completed (loss: 0.004150680266320705):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:00:49<36:28, 30.40s/it]Training Epoch: 6/12, completed (loss: 0.002702809404581785):  58%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 100/172 [1:01:04<36:28, 30.40s/it]Training Epoch: 6/12, completed (loss: 0.002702809404581785):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:19<35:34, 30.07s/it]Training Epoch: 6/12, completed (loss: 0.052585676312446594):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:19<35:34, 30.07s/it]Training Epoch: 6/12, completed (loss: 0.025057602673768997):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 101/172 [1:01:33<35:34, 30.07s/it]Training Epoch: 6/12, completed (loss: 0.025057602673768997):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:48<34:49, 29.85s/it]Training Epoch: 6/12, completed (loss: 0.14607350528240204):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:01:48<34:49, 29.85s/it] Training Epoch: 6/12, completed (loss: 0.15299704670906067):  59%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 102/172 [1:02:03<34:49, 29.85s/it]Training Epoch: 6/12, completed (loss: 0.15299704670906067):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:17<34:09, 29.70s/it]Training Epoch: 6/12, completed (loss: 0.007990974001586437):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:17<34:09, 29.70s/it]Training Epoch: 6/12, completed (loss: 0.03416772186756134):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 103/172 [1:02:32<34:09, 29.70s/it] Training Epoch: 6/12, completed (loss: 0.03416772186756134):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:47<33:31, 29.59s/it]Training Epoch: 6/12, completed (loss: 0.14219941198825836):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:02:47<33:31, 29.59s/it]Training Epoch: 6/12, completed (loss: 0.15912127494812012):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 104/172 [1:03:02<33:31, 29.59s/it]Training Epoch: 6/12, completed (loss: 0.15912127494812012):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:16<32:59, 29.55s/it]Training Epoch: 6/12, completed (loss: 0.1142536848783493):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:16<32:59, 29.55s/it] Training Epoch: 6/12, completed (loss: 0.00030643073841929436):  61%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 105/172 [1:03:31<32:59, 29.55s/it]Training Epoch: 6/12, completed (loss: 0.00030643073841929436):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:45<32:27, 29.51s/it]Training Epoch: 6/12, completed (loss: 0.07384413480758667):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:03:46<32:27, 29.51s/it]   Training Epoch: 6/12, completed (loss: 0.04105405882000923):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 106/172 [1:04:00<32:27, 29.51s/it]Training Epoch: 6/12, completed (loss: 0.04105405882000923):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:15<31:54, 29.45s/it]Training Epoch: 6/12, completed (loss: 0.1582421511411667):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:15<31:54, 29.45s/it] Training Epoch: 6/12, completed (loss: 0.06026227027177811):  62%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 107/172 [1:04:30<31:54, 29.45s/it]Training Epoch: 6/12, completed (loss: 0.06026227027177811):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:44<31:23, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.06621618568897247):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:44<31:23, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.08702059835195541):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 108/172 [1:04:59<31:23, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.08702059835195541):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:14<30:52, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.04063893109560013):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:14<30:52, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.12195853888988495):  63%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 109/172 [1:05:28<30:52, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.12195853888988495):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:43<30:21, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.00038905718247406185):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:43<30:21, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.08072979748249054):  64%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 110/172 [1:05:58<30:21, 29.38s/it]   Training Epoch: 6/12, completed (loss: 0.08072979748249054):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:12<29:51, 29.37s/it]Training Epoch: 6/12, completed (loss: 7.771033779135905e-06):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:12<29:51, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.15000447630882263):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 111/172 [1:06:27<29:51, 29.37s/it]  Training Epoch: 6/12, completed (loss: 0.15000447630882263):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:42<29:21, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.25598984956741333):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:42<29:21, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.10150301456451416):  65%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 112/172 [1:06:56<29:21, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.10150301456451416):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:11<28:52, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.016874363645911217):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:11<28:52, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.3712248206138611):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 113/172 [1:07:26<28:52, 29.37s/it]  Training Epoch: 6/12, completed (loss: 0.3712248206138611):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:40<28:23, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.0006475190166383982):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:40<28:23, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.2258545607328415):  66%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 114/172 [1:07:55<28:23, 29.36s/it]   Training Epoch: 6/12, completed (loss: 0.2258545607328415):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:10<27:55, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.2097993642091751):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:10<27:55, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.17284934222698212):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 115/172 [1:08:25<27:55, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.17284934222698212):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:39<27:25, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.27503201365470886):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:39<27:25, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.15167663991451263):  67%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 116/172 [1:08:54<27:25, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.15167663991451263):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:08<26:56, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.17797286808490753):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:09<26:56, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.12553052604198456):  68%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 117/172 [1:09:23<26:56, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.12553052604198456):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:38<26:27, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.12787431478500366):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:38<26:27, 29.39s/it]Training Epoch: 6/12, completed (loss: 0.263621985912323):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 118/172 [1:09:53<26:27, 29.39s/it]  Training Epoch: 6/12, completed (loss: 0.263621985912323):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:07<25:56, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.20978902280330658):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:07<25:56, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.13169626891613007):  69%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 119/172 [1:10:22<25:56, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.13169626891613007):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:37<25:27, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.08250071108341217):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:37<25:27, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.22852888703346252):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 120/172 [1:10:52<25:27, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.22852888703346252):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:06<25:01, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.049237094819545746):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:06<25:01, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.23016668856143951):  70%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 121/172 [1:11:21<25:01, 29.43s/it] Training Epoch: 6/12, completed (loss: 0.23016668856143951):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:35<24:30, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.0009311389876529574):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:36<24:30, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.18272803723812103):  71%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 122/172 [1:11:50<24:30, 29.40s/it]  Training Epoch: 6/12, completed (loss: 0.18272803723812103):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:05<24:01, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.1074976846575737):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:05<24:01, 29.42s/it] Training Epoch: 6/12, completed (loss: 0.17724186182022095):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 123/172 [1:12:20<24:01, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.17724186182022095):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:34<23:32, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.009882088750600815):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:35<23:32, 29.42s/it]Training Epoch: 6/12, completed (loss: 9.304523700848222e-06):  72%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 124/172 [1:12:49<23:32, 29.42s/it]Training Epoch: 6/12, completed (loss: 9.304523700848222e-06):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:04<22:59, 29.34s/it]Training Epoch: 6/12, completed (loss: 1.7540311091579497e-05):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:04<22:59, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.11581169068813324):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 125/172 [1:13:18<22:59, 29.34s/it]   Training Epoch: 6/12, completed (loss: 0.11581169068813324):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:33<22:30, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.00010725907486630604):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:33<22:30, 29.36s/it]Training Epoch: 6/12, completed (loss: 0.0018068078206852078):  73%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 126/172 [1:13:48<22:30, 29.36s/it] Training Epoch: 6/12, completed (loss: 0.0018068078206852078):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:14:02<21:59, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.3483220338821411):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:14:02<21:59, 29.33s/it]   Training Epoch: 6/12, completed (loss: 0.06823255866765976):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 127/172 [1:14:17<21:59, 29.33s/it]Training Epoch: 6/12, completed (loss: 0.06823255866765976):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:32<21:32, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.08045577257871628):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:32<21:32, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.009960129857063293):  74%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 128/172 [1:14:47<21:32, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.009960129857063293):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:15:01<21:02, 29.37s/it] eval_ppl=tensor(2.0621, device='cuda:0') eval_epoch_loss=tensor(0.7237, device='cuda:0')
Eval epoch loss:  tensor(0.7237, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_6_173
Time while saving:  2023-10-26 02:50:16 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 6, step_id: 257

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:48,  7.87s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.90s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:33,  7.89s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:25,  7.89s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.91s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.95s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.92s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:30,  7.91s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.92s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:15,  7.96s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:51<02:07,  7.97s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.97s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.95s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.93s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.93s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.94s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.92s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.91s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.92s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.94s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.95s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:26<00:31,  7.94s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.93s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:49<00:07,  7.93s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it]
Training Epoch: 6/12, completed (loss: 0.2887119948863983):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:18:59<21:02, 29.37s/it]  Training Epoch: 6/12, completed (loss: 0.0464317612349987):  75%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 129/172 [1:19:14<21:02, 29.37s/it]Training Epoch: 6/12, completed (loss: 0.0464317612349987):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:28<1:10:30, 100.73s/it]Training Epoch: 6/12, completed (loss: 0.004676904063671827):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:28<1:10:30, 100.73s/it]Training Epoch: 6/12, completed (loss: 0.1453109085559845):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 130/172 [1:19:43<1:10:30, 100.73s/it]  Training Epoch: 6/12, completed (loss: 0.1453109085559845):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:58<54:11, 79.30s/it]   Training Epoch: 6/12, completed (loss: 0.00614138413220644):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:19:58<54:11, 79.30s/it]Training Epoch: 6/12, completed (loss: 1.3842329281033017e-05):  76%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 131/172 [1:20:12<54:11, 79.30s/it]Training Epoch: 6/12, completed (loss: 1.3842329281033017e-05):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:27<42:51, 64.28s/it]Training Epoch: 6/12, completed (loss: 0.023480601608753204):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:27<42:51, 64.28s/it]  Training Epoch: 6/12, completed (loss: 0.05772829428315163):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 132/172 [1:20:42<42:51, 64.28s/it] Training Epoch: 6/12, completed (loss: 0.05772829428315163):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:56<34:57, 53.79s/it]Training Epoch: 6/12, completed (loss: 0.014069653116166592):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:20:56<34:57, 53.79s/it]Training Epoch: 6/12, completed (loss: 0.1939247101545334):  77%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 133/172 [1:21:11<34:57, 53.79s/it]  Training Epoch: 6/12, completed (loss: 0.1939247101545334):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:26<29:27, 46.52s/it]Training Epoch: 6/12, completed (loss: 0.29877984523773193):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:26<29:27, 46.52s/it]Training Epoch: 6/12, completed (loss: 0.041142553091049194):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 134/172 [1:21:41<29:27, 46.52s/it]Training Epoch: 6/12, completed (loss: 0.041142553091049194):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:55<25:30, 41.37s/it]Training Epoch: 6/12, completed (loss: 0.048815760761499405):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:21:55<25:30, 41.37s/it]Training Epoch: 6/12, completed (loss: 0.05377587303519249):  78%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 135/172 [1:22:10<25:30, 41.37s/it] Training Epoch: 6/12, completed (loss: 0.05377587303519249):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:24<22:40, 37.78s/it]Training Epoch: 6/12, completed (loss: 0.1503068506717682):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:25<22:40, 37.78s/it] Training Epoch: 6/12, completed (loss: 0.0007623265846632421):  79%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 136/172 [1:22:39<22:40, 37.78s/it]Training Epoch: 6/12, completed (loss: 0.0007623265846632421):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:54<20:35, 35.29s/it]Training Epoch: 6/12, completed (loss: 0.0009469517972320318):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:22:54<20:35, 35.29s/it]Training Epoch: 6/12, completed (loss: 0.00028695943183265626):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 137/172 [1:23:09<20:35, 35.29s/it]Training Epoch: 6/12, completed (loss: 0.00028695943183265626):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:23<18:59, 33.52s/it]Training Epoch: 6/12, completed (loss: 0.014754886738955975):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:24<18:59, 33.52s/it]  Training Epoch: 6/12, completed (loss: 0.12493503838777542):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 138/172 [1:23:38<18:59, 33.52s/it] Training Epoch: 6/12, completed (loss: 0.12493503838777542):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:53<17:44, 32.25s/it]Training Epoch: 6/12, completed (loss: 0.0025140533689409494):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:23:53<17:44, 32.25s/it]Training Epoch: 6/12, completed (loss: 0.19117850065231323):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 139/172 [1:24:07<17:44, 32.25s/it]  Training Epoch: 6/12, completed (loss: 0.19117850065231323):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:22<16:44, 31.39s/it]Training Epoch: 6/12, completed (loss: 0.1142461746931076):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:22<16:44, 31.39s/it] Training Epoch: 6/12, completed (loss: 0.01515153143554926):  81%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 140/172 [1:24:37<16:44, 31.39s/it]Training Epoch: 6/12, completed (loss: 0.01515153143554926):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:51<15:55, 30.83s/it]Training Epoch: 6/12, completed (loss: 9.149042853096034e-06):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:24:52<15:55, 30.83s/it]Training Epoch: 6/12, completed (loss: 4.7570229071425274e-05):  82%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 141/172 [1:25:06<15:55, 30.83s/it]Training Epoch: 6/12, completed (loss: 4.7570229071425274e-05):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:21<15:10, 30.36s/it]Training Epoch: 6/12, completed (loss: 0.1989128738641739):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:21<15:10, 30.36s/it]    Training Epoch: 6/12, completed (loss: 0.16580763459205627):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 142/172 [1:25:36<15:10, 30.36s/it]Training Epoch: 6/12, completed (loss: 0.16580763459205627):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:50<14:31, 30.07s/it]Training Epoch: 6/12, completed (loss: 0.18717625737190247):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:25:50<14:31, 30.07s/it]Training Epoch: 6/12, completed (loss: 0.026043839752674103):  83%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 143/172 [1:26:05<14:31, 30.07s/it]Training Epoch: 6/12, completed (loss: 0.026043839752674103):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:19<13:55, 29.85s/it]Training Epoch: 6/12, completed (loss: 0.25568869709968567):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:20<13:55, 29.85s/it] Training Epoch: 6/12, completed (loss: 0.0430595763027668):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 144/172 [1:26:34<13:55, 29.85s/it] Training Epoch: 6/12, completed (loss: 0.0430595763027668):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:49<13:20, 29.66s/it]Training Epoch: 6/12, completed (loss: 0.03851800411939621):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:26:49<13:20, 29.66s/it]Training Epoch: 6/12, completed (loss: 0.02411928027868271):  84%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 145/172 [1:27:04<13:20, 29.66s/it]Training Epoch: 6/12, completed (loss: 0.02411928027868271):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:18<12:49, 29.58s/it]Training Epoch: 6/12, completed (loss: 0.020107265561819077):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:18<12:49, 29.58s/it]Training Epoch: 6/12, completed (loss: 0.021903671324253082):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 146/172 [1:27:33<12:49, 29.58s/it]Training Epoch: 6/12, completed (loss: 0.021903671324253082):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:47<12:17, 29.51s/it]Training Epoch: 6/12, completed (loss: 0.20171304047107697):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:27:48<12:17, 29.51s/it] Training Epoch: 6/12, completed (loss: 0.03552171587944031):  85%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 147/172 [1:28:02<12:17, 29.51s/it]Training Epoch: 6/12, completed (loss: 0.03552171587944031):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:17<11:48, 29.50s/it]Training Epoch: 6/12, completed (loss: 0.0009726418065838516):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:17<11:48, 29.50s/it]Training Epoch: 6/12, completed (loss: 0.004570198245346546):  86%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 148/172 [1:28:32<11:48, 29.50s/it] Training Epoch: 6/12, completed (loss: 0.004570198245346546):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:46<11:18, 29.50s/it]Training Epoch: 6/12, completed (loss: 0.11352084577083588):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:28:47<11:18, 29.50s/it] Training Epoch: 6/12, completed (loss: 0.18516191840171814):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 149/172 [1:29:01<11:18, 29.50s/it]Training Epoch: 6/12, completed (loss: 0.18516191840171814):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:16<10:48, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.104104183614254):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:16<10:48, 29.47s/it]  Training Epoch: 6/12, completed (loss: 0.1872686743736267):  87%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 150/172 [1:29:31<10:48, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.1872686743736267):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:45<10:18, 29.48s/it]Training Epoch: 6/12, completed (loss: 0.23497094213962555):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:29:46<10:18, 29.48s/it]Training Epoch: 6/12, completed (loss: 0.19438274204730988):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 151/172 [1:30:00<10:18, 29.48s/it]Training Epoch: 6/12, completed (loss: 0.19438274204730988):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:15<09:49, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.18317216634750366):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:15<09:49, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.2469237595796585):  88%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 152/172 [1:30:30<09:49, 29.46s/it] Training Epoch: 6/12, completed (loss: 0.2469237595796585):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:44<09:19, 29.44s/it]Training Epoch: 6/12, completed (loss: 0.17858487367630005):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:44<09:19, 29.44s/it]Training Epoch: 6/12, completed (loss: 0.0894562378525734):  89%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 153/172 [1:30:59<09:19, 29.44s/it] Training Epoch: 6/12, completed (loss: 0.0894562378525734):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:14<08:49, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.12707066535949707):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:14<08:49, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.10567659884691238):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 154/172 [1:31:28<08:49, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.10567659884691238):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:43<08:20, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.09598007798194885):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:43<08:20, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.0007751038065180182):  90%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 155/172 [1:31:58<08:20, 29.43s/it]Training Epoch: 6/12, completed (loss: 0.0007751038065180182):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:12<07:50, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.15837615728378296):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:13<07:50, 29.42s/it]  Training Epoch: 6/12, completed (loss: 0.07577040046453476):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 156/172 [1:32:27<07:50, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.07577040046453476):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:42<07:21, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.18872526288032532):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:42<07:21, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.2777141034603119):  91%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 157/172 [1:32:57<07:21, 29.41s/it] Training Epoch: 6/12, completed (loss: 0.2777141034603119):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:11<06:51, 29.40s/it]Training Epoch: 6/12, completed (loss: 6.558313907589763e-05):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:11<06:51, 29.40s/it]Training Epoch: 6/12, completed (loss: 0.1622764617204666):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 158/172 [1:33:26<06:51, 29.40s/it]   Training Epoch: 6/12, completed (loss: 0.1622764617204666):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:41<06:23, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.07404090464115143):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:41<06:23, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.20078621804714203):  92%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 159/172 [1:33:56<06:23, 29.47s/it]Training Epoch: 6/12, completed (loss: 0.20078621804714203):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:10<05:53, 29.45s/it]Training Epoch: 6/12, completed (loss: 0.03536847233772278):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:10<05:53, 29.45s/it]Training Epoch: 6/12, completed (loss: 0.19075588881969452):  93%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 160/172 [1:34:25<05:53, 29.45s/it]Training Epoch: 6/12, completed (loss: 0.19075588881969452):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:40<05:24, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.07674586772918701):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:40<05:24, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.00013696684618480504):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 161/172 [1:34:54<05:24, 29.46s/it]Training Epoch: 6/12, completed (loss: 0.00013696684618480504):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:09<04:54, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.07852798700332642):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:09<04:54, 29.42s/it]   Training Epoch: 6/12, completed (loss: 0.02837657369673252):  94%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 162/172 [1:35:24<04:54, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.02837657369673252):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:38<04:24, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.03640780225396156):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:39<04:24, 29.41s/it]Training Epoch: 6/12, completed (loss: 0.2141614854335785):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 163/172 [1:35:53<04:24, 29.41s/it] Training Epoch: 6/12, completed (loss: 0.2141614854335785):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:08<03:55, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.07546695321798325):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:08<03:55, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.27843794226646423):  95%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 164/172 [1:36:23<03:55, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.27843794226646423):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:37<03:25, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.24471431970596313):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:37<03:25, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.09998182952404022):  96%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 165/172 [1:36:52<03:25, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.09998182952404022):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:07<02:56, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.20366008579730988):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:07<02:56, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.10349778831005096):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 166/172 [1:37:21<02:56, 29.42s/it]Training Epoch: 6/12, completed (loss: 0.10349778831005096):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:36<02:26, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.026921076700091362):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:36<02:26, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.020804429426789284):  97%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 167/172 [1:37:51<02:26, 29.38s/it]Training Epoch: 6/12, completed (loss: 0.020804429426789284):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:05<01:57, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.23358717560768127):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:05<01:57, 29.34s/it] Training Epoch: 6/12, completed (loss: 0.00035711206146515906):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 168/172 [1:38:20<01:57, 29.34s/it]Training Epoch: 6/12, completed (loss: 0.00035711206146515906):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:34<01:27, 29.29s/it]Training Epoch: 6/12, completed (loss: 0.1709228754043579):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:34<01:27, 29.29s/it]    Training Epoch: 6/12, completed (loss: 0.008221982046961784):  98%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 169/172 [1:38:49<01:27, 29.29s/it]Training Epoch: 6/12, completed (loss: 0.008221982046961784):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:39:03<00:58, 29.26s/it]Training Epoch: 6/12, completed (loss: 0.06278384476900101):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:39:04<00:58, 29.26s/it] Training Epoch: 6/12, completed (loss: 0.16232672333717346):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 170/172 [1:39:18<00:58, 29.26s/it]Training Epoch: 6/12, completed (loss: 0.16232672333717346):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:33<00:29, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.13720247149467468):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:33<00:29, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.08418942242860794):  99%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 171/172 [1:39:48<00:29, 29.30s/it]Training Epoch: 6/12, completed (loss: 0.08418942242860794): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:40:02<00:00, 29.32s/it] eval_ppl=tensor(2.0818, device='cuda:0') eval_epoch_loss=tensor(0.7332, device='cuda:0')
Eval epoch loss:  tensor(0.7332, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_6_257
Time while saving:  2023-10-26 03:14:48 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 6, step_id: 343

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:52,  8.01s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.91s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.88s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.87s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:17,  7.91s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.93s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.88s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:53,  7.88s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:45,  7.87s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:18<02:38,  7.90s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:30,  7.94s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.92s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:42<02:15,  7.95s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:50<02:07,  7.97s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.98s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.93s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.93s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:34,  7.91s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.92s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.94s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.94s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.91s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.92s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.94s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.94s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:25<00:31,  7.91s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.95s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.99s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:50<00:07,  7.97s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.95s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.93s/it]
Training Epoch: 6/12, completed (loss: 3.672105549412663e-06): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:44:01<00:00, 29.32s/it]Training Epoch: 6/12, completed (loss: 3.672105549412663e-06): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 172/172 [1:44:01<00:00, 36.29s/it]
 eval_ppl=tensor(2.1849, device='cuda:0') eval_epoch_loss=tensor(0.7816, device='cuda:0')
Eval epoch loss:  tensor(0.7816, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_6_343
Time while saving:  2023-10-26 03:39:50 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
Epoch ending time:  2023-10-26 03:39:50 IST+0530
Validation losses are: 
{'epoch_id': 0, 'ministep_id': 1, 'eval_epoch_loss': tensor(2.6360, device='cuda:0'), 'best_val_loss_yet': tensor(2.6360, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6698, device='cuda:0'), 'best_val_loss_yet': tensor(0.6698, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6023, device='cuda:0'), 'best_val_loss_yet': tensor(0.6023, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5568, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 0, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5643, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5634, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5644, device='cuda:0'), 'best_val_loss_yet': tensor(0.5568, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5524, device='cuda:0'), 'best_val_loss_yet': tensor(0.5524, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5513, device='cuda:0'), 'best_val_loss_yet': tensor(0.5513, device='cuda:0')}
{'epoch_id': 1, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5386, device='cuda:0'), 'best_val_loss_yet': tensor(0.5386, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5370, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5769, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.5758, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5729, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 2, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5558, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5550, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.5881, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6249, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.5809, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 3, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.5733, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.5711, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.6770, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6490, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.6375, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 4, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.6272, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.6215, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.7498, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.6938, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.7075, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 5, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.7203, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 6, 'ministep_id': 1, 'eval_epoch_loss': tensor(0.7151, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 6, 'ministep_id': 87, 'eval_epoch_loss': tensor(0.7710, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 6, 'ministep_id': 173, 'eval_epoch_loss': tensor(0.7237, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 6, 'ministep_id': 257, 'eval_epoch_loss': tensor(0.7332, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
{'epoch_id': 6, 'ministep_id': 343, 'eval_epoch_loss': tensor(0.7816, device='cuda:0'), 'best_val_loss_yet': tensor(0.5370, device='cuda:0')}
$$$%%%^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
Epoch 6: train_perplexity=1.1144, train_epoch_loss=0.1083, epoch time 6241.253795773024s
Epoch starting time:  2023-10-26 03:39:50 IST+0530
NumElems are:  5
Ministeps save_arr:  172 [1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49, 51, 53, 55, 57, 59, 61, 63, 65, 67, 69, 71, 73, 75, 77, 79, 81, 83, 85, 87, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 113, 115, 117, 119, 121, 123, 125, 127, 129, 131, 133, 135, 137, 139, 141, 143, 145, 147, 149, 151, 153, 155, 157, 159, 161, 163, 165, 167, 169, 171, 173, 175, 177, 179, 181, 183, 185, 187, 189, 191, 193, 195, 197, 199, 201, 203, 205, 207, 209, 211, 213, 215, 217, 219, 221, 223, 225, 227, 229, 231, 233, 235, 237, 239, 241, 243, 245, 247, 249, 251, 253, 255, 257, 259, 261, 263, 265, 267, 269, 271, 273, 275, 277, 279, 281, 283, 285, 287, 289, 291, 293, 295, 297, 299, 301, 303, 305, 307, 309, 311, 313, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 337, 339, 341, 343]
Essential ministeps:  5 [1, 257, 343, 87, 173]
Training Epoch: 7:   0%|[34m          [0m| 0/172 [00:00<?, ?it/s]Total ministeps are:  344
grad accumulation steps:  2
Total effective steps in Epoch:  172
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
Training Epoch: 7/12, completed (loss: 0.011884473264217377):   0%|[34m          [0m| 0/172 [00:14<?, ?it/s]Training Epoch: 7/12, completed (loss: 0.011884473264217377):   1%|[34m          [0m| 1/172 [00:29<1:23:29, 29.30s/it]$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 7, step_id: 1

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:08<03:52,  8.02s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:42,  7.95s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:32,  7.86s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.85s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:16,  7.87s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:09,  7.90s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:01,  7.90s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.92s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.91s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.92s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:30,  7.94s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:34<02:22,  7.93s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:15,  7.98s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:51<02:07,  7.98s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:58<01:59,  7.97s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:06<01:51,  7.96s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.95s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.94s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.93s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.94s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.92s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.92s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.95s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.95s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:26<00:31,  7.93s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.95s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.97s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:50<00:07,  7.96s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:58<00:00,  7.93s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:58<00:00,  7.94s/it]
Training Epoch: 7/12, completed (loss: 0.0447818860411644):   1%|[34m          [0m| 1/172 [04:27<1:23:29, 29.30s/it]  Training Epoch: 7/12, completed (loss: 0.023665815591812134):   1%|[34m          [0m| 1/172 [04:42<1:23:29, 29.30s/it]Training Epoch: 7/12, completed (loss: 0.023665815591812134):   1%|[34m          [0m| 2/172 [04:56<8:00:17, 169.52s/it]Training Epoch: 7/12, completed (loss: 0.0994291678071022):   1%|[34m          [0m| 2/172 [04:57<8:00:17, 169.52s/it]  Training Epoch: 7/12, completed (loss: 0.039783306419849396):   1%|[34m          [0m| 2/172 [05:11<8:00:17, 169.52s/it]Training Epoch: 7/12, completed (loss: 0.039783306419849396):   2%|[34mâ–         [0m| 3/172 [05:26<4:57:20, 105.57s/it]Training Epoch: 7/12, completed (loss: 0.1310424953699112):   2%|[34mâ–         [0m| 3/172 [05:26<4:57:20, 105.57s/it]  Training Epoch: 7/12, completed (loss: 0.17667391896247864):   2%|[34mâ–         [0m| 3/172 [05:41<4:57:20, 105.57s/it]Training Epoch: 7/12, completed (loss: 0.17667391896247864):   2%|[34mâ–         [0m| 4/172 [05:55<3:31:12, 75.43s/it] Training Epoch: 7/12, completed (loss: 0.0034889504313468933):   2%|[34mâ–         [0m| 4/172 [05:55<3:31:12, 75.43s/it]Training Epoch: 7/12, completed (loss: 0.13641218841075897):   2%|[34mâ–         [0m| 4/172 [06:10<3:31:12, 75.43s/it]  Training Epoch: 7/12, completed (loss: 0.13641218841075897):   3%|[34mâ–Ž         [0m| 5/172 [06:25<2:43:48, 58.85s/it]Training Epoch: 7/12, completed (loss: 0.3212731182575226):   3%|[34mâ–Ž         [0m| 5/172 [06:25<2:43:48, 58.85s/it] Training Epoch: 7/12, completed (loss: 0.12149432301521301):   3%|[34mâ–Ž         [0m| 5/172 [06:39<2:43:48, 58.85s/it]Training Epoch: 7/12, completed (loss: 0.12149432301521301):   3%|[34mâ–Ž         [0m| 6/172 [06:54<2:14:56, 48.77s/it]Training Epoch: 7/12, completed (loss: 6.694367039017379e-05):   3%|[34mâ–Ž         [0m| 6/172 [06:54<2:14:56, 48.77s/it]Training Epoch: 7/12, completed (loss: 0.15097416937351227):   3%|[34mâ–Ž         [0m| 6/172 [07:09<2:14:56, 48.77s/it]  Training Epoch: 7/12, completed (loss: 0.15097416937351227):   4%|[34mâ–         [0m| 7/172 [07:23<1:56:48, 42.48s/it]Training Epoch: 7/12, completed (loss: 0.02242329902946949):   4%|[34mâ–         [0m| 7/172 [07:24<1:56:48, 42.48s/it]Training Epoch: 7/12, completed (loss: 0.12969066202640533):   4%|[34mâ–         [0m| 7/172 [07:38<1:56:48, 42.48s/it]Training Epoch: 7/12, completed (loss: 0.12969066202640533):   5%|[34mâ–         [0m| 8/172 [07:53<1:44:45, 38.32s/it]Training Epoch: 7/12, completed (loss: 0.1108439490199089):   5%|[34mâ–         [0m| 8/172 [07:53<1:44:45, 38.32s/it] Training Epoch: 7/12, completed (loss: 0.27178117632865906):   5%|[34mâ–         [0m| 8/172 [08:08<1:44:45, 38.32s/it]Training Epoch: 7/12, completed (loss: 0.27178117632865906):   5%|[34mâ–Œ         [0m| 9/172 [08:22<1:36:41, 35.59s/it]Training Epoch: 7/12, completed (loss: 0.07345108687877655):   5%|[34mâ–Œ         [0m| 9/172 [08:23<1:36:41, 35.59s/it]Training Epoch: 7/12, completed (loss: 0.03342605382204056):   5%|[34mâ–Œ         [0m| 9/172 [08:37<1:36:41, 35.59s/it]Training Epoch: 7/12, completed (loss: 0.03342605382204056):   6%|[34mâ–Œ         [0m| 10/172 [08:52<1:30:43, 33.60s/it]Training Epoch: 7/12, completed (loss: 0.18531434237957):   6%|[34mâ–Œ         [0m| 10/172 [08:52<1:30:43, 33.60s/it]   Training Epoch: 7/12, completed (loss: 0.07290761917829514):   6%|[34mâ–Œ         [0m| 10/172 [09:06<1:30:43, 33.60s/it]Training Epoch: 7/12, completed (loss: 0.07290761917829514):   6%|[34mâ–‹         [0m| 11/172 [09:21<1:26:39, 32.29s/it]Training Epoch: 7/12, completed (loss: 0.07635805755853653):   6%|[34mâ–‹         [0m| 11/172 [09:21<1:26:39, 32.29s/it]Training Epoch: 7/12, completed (loss: 0.20101310312747955):   6%|[34mâ–‹         [0m| 11/172 [09:36<1:26:39, 32.29s/it]Training Epoch: 7/12, completed (loss: 0.20101310312747955):   7%|[34mâ–‹         [0m| 12/172 [09:50<1:23:39, 31.37s/it]Training Epoch: 7/12, completed (loss: 0.012695297598838806):   7%|[34mâ–‹         [0m| 12/172 [09:50<1:23:39, 31.37s/it]Training Epoch: 7/12, completed (loss: 0.0008008588338270783):   7%|[34mâ–‹         [0m| 12/172 [10:05<1:23:39, 31.37s/it]Training Epoch: 7/12, completed (loss: 0.0008008588338270783):   8%|[34mâ–Š         [0m| 13/172 [10:19<1:21:26, 30.74s/it]Training Epoch: 7/12, completed (loss: 0.00225715315900743):   8%|[34mâ–Š         [0m| 13/172 [10:20<1:21:26, 30.74s/it]  Training Epoch: 7/12, completed (loss: 0.15320418775081635):   8%|[34mâ–Š         [0m| 13/172 [10:34<1:21:26, 30.74s/it]Training Epoch: 7/12, completed (loss: 0.15320418775081635):   8%|[34mâ–Š         [0m| 14/172 [10:49<1:19:53, 30.34s/it]Training Epoch: 7/12, completed (loss: 0.19483043253421783):   8%|[34mâ–Š         [0m| 14/172 [10:49<1:19:53, 30.34s/it]Training Epoch: 7/12, completed (loss: 0.010776292532682419):   8%|[34mâ–Š         [0m| 14/172 [11:04<1:19:53, 30.34s/it]Training Epoch: 7/12, completed (loss: 0.010776292532682419):   9%|[34mâ–Š         [0m| 15/172 [11:18<1:18:34, 30.03s/it]Training Epoch: 7/12, completed (loss: 0.049286022782325745):   9%|[34mâ–Š         [0m| 15/172 [11:18<1:18:34, 30.03s/it]Training Epoch: 7/12, completed (loss: 0.0014149777125567198):   9%|[34mâ–Š         [0m| 15/172 [11:33<1:18:34, 30.03s/it]Training Epoch: 7/12, completed (loss: 0.0014149777125567198):   9%|[34mâ–‰         [0m| 16/172 [11:48<1:17:38, 29.86s/it]Training Epoch: 7/12, completed (loss: 0.05684769153594971):   9%|[34mâ–‰         [0m| 16/172 [11:48<1:17:38, 29.86s/it]  Training Epoch: 7/12, completed (loss: 0.1771899312734604):   9%|[34mâ–‰         [0m| 16/172 [12:02<1:17:38, 29.86s/it] Training Epoch: 7/12, completed (loss: 0.1771899312734604):  10%|[34mâ–‰         [0m| 17/172 [12:17<1:16:49, 29.74s/it]Training Epoch: 7/12, completed (loss: 0.08060220628976822):  10%|[34mâ–‰         [0m| 17/172 [12:17<1:16:49, 29.74s/it]Training Epoch: 7/12, completed (loss: 0.07622604072093964):  10%|[34mâ–‰         [0m| 17/172 [12:32<1:16:49, 29.74s/it]Training Epoch: 7/12, completed (loss: 0.07622604072093964):  10%|[34mâ–ˆ         [0m| 18/172 [12:46<1:15:56, 29.59s/it]Training Epoch: 7/12, completed (loss: 0.2145124226808548):  10%|[34mâ–ˆ         [0m| 18/172 [12:46<1:15:56, 29.59s/it] Training Epoch: 7/12, completed (loss: 0.10197609663009644):  10%|[34mâ–ˆ         [0m| 18/172 [13:01<1:15:56, 29.59s/it]Training Epoch: 7/12, completed (loss: 0.10197609663009644):  11%|[34mâ–ˆ         [0m| 19/172 [13:16<1:15:17, 29.52s/it]Training Epoch: 7/12, completed (loss: 0.016881855204701424):  11%|[34mâ–ˆ         [0m| 19/172 [13:16<1:15:17, 29.52s/it]Training Epoch: 7/12, completed (loss: 0.15761685371398926):  11%|[34mâ–ˆ         [0m| 19/172 [13:31<1:15:17, 29.52s/it] Training Epoch: 7/12, completed (loss: 0.15761685371398926):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:45<1:14:35, 29.45s/it]Training Epoch: 7/12, completed (loss: 0.0007313078385777771):  12%|[34mâ–ˆâ–        [0m| 20/172 [13:45<1:14:35, 29.45s/it]Training Epoch: 7/12, completed (loss: 0.02641277387738228):  12%|[34mâ–ˆâ–        [0m| 20/172 [14:00<1:14:35, 29.45s/it]  Training Epoch: 7/12, completed (loss: 0.02641277387738228):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:14<1:14:03, 29.43s/it]Training Epoch: 7/12, completed (loss: 0.006697647739201784):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:14<1:14:03, 29.43s/it]Training Epoch: 7/12, completed (loss: 0.0005146358162164688):  12%|[34mâ–ˆâ–        [0m| 21/172 [14:29<1:14:03, 29.43s/it]Training Epoch: 7/12, completed (loss: 0.0005146358162164688):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:44<1:13:35, 29.44s/it]Training Epoch: 7/12, completed (loss: 0.06739923357963562):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:44<1:13:35, 29.44s/it]  Training Epoch: 7/12, completed (loss: 0.23195432126522064):  13%|[34mâ–ˆâ–Ž        [0m| 22/172 [14:59<1:13:35, 29.44s/it]Training Epoch: 7/12, completed (loss: 0.23195432126522064):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:13<1:13:08, 29.46s/it]Training Epoch: 7/12, completed (loss: 0.035298410803079605):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:13<1:13:08, 29.46s/it]Training Epoch: 7/12, completed (loss: 0.2168760746717453):  13%|[34mâ–ˆâ–Ž        [0m| 23/172 [15:28<1:13:08, 29.46s/it]  Training Epoch: 7/12, completed (loss: 0.2168760746717453):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:43<1:12:38, 29.45s/it]Training Epoch: 7/12, completed (loss: 0.23653265833854675):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:43<1:12:38, 29.45s/it]Training Epoch: 7/12, completed (loss: 0.001238534925505519):  14%|[34mâ–ˆâ–        [0m| 24/172 [15:58<1:12:38, 29.45s/it]Training Epoch: 7/12, completed (loss: 0.001238534925505519):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:12<1:12:03, 29.41s/it]Training Epoch: 7/12, completed (loss: 0.0035486717242747545):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:12<1:12:03, 29.41s/it]Training Epoch: 7/12, completed (loss: 0.11173687875270844):  15%|[34mâ–ˆâ–        [0m| 25/172 [16:27<1:12:03, 29.41s/it]  Training Epoch: 7/12, completed (loss: 0.11173687875270844):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:41<1:11:30, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.18265336751937866):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:42<1:11:30, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.09538664668798447):  15%|[34mâ–ˆâ–Œ        [0m| 26/172 [16:56<1:11:30, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.09538664668798447):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:11<1:10:58, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.05700399726629257):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:11<1:10:58, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.08789671957492828):  16%|[34mâ–ˆâ–Œ        [0m| 27/172 [17:26<1:10:58, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.08789671957492828):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:40<1:10:29, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.0006439023418352008):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:40<1:10:29, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.29599255323410034):  16%|[34mâ–ˆâ–‹        [0m| 28/172 [17:55<1:10:29, 29.37s/it]  Training Epoch: 7/12, completed (loss: 0.29599255323410034):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:09<1:09:59, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.051715508103370667):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:10<1:09:59, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.1876019686460495):  17%|[34mâ–ˆâ–‹        [0m| 29/172 [18:24<1:09:59, 29.37s/it]  Training Epoch: 7/12, completed (loss: 0.1876019686460495):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:39<1:09:28, 29.36s/it]Training Epoch: 7/12, completed (loss: 0.3316415846347809):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:39<1:09:28, 29.36s/it]Training Epoch: 7/12, completed (loss: 0.0008877306827344):  17%|[34mâ–ˆâ–‹        [0m| 30/172 [18:54<1:09:28, 29.36s/it]Training Epoch: 7/12, completed (loss: 0.0008877306827344):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:08<1:09:00, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.005657140631228685):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:08<1:09:00, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.06949111074209213):  18%|[34mâ–ˆâ–Š        [0m| 31/172 [19:23<1:09:00, 29.37s/it] Training Epoch: 7/12, completed (loss: 0.06949111074209213):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:38<1:08:33, 29.38s/it]Training Epoch: 7/12, completed (loss: 0.012207160703837872):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:38<1:08:33, 29.38s/it]Training Epoch: 7/12, completed (loss: 0.12298913300037384):  19%|[34mâ–ˆâ–Š        [0m| 32/172 [19:52<1:08:33, 29.38s/it] Training Epoch: 7/12, completed (loss: 0.12298913300037384):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:07<1:07:59, 29.35s/it]Training Epoch: 7/12, completed (loss: 0.09683899581432343):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:07<1:07:59, 29.35s/it]Training Epoch: 7/12, completed (loss: 0.11701700091362):  19%|[34mâ–ˆâ–‰        [0m| 33/172 [20:22<1:07:59, 29.35s/it]   Training Epoch: 7/12, completed (loss: 0.11701700091362):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:36<1:07:31, 29.36s/it]Training Epoch: 7/12, completed (loss: 0.12127915024757385):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:36<1:07:31, 29.36s/it]Training Epoch: 7/12, completed (loss: 0.02040429227054119):  20%|[34mâ–ˆâ–‰        [0m| 34/172 [20:51<1:07:31, 29.36s/it]Training Epoch: 7/12, completed (loss: 0.02040429227054119):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:06<1:07:02, 29.36s/it]Training Epoch: 7/12, completed (loss: 8.491344487993047e-05):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:06<1:07:02, 29.36s/it]Training Epoch: 7/12, completed (loss: 0.07131961733102798):  20%|[34mâ–ˆâ–ˆ        [0m| 35/172 [21:21<1:07:02, 29.36s/it]  Training Epoch: 7/12, completed (loss: 0.07131961733102798):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:35<1:06:36, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.025432316586375237):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:35<1:06:36, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.00027917366242036223):  21%|[34mâ–ˆâ–ˆ        [0m| 36/172 [21:50<1:06:36, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.00027917366242036223):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:04<1:06:07, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.001928176498040557):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:05<1:06:07, 29.39s/it]  Training Epoch: 7/12, completed (loss: 0.017401212826371193):  22%|[34mâ–ˆâ–ˆâ–       [0m| 37/172 [22:19<1:06:07, 29.39s/it]Training Epoch: 7/12, completed (loss: 0.017401212826371193):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:34<1:05:30, 29.33s/it]Training Epoch: 7/12, completed (loss: 4.776395144290291e-06):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:34<1:05:30, 29.33s/it]Training Epoch: 7/12, completed (loss: 0.31136423349380493):  22%|[34mâ–ˆâ–ˆâ–       [0m| 38/172 [22:49<1:05:30, 29.33s/it]  Training Epoch: 7/12, completed (loss: 0.31136423349380493):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:03<1:05:02, 29.34s/it]Training Epoch: 7/12, completed (loss: 0.018016142770648003):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:03<1:05:02, 29.34s/it]Training Epoch: 7/12, completed (loss: 0.08987126499414444):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 39/172 [23:18<1:05:02, 29.34s/it] Training Epoch: 7/12, completed (loss: 0.08987126499414444):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:32<1:04:31, 29.33s/it]Training Epoch: 7/12, completed (loss: 0.037426289170980453):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:32<1:04:31, 29.33s/it]Training Epoch: 7/12, completed (loss: 0.055424924939870834):  23%|[34mâ–ˆâ–ˆâ–Ž       [0m| 40/172 [23:47<1:04:31, 29.33s/it]Training Epoch: 7/12, completed (loss: 0.055424924939870834):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:02<1:04:07, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.04546890780329704):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:02<1:04:07, 29.37s/it] Training Epoch: 7/12, completed (loss: 0.0003471570380497724):  24%|[34mâ–ˆâ–ˆâ–       [0m| 41/172 [24:17<1:04:07, 29.37s/it]Training Epoch: 7/12, completed (loss: 0.0003471570380497724):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:31<1:03:42, 29.40s/it]Training Epoch: 7/12, completed (loss: 0.01362160686403513):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:31<1:03:42, 29.40s/it]  Training Epoch: 7/12, completed (loss: 0.0364314541220665):  24%|[34mâ–ˆâ–ˆâ–       [0m| 42/172 [24:46<1:03:42, 29.40s/it] Training Epoch: 7/12, completed (loss: 0.0364314541220665):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:01<1:03:12, 29.40s/it]Training Epoch: 7/12, completed (loss: 0.026581117883324623):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:01<1:03:12, 29.40s/it]Training Epoch: 7/12, completed (loss: 0.17116831243038177):  25%|[34mâ–ˆâ–ˆâ–Œ       [0m| 43/172 [25:15<1:03:12, 29.40s/it] Training Epoch: 7/12, completed (loss: 0.17116831243038177):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [25:30<1:02:39, 29.37s/it] eval_ppl=tensor(2.1933, device='cuda:0') eval_epoch_loss=tensor(0.7854, device='cuda:0')
Eval epoch loss:  tensor(0.7854, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_7_1
Time while saving:  2023-10-26 03:44:18 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
$$$$$$ EVALUATING $$$$$$
Evaluating on epoch_id 7, step_id: 87

evaluating Epoch:   0%|[32m          [0m| 0/30 [00:00<?, ?it/s][Ahuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)

evaluating Epoch:   3%|[32mâ–Ž         [0m| 1/30 [00:07<03:50,  7.94s/it][A
evaluating Epoch:   7%|[32mâ–‹         [0m| 2/30 [00:15<03:41,  7.90s/it][A
evaluating Epoch:  10%|[32mâ–ˆ         [0m| 3/30 [00:23<03:31,  7.84s/it][A
evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 4/30 [00:31<03:24,  7.85s/it][A
evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 5/30 [00:39<03:19,  7.96s/it][A
evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 6/30 [00:47<03:10,  7.93s/it][A
evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 7/30 [00:55<03:03,  7.97s/it][A
evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 8/30 [01:03<02:54,  7.95s/it][A
evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 9/30 [01:11<02:46,  7.94s/it][A
evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 10/30 [01:19<02:38,  7.95s/it][A
evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 11/30 [01:27<02:31,  7.96s/it][A
evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 12/30 [01:35<02:23,  7.95s/it][A
evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 13/30 [01:43<02:15,  7.98s/it][A
evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 14/30 [01:51<02:07,  7.98s/it][A
evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 15/30 [01:59<01:59,  7.96s/it][A
evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 16/30 [02:07<01:51,  7.95s/it][A
evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 17/30 [02:14<01:43,  7.94s/it][A
evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 18/30 [02:22<01:35,  7.92s/it][A
evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 19/30 [02:30<01:27,  7.94s/it][A
evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 20/30 [02:38<01:19,  7.95s/it][A
evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 21/30 [02:46<01:11,  7.94s/it][A
evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 22/30 [02:54<01:03,  7.92s/it][A
evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 23/30 [03:02<00:55,  7.91s/it][A
evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 24/30 [03:10<00:47,  7.92s/it][A
evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 25/30 [03:18<00:39,  7.91s/it][A
evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 26/30 [03:26<00:31,  7.90s/it][A
evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 27/30 [03:34<00:23,  7.92s/it][A
evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 28/30 [03:42<00:15,  7.94s/it][A
evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 29/30 [03:50<00:07,  7.92s/it][A
evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:57<00:00,  7.92s/it][Aevaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 30/30 [03:58<00:00,  7.93s/it]
Training Epoch: 7/12, completed (loss: 0.0665990561246872):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:28<1:02:39, 29.37s/it]  eval_ppl=tensor(2.3527, device='cuda:0') eval_epoch_loss=tensor(0.8556, device='cuda:0')
Eval epoch loss:  tensor(0.8556, device='cuda:0') | best_val_loss:  tensor(0.5370, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72/epoch_7_87
Time while saving:  2023-10-26 04:09:19 IST+0530
PEFT modules are saved in ./models_saved/32_16_2a14e64a-04ba-401a-b35a-9ed575f46c72 directory
$$$$$$ EVALUATION DONE $$$$$$
Traceback (most recent call last):
  File "train.py", line 93, in <module>
    main()
  File "train.py", line 77, in main
    finetuning(**kwargs)
  File "/home/t-agarwalan/Desktop/nips_effeciency_challenge/EfficiencyChallenge/code/00_starter_repo/neurips_llm_efficiency_challenge/sample-submissions/llama_recipes/llama_recipes_external_code/src/llama_recipes/finetuning.py", line 276, in main
    results = train(
  File "/home/t-agarwalan/Desktop/nips_effeciency_challenge/EfficiencyChallenge/code/00_starter_repo/neurips_llm_efficiency_challenge/sample-submissions/llama_recipes/llama_recipes_external_code/src/llama_recipes/utils/train_utils.py", line 307, in train
Traceback (most recent call last):
  File "/anaconda/envs/wizard_coder_inference/lib/python3.8/multiprocessing/queues.py", line 245, in _feed
    send_bytes(obj)
  File "/anaconda/envs/wizard_coder_inference/lib/python3.8/multiprocessing/connection.py", line 200, in send_bytes
    self._send_bytes(m[offset:offset + size])
  File "/anaconda/envs/wizard_coder_inference/lib/python3.8/multiprocessing/connection.py", line 411, in _send_bytes
    self._send(header + buf)
  File "/anaconda/envs/wizard_coder_inference/lib/python3.8/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
    loss.backward()
  File "/anaconda/envs/wizard_coder_inference/lib/python3.8/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/anaconda/envs/wizard_coder_inference/lib/python3.8/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Training Epoch: 7/12, completed (loss: 0.0665990561246872):  26%|[34mâ–ˆâ–ˆâ–Œ       [0m| 44/172 [29:43<1:26:28, 40.53s/it]