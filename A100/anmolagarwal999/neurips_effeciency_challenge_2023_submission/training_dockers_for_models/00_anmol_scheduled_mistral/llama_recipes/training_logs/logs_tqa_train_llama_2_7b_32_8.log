2023-10-22 18:28:58.347260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
Starting time is:  2023-10-23 06:58:59 IST+0530
RANDOM STRING is:  8f6b78de-c452-4f3f-a312-810f90528827
REPO DECIDED is:  anmolagarwal999/nips_challenge_8f6b78de-c452-4f3f-a312-810f90528827
Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.
Token is valid (permission: write).
Your token has been saved to /home/anmol/.cache/huggingface/token
Login successful
Total gradient accumulation steps are:  4
OUTPUT dir is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827
KWARGS sent to main() are:  {'model_name': 'meta-llama/Llama-2-7b-hf', 'use_peft': True, 'peft_method': 'lora', 'quantization': True, 'batch_size_training': 8, 'gradient_accumulation_steps': 4, 'dataset': 'custom_dataset', 'custom_dataset.file': './train.py:get_anmol_dataset', 'output_dir': './models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827'}
Inside update config file
Inside update config file
Inside update config file
Anmol: The final config after all the updations is:  <class 'llama_recipes.configs.training.train_config'>
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:01<00:01,  1.46s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.04it/s]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:02<00:00,  1.04s/it]
/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/peft/utils/other.py:133: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.
  warnings.warn(
/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/torch/cuda/memory.py:329: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.
  warnings.warn(
--> Model meta-llama/Llama-2-7b-hf

--> meta-llama/Llama-2-7b-hf has 262.41024 Million params

Inside update config file
trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199
Inside update config file
Dataset config is:  custom_dataset(dataset='custom_dataset', file='./train.py:get_anmol_dataset', train_split='train', test_split='validation')
Starting time is:  2023-10-23 06:59:10 IST+0530
RANDOM STRING is:  e5e1f1a6-9d3d-4ff7-acfa-49bd49bb473d
REPO DECIDED is:  anmolagarwal999/nips_challenge_e5e1f1a6-9d3d-4ff7-acfa-49bd49bb473d
Ending time is:  2023-10-23 06:59:10 IST+0530
INSIDE INIT FUNCTION for partition:  train
TRAIN PATH is:  /home/anmol/nips_challenge/efficiency_challenge_repo/data/training_datasets/tqa_train_dataset.json
Initial len is:  163
Final len is:  163
MAX WORDS in dataset is:  259
--> Training Set Length = 163
Starting time is:  2023-10-23 06:59:10 IST+0530
RANDOM STRING is:  49f2bd97-20f9-423e-9e32-5928f7044bdb
REPO DECIDED is:  anmolagarwal999/nips_challenge_49f2bd97-20f9-423e-9e32-5928f7044bdb
Ending time is:  2023-10-23 06:59:10 IST+0530
INSIDE INIT FUNCTION for partition:  validation
Validation PATH is:  /home/anmol/nips_challenge/efficiency_challenge_repo/data/training_datasets/tqa_valid_dataset.json
Initial len is:  100
Final len is:  100
MAX WORDS in dataset is:  203
--> Validation Set Length = 100
Training config is:  <class 'llama_recipes.configs.training.train_config'>
Epoch starting time:  2023-10-23 06:59:10 IST+0530
Training Epoch: 1:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/home/anmol/anaconda3/envs/wizard_coder/lib/python3.8/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization
  warnings.warn(f"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization")
Training Epoch: 1/10, step 0/20 completed (loss: 1.492862582206726):   0%|[34m          [0m| 0/5 [00:05<?, ?it/s]Training Epoch: 1/10, step 1/20 completed (loss: 1.5396969318389893):   0%|[34m          [0m| 0/5 [00:08<?, ?it/s]Training Epoch: 1/10, step 2/20 completed (loss: 1.5006027221679688):   0%|[34m          [0m| 0/5 [00:11<?, ?it/s]Training Epoch: 1/10, step 2/20 completed (loss: 1.5006027221679688):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:14<00:58, 14.67s/it]Training Epoch: 1/10, step 3/20 completed (loss: 1.4793918132781982):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:14<00:58, 14.67s/it]Training Epoch: 1/10, step 4/20 completed (loss: 1.3745131492614746):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:17<00:58, 14.67s/it]Training Epoch: 1/10, step 5/20 completed (loss: 1.3547706604003906):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:21<00:58, 14.67s/it]Training Epoch: 1/10, step 6/20 completed (loss: 1.3507508039474487):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:24<00:58, 14.67s/it]Training Epoch: 1/10, step 6/20 completed (loss: 1.3507508039474487):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:27<00:40, 13.61s/it]Training Epoch: 1/10, step 7/20 completed (loss: 1.4389009475708008):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:27<00:40, 13.61s/it]Training Epoch: 1/10, step 8/20 completed (loss: 1.185352087020874):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:30<00:40, 13.61s/it] Training Epoch: 1/10, step 9/20 completed (loss: 1.1219621896743774):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:34<00:40, 13.61s/it]Training Epoch: 1/10, step 10/20 completed (loss: 1.1046034097671509):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:37<00:40, 13.61s/it]Training Epoch: 1/10, step 10/20 completed (loss: 1.1046034097671509):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:40<00:26, 13.30s/it]Training Epoch: 1/10, step 11/20 completed (loss: 1.0897916555404663):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:40<00:26, 13.30s/it]Training Epoch: 1/10, step 12/20 completed (loss: 0.985830545425415):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:43<00:26, 13.30s/it] Training Epoch: 1/10, step 13/20 completed (loss: 1.0623294115066528):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:46<00:26, 13.30s/it]Training Epoch: 1/10, step 14/20 completed (loss: 0.9531856775283813):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:50<00:26, 13.30s/it]Training Epoch: 1/10, step 14/20 completed (loss: 0.9531856775283813):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:53<00:13, 13.17s/it]Training Epoch: 1/10, step 15/20 completed (loss: 1.0883307456970215):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:53<00:13, 13.17s/it]Training Epoch: 1/10, step 16/20 completed (loss: 0.8662993907928467):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:56<00:13, 13.17s/it]Training Epoch: 1/10, step 17/20 completed (loss: 0.7994734644889832):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:59<00:13, 13.17s/it]Training Epoch: 1/10, step 18/20 completed (loss: 0.8391492962837219):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:03<00:13, 13.17s/it]Training Epoch: 1/10, step 18/20 completed (loss: 0.8391492962837219): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:06<00:00, 13.08s/it]Training Epoch: 1/10, step 19/20 completed (loss: 0.7731260657310486): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:06<00:00, 13.08s/it]Training Epoch: 1/10, step 19/20 completed (loss: 0.7731260657310486): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:06<00:00, 13.30s/it]
Epoch ending time:  2023-10-23 07:00:17 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 7 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:56,  1.76it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:01<00:49,  1.98it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:46,  2.09it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:44,  2.18it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:43,  2.20it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:42,  2.21it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:41,  2.24it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:40,  2.27it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:04<00:39,  2.28it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:39,  2.27it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:38,  2.30it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:38,  2.31it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:37,  2.31it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:37,  2.29it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:36,  2.33it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:07<00:36,  2.33it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:35,  2.33it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:34,  2.36it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:34,  2.37it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:34,  2.35it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:33,  2.34it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:33,  2.34it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:10<00:32,  2.36it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:32,  2.36it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:31,  2.37it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.37it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:30,  2.36it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:12<00:30,  2.39it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:30,  2.36it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:13<00:29,  2.39it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:28,  2.39it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:28,  2.39it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:27,  2.40it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:27,  2.36it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:15<00:27,  2.34it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.30it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:16<00:27,  2.30it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.30it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:26,  2.29it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:25,  2.31it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.32it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:18<00:24,  2.32it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:24,  2.36it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:19<00:23,  2.35it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:23,  2.36it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:19<00:22,  2.37it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:20<00:22,  2.38it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:21,  2.42it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:21<00:21,  2.41it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:20,  2.38it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:21<00:20,  2.37it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:22<00:20,  2.34it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:22<00:20,  2.34it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:23<00:19,  2.31it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:19,  2.33it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:24<00:19,  2.30it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:18,  2.33it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:24<00:17,  2.38it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:25<00:17,  2.41it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:25<00:16,  2.40it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:26<00:16,  2.37it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:16,  2.34it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:27<00:15,  2.36it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:15,  2.35it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:27<00:14,  2.34it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:28<00:14,  2.33it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:28<00:14,  2.29it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:29<00:13,  2.30it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:29<00:13,  2.35it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:30<00:12,  2.36it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:30<00:12,  2.38it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:30<00:11,  2.39it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:31<00:11,  2.39it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:31<00:10,  2.39it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:32<00:10,  2.39it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:32<00:10,  2.39it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:32<00:09,  2.39it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:33<00:09,  2.38it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:33<00:08,  2.38it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:34<00:08,  2.36it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:34<00:07,  2.39it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:35<00:07,  2.40it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:35<00:07,  2.41it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:35<00:06,  2.38it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:36<00:06,  2.38it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:36<00:05,  2.39it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:37<00:05,  2.39it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:37<00:04,  2.40it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:38<00:04,  2.39it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:38<00:04,  2.39it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:38<00:03,  2.40it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:39<00:03,  2.41it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:39<00:02,  2.41it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:40<00:02,  2.40it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:40<00:02,  2.44it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:40<00:01,  2.43it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:41<00:01,  2.42it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:41<00:00,  2.44it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:42<00:00,  2.45it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.43it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.34it/s]
LOSS is:  tensor(2.3549, device='cuda:0')
LOSS is:  tensor(4.1725, device='cuda:0')
LOSS is:  tensor(2.5900, device='cuda:0')
LOSS is:  tensor(1.9467, device='cuda:0')
LOSS is:  tensor(2.9757, device='cuda:0')
LOSS is:  tensor(2.7871, device='cuda:0')
LOSS is:  tensor(2.5621, device='cuda:0')
LOSS is:  tensor(2.3770, device='cuda:0')
LOSS is:  tensor(2.9378, device='cuda:0')
LOSS is:  tensor(2.6150, device='cuda:0')
LOSS is:  tensor(2.2830, device='cuda:0')
LOSS is:  tensor(2.6480, device='cuda:0')
LOSS is:  tensor(2.2915, device='cuda:0')
LOSS is:  tensor(2.3601, device='cuda:0')
LOSS is:  tensor(2.4101, device='cuda:0')
LOSS is:  tensor(2.4808, device='cuda:0')
LOSS is:  tensor(2.7935, device='cuda:0')
LOSS is:  tensor(2.1241, device='cuda:0')
LOSS is:  tensor(2.4180, device='cuda:0')
LOSS is:  tensor(2.3834, device='cuda:0')
LOSS is:  tensor(2.6442, device='cuda:0')
LOSS is:  tensor(2.7004, device='cuda:0')
LOSS is:  tensor(1.9759, device='cuda:0')
LOSS is:  tensor(1.9681, device='cuda:0')
LOSS is:  tensor(2.0338, device='cuda:0')
LOSS is:  tensor(1.8819, device='cuda:0')
LOSS is:  tensor(1.9852, device='cuda:0')
LOSS is:  tensor(2.4803, device='cuda:0')
LOSS is:  tensor(2.4482, device='cuda:0')
LOSS is:  tensor(2.5893, device='cuda:0')
LOSS is:  tensor(2.9367, device='cuda:0')
LOSS is:  tensor(2.5392, device='cuda:0')
LOSS is:  tensor(2.6015, device='cuda:0')
LOSS is:  tensor(1.9682, device='cuda:0')
LOSS is:  tensor(2.7527, device='cuda:0')
LOSS is:  tensor(2.1699, device='cuda:0')
LOSS is:  tensor(2.4927, device='cuda:0')
LOSS is:  tensor(2.2165, device='cuda:0')
LOSS is:  tensor(3.4053, device='cuda:0')
LOSS is:  tensor(2.5510, device='cuda:0')
LOSS is:  tensor(2.5805, device='cuda:0')
LOSS is:  tensor(2.5367, device='cuda:0')
LOSS is:  tensor(2.7800, device='cuda:0')
LOSS is:  tensor(2.6287, device='cuda:0')
LOSS is:  tensor(2.7079, device='cuda:0')
LOSS is:  tensor(2.7573, device='cuda:0')
LOSS is:  tensor(2.6784, device='cuda:0')
LOSS is:  tensor(3.3802, device='cuda:0')
LOSS is:  tensor(2.6998, device='cuda:0')
LOSS is:  tensor(2.2183, device='cuda:0')
LOSS is:  tensor(2.0604, device='cuda:0')
LOSS is:  tensor(3.3602, device='cuda:0')
LOSS is:  tensor(2.4021, device='cuda:0')
LOSS is:  tensor(3.1821, device='cuda:0')
LOSS is:  tensor(2.4822, device='cuda:0')
LOSS is:  tensor(2.4827, device='cuda:0')
LOSS is:  tensor(2.8065, device='cuda:0')
LOSS is:  tensor(2.4552, device='cuda:0')
LOSS is:  tensor(3.1742, device='cuda:0')
LOSS is:  tensor(2.7202, device='cuda:0')
LOSS is:  tensor(2.3668, device='cuda:0')
LOSS is:  tensor(3.0822, device='cuda:0')
LOSS is:  tensor(2.7711, device='cuda:0')
LOSS is:  tensor(2.8131, device='cuda:0')
LOSS is:  tensor(3.7190, device='cuda:0')
LOSS is:  tensor(2.3698, device='cuda:0')
LOSS is:  tensor(2.5784, device='cuda:0')
LOSS is:  tensor(2.6030, device='cuda:0')
LOSS is:  tensor(2.7345, device='cuda:0')
LOSS is:  tensor(2.4567, device='cuda:0')
LOSS is:  tensor(2.4755, device='cuda:0')
LOSS is:  tensor(2.5664, device='cuda:0')
LOSS is:  tensor(2.9962, device='cuda:0')
LOSS is:  tensor(2.5564, device='cuda:0')
LOSS is:  tensor(2.0630, device='cuda:0')
LOSS is:  tensor(1.8192, device='cuda:0')
LOSS is:  tensor(2.7542, device='cuda:0')
LOSS is:  tensor(2.5314, device='cuda:0')
LOSS is:  tensor(2.4571, device='cuda:0')
LOSS is:  tensor(2.4111, device='cuda:0')
LOSS is:  tensor(2.9050, device='cuda:0')
LOSS is:  tensor(2.6417, device='cuda:0')
LOSS is:  tensor(2.8764, device='cuda:0')
LOSS is:  tensor(2.1415, device='cuda:0')
LOSS is:  tensor(1.8921, device='cuda:0')
LOSS is:  tensor(2.8894, device='cuda:0')
LOSS is:  tensor(2.6687, device='cuda:0')
LOSS is:  tensor(2.5642, device='cuda:0')
LOSS is:  tensor(2.5063, device='cuda:0')
LOSS is:  tensor(2.6101, device='cuda:0')
LOSS is:  tensor(2.7966, device='cuda:0')
LOSS is:  tensor(2.8572, device='cuda:0')
LOSS is:  tensor(2.5245, device='cuda:0')
LOSS is:  tensor(2.3320, device='cuda:0')
LOSS is:  tensor(3.0024, device='cuda:0')
LOSS is:  tensor(2.2653, device='cuda:0')
LOSS is:  tensor(2.4950, device='cuda:0')
LOSS is:  tensor(2.2388, device='cuda:0')
LOSS is:  tensor(2.2825, device='cuda:0')
LOSS is:  tensor(2.6214, device='cuda:0')
 eval_ppl=tensor(13.0897, device='cuda:0') eval_epoch_loss=tensor(2.5718, device='cuda:0')
Eval epoch loss:  tensor(2.5718, device='cuda:0') | best_val_loss:  inf
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_0
Time while saving:  2023-10-23 07:01:00 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 1 is 2.571824073791504
Epoch 1: train_perplexity=3.2221, train_epoch_loss=1.1700, epoch time 66.92566597601399s
Epoch starting time:  2023-10-23 07:01:00 IST+0530
Training Epoch: 2:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 2/10, step 0/20 completed (loss: 0.715728223323822):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 2/10, step 1/20 completed (loss: 0.6058470010757446):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s]Training Epoch: 2/10, step 2/20 completed (loss: 0.6159538626670837):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 2/10, step 2/20 completed (loss: 0.6159538626670837):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.01s/it]Training Epoch: 2/10, step 3/20 completed (loss: 0.622931182384491):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.01s/it] Training Epoch: 2/10, step 4/20 completed (loss: 0.5535222887992859):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.01s/it]Training Epoch: 2/10, step 5/20 completed (loss: 0.485622763633728):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.01s/it] Training Epoch: 2/10, step 6/20 completed (loss: 0.5080621838569641):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.01s/it]Training Epoch: 2/10, step 6/20 completed (loss: 0.5080621838569641):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:25<00:38, 12.98s/it]Training Epoch: 2/10, step 7/20 completed (loss: 0.5472216010093689):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:38, 12.98s/it]Training Epoch: 2/10, step 8/20 completed (loss: 0.46181800961494446):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:38, 12.98s/it]Training Epoch: 2/10, step 9/20 completed (loss: 0.42012321949005127):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:38, 12.98s/it]Training Epoch: 2/10, step 10/20 completed (loss: 0.3939843773841858):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:35<00:38, 12.98s/it]Training Epoch: 2/10, step 10/20 completed (loss: 0.3939843773841858):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:38<00:25, 12.99s/it]Training Epoch: 2/10, step 11/20 completed (loss: 0.37587791681289673):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:38<00:25, 12.99s/it]Training Epoch: 2/10, step 12/20 completed (loss: 0.3858254849910736):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:25, 12.99s/it] Training Epoch: 2/10, step 13/20 completed (loss: 0.3713788688182831):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:25, 12.99s/it]Training Epoch: 2/10, step 14/20 completed (loss: 0.35531938076019287):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:48<00:25, 12.99s/it]Training Epoch: 2/10, step 14/20 completed (loss: 0.35531938076019287):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:51<00:12, 12.99s/it]Training Epoch: 2/10, step 15/20 completed (loss: 0.4202354848384857):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:12, 12.99s/it] Training Epoch: 2/10, step 16/20 completed (loss: 0.3091432452201843):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:12, 12.99s/it]Training Epoch: 2/10, step 17/20 completed (loss: 0.3344075679779053):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:12, 12.99s/it]Training Epoch: 2/10, step 18/20 completed (loss: 0.36255165934562683):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:01<00:12, 12.99s/it]Training Epoch: 2/10, step 18/20 completed (loss: 0.36255165934562683): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:04<00:00, 13.01s/it]Training Epoch: 2/10, step 19/20 completed (loss: 0.29751232266426086): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.01s/it]Training Epoch: 2/10, step 19/20 completed (loss: 0.29751232266426086): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.03s/it]
Epoch ending time:  2023-10-23 07:02:06 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:55,  1.79it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:01<00:48,  2.04it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:44,  2.18it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:42,  2.27it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:41,  2.28it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:41,  2.27it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:40,  2.28it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:40,  2.29it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:04<00:39,  2.31it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:38,  2.33it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:38,  2.30it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:38,  2.29it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:38,  2.29it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:37,  2.27it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:36,  2.31it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:07<00:35,  2.34it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:35,  2.33it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:35,  2.29it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:35,  2.30it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:34,  2.29it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:34,  2.30it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:34,  2.29it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:10<00:33,  2.33it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:32,  2.34it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:31,  2.35it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.32it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:31,  2.31it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:12<00:30,  2.36it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:30,  2.33it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:13<00:30,  2.30it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:30,  2.29it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:29,  2.27it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:29,  2.29it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:28,  2.28it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:15<00:28,  2.28it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:28,  2.24it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:16<00:28,  2.25it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:28,  2.19it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:17<00:27,  2.21it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:27,  2.22it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:18<00:26,  2.21it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:18<00:26,  2.21it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:25,  2.26it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:19<00:24,  2.30it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:23,  2.32it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:20<00:23,  2.32it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:20<00:22,  2.36it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:21,  2.40it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:21<00:21,  2.37it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:21,  2.36it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:22<00:20,  2.36it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:22<00:20,  2.30it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:23<00:20,  2.33it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:23<00:19,  2.31it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:24<00:19,  2.33it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:24<00:18,  2.33it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:18,  2.33it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:25<00:17,  2.36it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:25<00:17,  2.37it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:26<00:17,  2.35it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:26<00:16,  2.37it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:16,  2.34it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:27<00:15,  2.34it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:15,  2.37it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:28<00:14,  2.35it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:28<00:14,  2.34it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:29<00:14,  2.33it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:29<00:13,  2.34it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:29<00:13,  2.37it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:30<00:12,  2.38it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:30<00:12,  2.38it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:31<00:11,  2.38it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:31<00:11,  2.37it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:32<00:10,  2.39it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:32<00:10,  2.38it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:32<00:10,  2.39it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:33<00:09,  2.39it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:33<00:09,  2.39it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:34<00:08,  2.43it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:34<00:08,  2.43it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:34<00:07,  2.43it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:35<00:07,  2.42it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:35<00:06,  2.44it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:36<00:06,  2.43it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:36<00:06,  2.46it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:36<00:05,  2.42it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:37<00:05,  2.42it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:37<00:04,  2.41it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:38<00:04,  2.41it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:38<00:04,  2.44it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:39<00:03,  2.43it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:39<00:03,  2.41it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:39<00:02,  2.42it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:40<00:02,  2.36it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:40<00:02,  2.36it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:41<00:01,  2.33it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:41<00:01,  2.30it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:42<00:00,  2.32it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:42<00:00,  2.33it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.33it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:43<00:00,  2.32it/s]
LOSS is:  tensor(1.0324, device='cuda:0')
LOSS is:  tensor(1.2199, device='cuda:0')
LOSS is:  tensor(1.1163, device='cuda:0')
LOSS is:  tensor(0.5628, device='cuda:0')
LOSS is:  tensor(1.2297, device='cuda:0')
LOSS is:  tensor(1.2682, device='cuda:0')
LOSS is:  tensor(1.5096, device='cuda:0')
LOSS is:  tensor(1.1397, device='cuda:0')
LOSS is:  tensor(1.5999, device='cuda:0')
LOSS is:  tensor(1.0888, device='cuda:0')
LOSS is:  tensor(0.7105, device='cuda:0')
LOSS is:  tensor(1.2864, device='cuda:0')
LOSS is:  tensor(0.7374, device='cuda:0')
LOSS is:  tensor(1.2247, device='cuda:0')
LOSS is:  tensor(0.7699, device='cuda:0')
LOSS is:  tensor(1.1460, device='cuda:0')
LOSS is:  tensor(1.2373, device='cuda:0')
LOSS is:  tensor(1.1041, device='cuda:0')
LOSS is:  tensor(0.9047, device='cuda:0')
LOSS is:  tensor(1.1072, device='cuda:0')
LOSS is:  tensor(1.1736, device='cuda:0')
LOSS is:  tensor(1.3239, device='cuda:0')
LOSS is:  tensor(0.9118, device='cuda:0')
LOSS is:  tensor(0.9434, device='cuda:0')
LOSS is:  tensor(0.8452, device='cuda:0')
LOSS is:  tensor(0.6874, device='cuda:0')
LOSS is:  tensor(0.9038, device='cuda:0')
LOSS is:  tensor(0.7849, device='cuda:0')
LOSS is:  tensor(1.0782, device='cuda:0')
LOSS is:  tensor(1.2804, device='cuda:0')
LOSS is:  tensor(1.4915, device='cuda:0')
LOSS is:  tensor(0.8909, device='cuda:0')
LOSS is:  tensor(0.8162, device='cuda:0')
LOSS is:  tensor(0.8528, device='cuda:0')
LOSS is:  tensor(1.7628, device='cuda:0')
LOSS is:  tensor(0.8775, device='cuda:0')
LOSS is:  tensor(1.2159, device='cuda:0')
LOSS is:  tensor(0.8001, device='cuda:0')
LOSS is:  tensor(1.3832, device='cuda:0')
LOSS is:  tensor(0.9674, device='cuda:0')
LOSS is:  tensor(1.6117, device='cuda:0')
LOSS is:  tensor(1.4462, device='cuda:0')
LOSS is:  tensor(1.5287, device='cuda:0')
LOSS is:  tensor(1.4674, device='cuda:0')
LOSS is:  tensor(1.2471, device='cuda:0')
LOSS is:  tensor(1.0507, device='cuda:0')
LOSS is:  tensor(1.5197, device='cuda:0')
LOSS is:  tensor(1.1070, device='cuda:0')
LOSS is:  tensor(1.2246, device='cuda:0')
LOSS is:  tensor(1.0335, device='cuda:0')
LOSS is:  tensor(0.8501, device='cuda:0')
LOSS is:  tensor(1.7068, device='cuda:0')
LOSS is:  tensor(1.0937, device='cuda:0')
LOSS is:  tensor(1.3195, device='cuda:0')
LOSS is:  tensor(1.3819, device='cuda:0')
LOSS is:  tensor(0.9211, device='cuda:0')
LOSS is:  tensor(1.3205, device='cuda:0')
LOSS is:  tensor(1.0436, device='cuda:0')
LOSS is:  tensor(1.4603, device='cuda:0')
LOSS is:  tensor(1.4916, device='cuda:0')
LOSS is:  tensor(0.8400, device='cuda:0')
LOSS is:  tensor(1.0687, device='cuda:0')
LOSS is:  tensor(1.2229, device='cuda:0')
LOSS is:  tensor(1.2393, device='cuda:0')
LOSS is:  tensor(1.9245, device='cuda:0')
LOSS is:  tensor(0.8619, device='cuda:0')
LOSS is:  tensor(1.5680, device='cuda:0')
LOSS is:  tensor(1.1872, device='cuda:0')
LOSS is:  tensor(1.5454, device='cuda:0')
LOSS is:  tensor(0.9593, device='cuda:0')
LOSS is:  tensor(1.4152, device='cuda:0')
LOSS is:  tensor(1.2868, device='cuda:0')
LOSS is:  tensor(1.3073, device='cuda:0')
LOSS is:  tensor(1.1715, device='cuda:0')
LOSS is:  tensor(0.7652, device='cuda:0')
LOSS is:  tensor(0.6433, device='cuda:0')
LOSS is:  tensor(1.3720, device='cuda:0')
LOSS is:  tensor(1.1575, device='cuda:0')
LOSS is:  tensor(1.1073, device='cuda:0')
LOSS is:  tensor(0.8848, device='cuda:0')
LOSS is:  tensor(1.1502, device='cuda:0')
LOSS is:  tensor(1.1031, device='cuda:0')
LOSS is:  tensor(1.1176, device='cuda:0')
LOSS is:  tensor(0.7360, device='cuda:0')
LOSS is:  tensor(0.9362, device='cuda:0')
LOSS is:  tensor(1.1215, device='cuda:0')
LOSS is:  tensor(1.3268, device='cuda:0')
LOSS is:  tensor(1.1709, device='cuda:0')
LOSS is:  tensor(1.3501, device='cuda:0')
LOSS is:  tensor(1.1726, device='cuda:0')
LOSS is:  tensor(0.7088, device='cuda:0')
LOSS is:  tensor(1.5568, device='cuda:0')
LOSS is:  tensor(1.0454, device='cuda:0')
LOSS is:  tensor(1.0698, device='cuda:0')
LOSS is:  tensor(1.5561, device='cuda:0')
LOSS is:  tensor(1.0166, device='cuda:0')
LOSS is:  tensor(0.9157, device='cuda:0')
LOSS is:  tensor(1.1326, device='cuda:0')
LOSS is:  tensor(1.0835, device='cuda:0')
LOSS is:  tensor(1.4069, device='cuda:0')
 eval_ppl=tensor(3.1588, device='cuda:0') eval_epoch_loss=tensor(1.1502, device='cuda:0')
Eval epoch loss:  tensor(1.1502, device='cuda:0') | best_val_loss:  tensor(2.5718, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_1
Time while saving:  2023-10-23 07:02:49 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 2 is 1.1501771211624146
Epoch 2: train_perplexity=1.5796, train_epoch_loss=0.4572, epoch time 65.56448469590396s
Epoch starting time:  2023-10-23 07:02:49 IST+0530
Training Epoch: 3:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 3/10, step 0/20 completed (loss: 0.30285635590553284):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 3/10, step 1/20 completed (loss: 0.2688172161579132):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s] Training Epoch: 3/10, step 2/20 completed (loss: 0.2512216567993164):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 3/10, step 2/20 completed (loss: 0.2512216567993164):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.05s/it]Training Epoch: 3/10, step 3/20 completed (loss: 0.26380255818367004):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.05s/it]Training Epoch: 3/10, step 4/20 completed (loss: 0.26975810527801514):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.05s/it]Training Epoch: 3/10, step 5/20 completed (loss: 0.22868743538856506):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.05s/it]Training Epoch: 3/10, step 6/20 completed (loss: 0.24621990323066711):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.05s/it]Training Epoch: 3/10, step 6/20 completed (loss: 0.24621990323066711):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.05s/it]Training Epoch: 3/10, step 7/20 completed (loss: 0.2799808979034424):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.05s/it] Training Epoch: 3/10, step 8/20 completed (loss: 0.2503916919231415):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.05s/it]Training Epoch: 3/10, step 9/20 completed (loss: 0.21126209199428558):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.05s/it]Training Epoch: 3/10, step 10/20 completed (loss: 0.22124700248241425):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:35<00:39, 13.05s/it]Training Epoch: 3/10, step 10/20 completed (loss: 0.22124700248241425):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.06s/it]Training Epoch: 3/10, step 11/20 completed (loss: 0.21045304834842682):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.06s/it]Training Epoch: 3/10, step 12/20 completed (loss: 0.23471921682357788):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.06s/it]Training Epoch: 3/10, step 13/20 completed (loss: 0.24810296297073364):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.06s/it]Training Epoch: 3/10, step 14/20 completed (loss: 0.19195851683616638):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.06s/it]Training Epoch: 3/10, step 14/20 completed (loss: 0.19195851683616638):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.08s/it]Training Epoch: 3/10, step 15/20 completed (loss: 0.24482132494449615):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.08s/it]Training Epoch: 3/10, step 16/20 completed (loss: 0.20258288085460663):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.08s/it]Training Epoch: 3/10, step 17/20 completed (loss: 0.2128164917230606):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.08s/it] Training Epoch: 3/10, step 18/20 completed (loss: 0.26110637187957764):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.08s/it]Training Epoch: 3/10, step 18/20 completed (loss: 0.26110637187957764): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.09s/it]Training Epoch: 3/10, step 19/20 completed (loss: 0.2031293660402298): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.09s/it] Training Epoch: 3/10, step 19/20 completed (loss: 0.2031293660402298): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.11s/it]
Epoch ending time:  2023-10-23 07:03:55 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:54,  1.83it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:00<00:46,  2.12it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:43,  2.23it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:40,  2.34it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:40,  2.35it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:39,  2.36it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:39,  2.38it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:38,  2.39it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:03<00:36,  2.47it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:36,  2.48it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:36,  2.45it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:36,  2.41it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:36,  2.40it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:05<00:36,  2.38it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:35,  2.40it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:06<00:34,  2.41it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:34,  2.44it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:33,  2.45it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:07<00:33,  2.44it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:32,  2.43it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:08<00:32,  2.44it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:32,  2.41it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:09<00:31,  2.43it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:31,  2.42it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:30,  2.43it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:10<00:31,  2.37it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:31,  2.33it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:11<00:30,  2.37it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:30,  2.34it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:12<00:30,  2.33it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:29,  2.34it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:29,  2.34it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:13<00:28,  2.34it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:28,  2.34it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:14<00:27,  2.35it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.34it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:15<00:26,  2.34it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.34it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:26,  2.32it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:16<00:26,  2.29it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.28it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:17<00:25,  2.30it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:24,  2.34it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:18<00:23,  2.35it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:23,  2.37it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:19<00:22,  2.35it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:19<00:22,  2.36it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:21,  2.39it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:20<00:21,  2.38it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:21,  2.33it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:21<00:20,  2.34it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:21<00:20,  2.37it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:22<00:19,  2.35it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:22<00:19,  2.33it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:19,  2.32it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:23<00:19,  2.31it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:18,  2.33it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:24<00:17,  2.37it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:25<00:17,  2.31it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:25<00:17,  2.29it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:25<00:16,  2.35it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:16,  2.35it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:26<00:15,  2.38it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:15,  2.34it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:27<00:15,  2.33it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:28<00:14,  2.33it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:28<00:14,  2.32it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:28<00:13,  2.29it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:29<00:13,  2.31it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:29<00:12,  2.33it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:30<00:12,  2.32it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:30<00:12,  2.33it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:31<00:11,  2.34it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:31<00:11,  2.34it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:31<00:10,  2.32it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:32<00:10,  2.32it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:32<00:09,  2.31it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:33<00:09,  2.34it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:33<00:08,  2.35it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:34<00:08,  2.34it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:34<00:08,  2.35it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:34<00:07,  2.37it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:35<00:07,  2.39it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:35<00:06,  2.39it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:36<00:06,  2.38it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:36<00:05,  2.35it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:36<00:05,  2.33it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:37<00:05,  2.33it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:37<00:04,  2.34it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:38<00:04,  2.37it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:38<00:03,  2.40it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:39<00:03,  2.38it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:39<00:02,  2.36it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:39<00:02,  2.35it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:40<00:02,  2.36it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:40<00:01,  2.34it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:41<00:01,  2.33it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:41<00:00,  2.35it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:42<00:00,  2.37it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.34it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.35it/s]
LOSS is:  tensor(0.7306, device='cuda:0')
LOSS is:  tensor(0.8649, device='cuda:0')
LOSS is:  tensor(0.9463, device='cuda:0')
LOSS is:  tensor(0.3015, device='cuda:0')
LOSS is:  tensor(1.0382, device='cuda:0')
LOSS is:  tensor(1.1196, device='cuda:0')
LOSS is:  tensor(1.0645, device='cuda:0')
LOSS is:  tensor(0.9562, device='cuda:0')
LOSS is:  tensor(1.2467, device='cuda:0')
LOSS is:  tensor(0.9359, device='cuda:0')
LOSS is:  tensor(0.4441, device='cuda:0')
LOSS is:  tensor(0.8420, device='cuda:0')
LOSS is:  tensor(0.3364, device='cuda:0')
LOSS is:  tensor(1.2328, device='cuda:0')
LOSS is:  tensor(0.5964, device='cuda:0')
LOSS is:  tensor(0.6259, device='cuda:0')
LOSS is:  tensor(1.2419, device='cuda:0')
LOSS is:  tensor(0.8851, device='cuda:0')
LOSS is:  tensor(0.6638, device='cuda:0')
LOSS is:  tensor(0.8950, device='cuda:0')
LOSS is:  tensor(1.0355, device='cuda:0')
LOSS is:  tensor(1.0561, device='cuda:0')
LOSS is:  tensor(0.6962, device='cuda:0')
LOSS is:  tensor(0.6142, device='cuda:0')
LOSS is:  tensor(0.5353, device='cuda:0')
LOSS is:  tensor(0.3482, device='cuda:0')
LOSS is:  tensor(0.6253, device='cuda:0')
LOSS is:  tensor(0.5226, device='cuda:0')
LOSS is:  tensor(0.8911, device='cuda:0')
LOSS is:  tensor(0.9950, device='cuda:0')
LOSS is:  tensor(1.2286, device='cuda:0')
LOSS is:  tensor(0.6098, device='cuda:0')
LOSS is:  tensor(0.6177, device='cuda:0')
LOSS is:  tensor(0.6716, device='cuda:0')
LOSS is:  tensor(1.5694, device='cuda:0')
LOSS is:  tensor(0.6661, device='cuda:0')
LOSS is:  tensor(1.1407, device='cuda:0')
LOSS is:  tensor(0.5718, device='cuda:0')
LOSS is:  tensor(0.9624, device='cuda:0')
LOSS is:  tensor(0.7852, device='cuda:0')
LOSS is:  tensor(1.8762, device='cuda:0')
LOSS is:  tensor(1.3271, device='cuda:0')
LOSS is:  tensor(1.2796, device='cuda:0')
LOSS is:  tensor(1.2040, device='cuda:0')
LOSS is:  tensor(0.6782, device='cuda:0')
LOSS is:  tensor(1.0155, device='cuda:0')
LOSS is:  tensor(1.4073, device='cuda:0')
LOSS is:  tensor(0.7175, device='cuda:0')
LOSS is:  tensor(0.9818, device='cuda:0')
LOSS is:  tensor(0.8277, device='cuda:0')
LOSS is:  tensor(0.6862, device='cuda:0')
LOSS is:  tensor(1.4557, device='cuda:0')
LOSS is:  tensor(0.8328, device='cuda:0')
LOSS is:  tensor(1.1607, device='cuda:0')
LOSS is:  tensor(0.9851, device='cuda:0')
LOSS is:  tensor(0.6829, device='cuda:0')
LOSS is:  tensor(1.0560, device='cuda:0')
LOSS is:  tensor(0.5716, device='cuda:0')
LOSS is:  tensor(0.8871, device='cuda:0')
LOSS is:  tensor(1.2623, device='cuda:0')
LOSS is:  tensor(0.6863, device='cuda:0')
LOSS is:  tensor(0.7895, device='cuda:0')
LOSS is:  tensor(0.9451, device='cuda:0')
LOSS is:  tensor(0.8101, device='cuda:0')
LOSS is:  tensor(1.4441, device='cuda:0')
LOSS is:  tensor(0.7101, device='cuda:0')
LOSS is:  tensor(1.3366, device='cuda:0')
LOSS is:  tensor(0.9918, device='cuda:0')
LOSS is:  tensor(1.1580, device='cuda:0')
LOSS is:  tensor(0.6089, device='cuda:0')
LOSS is:  tensor(1.2075, device='cuda:0')
LOSS is:  tensor(1.0514, device='cuda:0')
LOSS is:  tensor(0.6823, device='cuda:0')
LOSS is:  tensor(0.9057, device='cuda:0')
LOSS is:  tensor(0.5632, device='cuda:0')
LOSS is:  tensor(0.4419, device='cuda:0')
LOSS is:  tensor(0.8222, device='cuda:0')
LOSS is:  tensor(0.9703, device='cuda:0')
LOSS is:  tensor(0.8649, device='cuda:0')
LOSS is:  tensor(0.6495, device='cuda:0')
LOSS is:  tensor(0.9145, device='cuda:0')
LOSS is:  tensor(0.8894, device='cuda:0')
LOSS is:  tensor(0.6568, device='cuda:0')
LOSS is:  tensor(0.6339, device='cuda:0')
LOSS is:  tensor(0.6244, device='cuda:0')
LOSS is:  tensor(0.9662, device='cuda:0')
LOSS is:  tensor(0.9550, device='cuda:0')
LOSS is:  tensor(0.9381, device='cuda:0')
LOSS is:  tensor(1.0496, device='cuda:0')
LOSS is:  tensor(0.9356, device='cuda:0')
LOSS is:  tensor(0.3983, device='cuda:0')
LOSS is:  tensor(1.3156, device='cuda:0')
LOSS is:  tensor(0.7775, device='cuda:0')
LOSS is:  tensor(0.6247, device='cuda:0')
LOSS is:  tensor(1.2185, device='cuda:0')
LOSS is:  tensor(0.7263, device='cuda:0')
LOSS is:  tensor(0.8541, device='cuda:0')
LOSS is:  tensor(1.1012, device='cuda:0')
LOSS is:  tensor(0.9283, device='cuda:0')
LOSS is:  tensor(1.0958, device='cuda:0')
 eval_ppl=tensor(2.4412, device='cuda:0') eval_epoch_loss=tensor(0.8925, device='cuda:0')
Eval epoch loss:  tensor(0.8925, device='cuda:0') | best_val_loss:  tensor(1.1502, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_2
Time while saving:  2023-10-23 07:04:38 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 3 is 0.8924906253814697
Epoch 3: train_perplexity=1.2715, train_epoch_loss=0.2402, epoch time 65.94796177279204s
Epoch starting time:  2023-10-23 07:04:38 IST+0530
Training Epoch: 4:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 4/10, step 0/20 completed (loss: 0.2313821166753769):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 4/10, step 1/20 completed (loss: 0.21033582091331482):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s]Training Epoch: 4/10, step 2/20 completed (loss: 0.16283893585205078):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 4/10, step 2/20 completed (loss: 0.16283893585205078):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.13s/it]Training Epoch: 4/10, step 3/20 completed (loss: 0.1971893161535263):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.13s/it] Training Epoch: 4/10, step 4/20 completed (loss: 0.1833958923816681):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.13s/it]Training Epoch: 4/10, step 5/20 completed (loss: 0.17519249022006989):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.13s/it]Training Epoch: 4/10, step 6/20 completed (loss: 0.21456967294216156):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.13s/it]Training Epoch: 4/10, step 6/20 completed (loss: 0.21456967294216156):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.08s/it]Training Epoch: 4/10, step 7/20 completed (loss: 0.2204485535621643):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.08s/it] Training Epoch: 4/10, step 8/20 completed (loss: 0.2041899412870407):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.08s/it]Training Epoch: 4/10, step 9/20 completed (loss: 0.16380351781845093):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.08s/it]Training Epoch: 4/10, step 10/20 completed (loss: 0.20438645780086517):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:36<00:39, 13.08s/it]Training Epoch: 4/10, step 10/20 completed (loss: 0.20438645780086517):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.09s/it]Training Epoch: 4/10, step 11/20 completed (loss: 0.1758013516664505):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.09s/it] Training Epoch: 4/10, step 12/20 completed (loss: 0.20652583241462708):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.09s/it]Training Epoch: 4/10, step 13/20 completed (loss: 0.23909065127372742):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.09s/it]Training Epoch: 4/10, step 14/20 completed (loss: 0.11834484338760376):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.09s/it]Training Epoch: 4/10, step 14/20 completed (loss: 0.11834484338760376):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.10s/it]Training Epoch: 4/10, step 15/20 completed (loss: 0.22621090710163116):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.10s/it]Training Epoch: 4/10, step 16/20 completed (loss: 0.17293553054332733):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.10s/it]Training Epoch: 4/10, step 17/20 completed (loss: 0.17311877012252808):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.10s/it]Training Epoch: 4/10, step 18/20 completed (loss: 0.24230876564979553):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.10s/it]Training Epoch: 4/10, step 18/20 completed (loss: 0.24230876564979553): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.10s/it]Training Epoch: 4/10, step 19/20 completed (loss: 0.17586830258369446): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.10s/it]Training Epoch: 4/10, step 19/20 completed (loss: 0.17586830258369446): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.14s/it]
Epoch ending time:  2023-10-23 07:05:44 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:54,  1.81it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:01<00:48,  2.04it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:45,  2.12it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:43,  2.23it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:42,  2.24it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:41,  2.25it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:40,  2.27it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:39,  2.30it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:04<00:39,  2.32it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:38,  2.31it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:38,  2.32it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:38,  2.31it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:37,  2.32it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:37,  2.30it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:37,  2.28it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:07<00:36,  2.31it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:35,  2.35it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:34,  2.35it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:34,  2.32it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:34,  2.29it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:34,  2.29it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:33,  2.30it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:10<00:33,  2.31it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:32,  2.31it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:31,  2.35it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.34it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:31,  2.32it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:12<00:31,  2.32it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:31,  2.29it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:13<00:31,  2.25it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:30,  2.28it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:29,  2.31it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:28,  2.34it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:28,  2.33it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:15<00:28,  2.32it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.32it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:16<00:27,  2.32it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.31it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:26,  2.32it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:25,  2.32it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.29it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:18<00:25,  2.28it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:24,  2.32it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:19<00:24,  2.31it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:24,  2.28it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:20<00:23,  2.27it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:20<00:23,  2.27it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:22,  2.31it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:21<00:21,  2.33it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:21,  2.33it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:22<00:21,  2.33it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:22<00:20,  2.30it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:23<00:20,  2.30it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:23<00:19,  2.31it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:19,  2.31it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:24<00:18,  2.33it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:18,  2.33it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:25<00:17,  2.33it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:25<00:17,  2.32it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:26<00:17,  2.27it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:26<00:16,  2.31it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:16,  2.30it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:27<00:16,  2.31it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:15,  2.31it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:28<00:15,  2.29it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:28<00:14,  2.30it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:29<00:14,  2.28it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:29<00:13,  2.30it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:30<00:13,  2.31it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:30<00:12,  2.33it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:30<00:12,  2.33it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:31<00:12,  2.31it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:31<00:11,  2.29it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:32<00:11,  2.30it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:32<00:10,  2.31it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:33<00:10,  2.32it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:33<00:10,  2.29it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:33<00:09,  2.28it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:34<00:09,  2.32it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:34<00:08,  2.32it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:35<00:08,  2.35it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:35<00:07,  2.35it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:36<00:07,  2.37it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:36<00:06,  2.37it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:36<00:06,  2.39it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:37<00:05,  2.37it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:37<00:05,  2.38it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:38<00:05,  2.36it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:38<00:04,  2.33it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:38<00:04,  2.35it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:39<00:03,  2.34it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:39<00:03,  2.36it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:40<00:02,  2.39it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:40<00:02,  2.38it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:41<00:02,  2.42it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:41<00:01,  2.39it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:41<00:01,  2.37it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:42<00:00,  2.37it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:42<00:00,  2.40it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:43<00:00,  2.41it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:43<00:00,  2.31it/s]
LOSS is:  tensor(0.5086, device='cuda:0')
LOSS is:  tensor(0.8170, device='cuda:0')
LOSS is:  tensor(0.6735, device='cuda:0')
LOSS is:  tensor(0.1784, device='cuda:0')
LOSS is:  tensor(0.9268, device='cuda:0')
LOSS is:  tensor(1.3390, device='cuda:0')
LOSS is:  tensor(0.8958, device='cuda:0')
LOSS is:  tensor(0.7238, device='cuda:0')
LOSS is:  tensor(0.9874, device='cuda:0')
LOSS is:  tensor(0.6889, device='cuda:0')
LOSS is:  tensor(0.4740, device='cuda:0')
LOSS is:  tensor(0.5351, device='cuda:0')
LOSS is:  tensor(0.2151, device='cuda:0')
LOSS is:  tensor(1.6663, device='cuda:0')
LOSS is:  tensor(0.5785, device='cuda:0')
LOSS is:  tensor(0.3114, device='cuda:0')
LOSS is:  tensor(1.5166, device='cuda:0')
LOSS is:  tensor(0.6090, device='cuda:0')
LOSS is:  tensor(0.5062, device='cuda:0')
LOSS is:  tensor(0.8311, device='cuda:0')
LOSS is:  tensor(0.8159, device='cuda:0')
LOSS is:  tensor(0.9179, device='cuda:0')
LOSS is:  tensor(0.7442, device='cuda:0')
LOSS is:  tensor(0.3386, device='cuda:0')
LOSS is:  tensor(0.3183, device='cuda:0')
LOSS is:  tensor(0.3909, device='cuda:0')
LOSS is:  tensor(0.6866, device='cuda:0')
LOSS is:  tensor(0.5138, device='cuda:0')
LOSS is:  tensor(0.6422, device='cuda:0')
LOSS is:  tensor(0.8949, device='cuda:0')
LOSS is:  tensor(1.0584, device='cuda:0')
LOSS is:  tensor(0.4578, device='cuda:0')
LOSS is:  tensor(1.0497, device='cuda:0')
LOSS is:  tensor(0.4713, device='cuda:0')
LOSS is:  tensor(1.5855, device='cuda:0')
LOSS is:  tensor(0.9814, device='cuda:0')
LOSS is:  tensor(1.5644, device='cuda:0')
LOSS is:  tensor(0.8055, device='cuda:0')
LOSS is:  tensor(0.7730, device='cuda:0')
LOSS is:  tensor(0.7840, device='cuda:0')
LOSS is:  tensor(2.2510, device='cuda:0')
LOSS is:  tensor(1.4548, device='cuda:0')
LOSS is:  tensor(1.4448, device='cuda:0')
LOSS is:  tensor(1.1049, device='cuda:0')
LOSS is:  tensor(0.3937, device='cuda:0')
LOSS is:  tensor(1.3502, device='cuda:0')
LOSS is:  tensor(1.4778, device='cuda:0')
LOSS is:  tensor(0.6109, device='cuda:0')
LOSS is:  tensor(0.9676, device='cuda:0')
LOSS is:  tensor(0.6479, device='cuda:0')
LOSS is:  tensor(0.4603, device='cuda:0')
LOSS is:  tensor(1.3766, device='cuda:0')
LOSS is:  tensor(0.6277, device='cuda:0')
LOSS is:  tensor(1.5248, device='cuda:0')
LOSS is:  tensor(0.8062, device='cuda:0')
LOSS is:  tensor(0.8799, device='cuda:0')
LOSS is:  tensor(0.8840, device='cuda:0')
LOSS is:  tensor(0.5112, device='cuda:0')
LOSS is:  tensor(0.6699, device='cuda:0')
LOSS is:  tensor(1.1407, device='cuda:0')
LOSS is:  tensor(0.7750, device='cuda:0')
LOSS is:  tensor(0.7895, device='cuda:0')
LOSS is:  tensor(0.6902, device='cuda:0')
LOSS is:  tensor(0.6680, device='cuda:0')
LOSS is:  tensor(1.1710, device='cuda:0')
LOSS is:  tensor(0.9402, device='cuda:0')
LOSS is:  tensor(1.0941, device='cuda:0')
LOSS is:  tensor(0.7522, device='cuda:0')
LOSS is:  tensor(1.0209, device='cuda:0')
LOSS is:  tensor(0.5477, device='cuda:0')
LOSS is:  tensor(1.0903, device='cuda:0')
LOSS is:  tensor(0.8830, device='cuda:0')
LOSS is:  tensor(0.4702, device='cuda:0')
LOSS is:  tensor(0.8432, device='cuda:0')
LOSS is:  tensor(0.5404, device='cuda:0')
LOSS is:  tensor(0.4594, device='cuda:0')
LOSS is:  tensor(0.5749, device='cuda:0')
LOSS is:  tensor(0.7457, device='cuda:0')
LOSS is:  tensor(0.7164, device='cuda:0')
LOSS is:  tensor(0.4840, device='cuda:0')
LOSS is:  tensor(0.6906, device='cuda:0')
LOSS is:  tensor(0.6674, device='cuda:0')
LOSS is:  tensor(0.5049, device='cuda:0')
LOSS is:  tensor(0.8252, device='cuda:0')
LOSS is:  tensor(0.4392, device='cuda:0')
LOSS is:  tensor(0.8347, device='cuda:0')
LOSS is:  tensor(0.6788, device='cuda:0')
LOSS is:  tensor(1.0063, device='cuda:0')
LOSS is:  tensor(0.9638, device='cuda:0')
LOSS is:  tensor(0.8181, device='cuda:0')
LOSS is:  tensor(0.4429, device='cuda:0')
LOSS is:  tensor(1.2326, device='cuda:0')
LOSS is:  tensor(0.5960, device='cuda:0')
LOSS is:  tensor(0.3938, device='cuda:0')
LOSS is:  tensor(1.1946, device='cuda:0')
LOSS is:  tensor(0.8017, device='cuda:0')
LOSS is:  tensor(1.1710, device='cuda:0')
LOSS is:  tensor(1.4233, device='cuda:0')
LOSS is:  tensor(0.9518, device='cuda:0')
LOSS is:  tensor(1.1756, device='cuda:0')
 eval_ppl=tensor(2.3032, device='cuda:0') eval_epoch_loss=tensor(0.8343, device='cuda:0')
Eval epoch loss:  tensor(0.8343, device='cuda:0') | best_val_loss:  tensor(0.8925, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_3
Time while saving:  2023-10-23 07:06:28 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 4 is 0.8343009948730469
Epoch 4: train_perplexity=1.2152, train_epoch_loss=0.1949, epoch time 66.07749099191278s
Epoch starting time:  2023-10-23 07:06:28 IST+0530
Training Epoch: 5:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 5/10, step 0/20 completed (loss: 0.2179858237504959):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 5/10, step 1/20 completed (loss: 0.1670977622270584):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s]Training Epoch: 5/10, step 2/20 completed (loss: 0.12018566578626633):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 5/10, step 2/20 completed (loss: 0.12018566578626633):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.08s/it]Training Epoch: 5/10, step 3/20 completed (loss: 0.18782711029052734):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.08s/it]Training Epoch: 5/10, step 4/20 completed (loss: 0.15409475564956665):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.08s/it]Training Epoch: 5/10, step 5/20 completed (loss: 0.1613299548625946):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.08s/it] Training Epoch: 5/10, step 6/20 completed (loss: 0.21978245675563812):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.08s/it]Training Epoch: 5/10, step 6/20 completed (loss: 0.21978245675563812):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.05s/it]Training Epoch: 5/10, step 7/20 completed (loss: 0.17280827462673187):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.05s/it]Training Epoch: 5/10, step 8/20 completed (loss: 0.18645884096622467):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.05s/it]Training Epoch: 5/10, step 9/20 completed (loss: 0.1812485158443451):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.05s/it] Training Epoch: 5/10, step 10/20 completed (loss: 0.22224266827106476):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:35<00:39, 13.05s/it]Training Epoch: 5/10, step 10/20 completed (loss: 0.22224266827106476):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.05s/it]Training Epoch: 5/10, step 11/20 completed (loss: 0.17041338980197906):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.05s/it]Training Epoch: 5/10, step 12/20 completed (loss: 0.1806907057762146):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.05s/it] Training Epoch: 5/10, step 13/20 completed (loss: 0.2324027121067047):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.05s/it]Training Epoch: 5/10, step 14/20 completed (loss: 0.0983007475733757):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.05s/it]Training Epoch: 5/10, step 14/20 completed (loss: 0.0983007475733757):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.07s/it]Training Epoch: 5/10, step 15/20 completed (loss: 0.2444293349981308):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.07s/it]Training Epoch: 5/10, step 16/20 completed (loss: 0.15495334565639496):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.07s/it]Training Epoch: 5/10, step 17/20 completed (loss: 0.16067151725292206):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.07s/it]Training Epoch: 5/10, step 18/20 completed (loss: 0.22415871918201447):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.07s/it]Training Epoch: 5/10, step 18/20 completed (loss: 0.22415871918201447): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.07s/it]Training Epoch: 5/10, step 19/20 completed (loss: 0.16986629366874695): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.07s/it]Training Epoch: 5/10, step 19/20 completed (loss: 0.16986629366874695): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.10s/it]
Epoch ending time:  2023-10-23 07:07:34 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:52,  1.87it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:00<00:46,  2.12it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:43,  2.24it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:41,  2.30it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:40,  2.33it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:39,  2.37it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:39,  2.37it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:38,  2.39it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:03<00:38,  2.39it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:37,  2.39it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:36,  2.41it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:36,  2.41it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:35,  2.42it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:05<00:35,  2.41it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:34,  2.43it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:06<00:34,  2.46it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:33,  2.48it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:32,  2.50it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:07<00:32,  2.49it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:32,  2.46it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:08<00:32,  2.47it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:31,  2.45it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:09<00:31,  2.44it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:09<00:31,  2.44it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:30,  2.45it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:10<00:30,  2.41it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:30,  2.41it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:11<00:29,  2.44it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:29,  2.44it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:12<00:28,  2.44it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:12<00:28,  2.44it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:27,  2.45it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:13<00:27,  2.46it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:27,  2.43it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:14<00:26,  2.41it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:14<00:26,  2.40it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:15<00:25,  2.42it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:15<00:25,  2.41it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:25,  2.41it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:16<00:24,  2.41it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:24,  2.40it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:17<00:24,  2.40it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:17<00:23,  2.42it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:18<00:23,  2.43it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:18<00:22,  2.42it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:19<00:22,  2.39it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:19<00:22,  2.40it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:19<00:21,  2.44it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:20<00:20,  2.46it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:20<00:20,  2.44it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:21<00:20,  2.42it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:21<00:19,  2.43it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:21<00:19,  2.43it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:22<00:18,  2.43it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:22<00:18,  2.41it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:23<00:18,  2.42it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:23<00:17,  2.44it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:24<00:17,  2.46it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:24<00:16,  2.45it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:24<00:16,  2.42it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:25<00:16,  2.43it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:25<00:15,  2.42it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:26<00:15,  2.42it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:26<00:14,  2.41it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:26<00:14,  2.38it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:27<00:14,  2.39it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:27<00:13,  2.40it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:28<00:13,  2.41it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:28<00:12,  2.44it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:28<00:12,  2.43it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:29<00:12,  2.41it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:29<00:11,  2.42it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:30<00:11,  2.44it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:30<00:10,  2.45it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:31<00:10,  2.40it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:31<00:10,  2.38it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:31<00:09,  2.38it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:32<00:09,  2.36it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:32<00:08,  2.39it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:33<00:08,  2.39it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:33<00:07,  2.41it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:33<00:07,  2.42it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:34<00:06,  2.44it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:34<00:06,  2.46it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:35<00:06,  2.47it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:35<00:05,  2.45it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:36<00:05,  2.43it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:36<00:04,  2.40it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:36<00:04,  2.41it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:37<00:04,  2.44it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:37<00:03,  2.42it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:38<00:03,  2.39it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:38<00:02,  2.40it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:38<00:02,  2.39it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:39<00:02,  2.44it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:39<00:01,  2.44it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:40<00:01,  2.44it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:40<00:00,  2.44it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:40<00:00,  2.46it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:41<00:00,  2.47it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:41<00:00,  2.41it/s]
LOSS is:  tensor(0.4325, device='cuda:0')
LOSS is:  tensor(0.7730, device='cuda:0')
LOSS is:  tensor(0.5695, device='cuda:0')
LOSS is:  tensor(0.1381, device='cuda:0')
LOSS is:  tensor(0.7118, device='cuda:0')
LOSS is:  tensor(1.3732, device='cuda:0')
LOSS is:  tensor(0.9007, device='cuda:0')
LOSS is:  tensor(0.5653, device='cuda:0')
LOSS is:  tensor(0.8085, device='cuda:0')
LOSS is:  tensor(0.5227, device='cuda:0')
LOSS is:  tensor(0.5313, device='cuda:0')
LOSS is:  tensor(0.4375, device='cuda:0')
LOSS is:  tensor(0.1644, device='cuda:0')
LOSS is:  tensor(1.9216, device='cuda:0')
LOSS is:  tensor(0.6820, device='cuda:0')
LOSS is:  tensor(0.1841, device='cuda:0')
LOSS is:  tensor(1.6225, device='cuda:0')
LOSS is:  tensor(0.4764, device='cuda:0')
LOSS is:  tensor(0.4097, device='cuda:0')
LOSS is:  tensor(0.9693, device='cuda:0')
LOSS is:  tensor(0.6537, device='cuda:0')
LOSS is:  tensor(0.7279, device='cuda:0')
LOSS is:  tensor(0.8232, device='cuda:0')
LOSS is:  tensor(0.2504, device='cuda:0')
LOSS is:  tensor(0.2105, device='cuda:0')
LOSS is:  tensor(0.4894, device='cuda:0')
LOSS is:  tensor(0.9304, device='cuda:0')
LOSS is:  tensor(0.5750, device='cuda:0')
LOSS is:  tensor(0.5535, device='cuda:0')
LOSS is:  tensor(0.9003, device='cuda:0')
LOSS is:  tensor(1.0601, device='cuda:0')
LOSS is:  tensor(0.3574, device='cuda:0')
LOSS is:  tensor(1.3532, device='cuda:0')
LOSS is:  tensor(0.3516, device='cuda:0')
LOSS is:  tensor(1.5290, device='cuda:0')
LOSS is:  tensor(1.1506, device='cuda:0')
LOSS is:  tensor(1.7519, device='cuda:0')
LOSS is:  tensor(0.9613, device='cuda:0')
LOSS is:  tensor(0.6840, device='cuda:0')
LOSS is:  tensor(0.9108, device='cuda:0')
LOSS is:  tensor(2.1064, device='cuda:0')
LOSS is:  tensor(1.4494, device='cuda:0')
LOSS is:  tensor(1.4745, device='cuda:0')
LOSS is:  tensor(0.9534, device='cuda:0')
LOSS is:  tensor(0.5035, device='cuda:0')
LOSS is:  tensor(1.7218, device='cuda:0')
LOSS is:  tensor(1.5421, device='cuda:0')
LOSS is:  tensor(0.5976, device='cuda:0')
LOSS is:  tensor(0.9126, device='cuda:0')
LOSS is:  tensor(0.4361, device='cuda:0')
LOSS is:  tensor(0.3988, device='cuda:0')
LOSS is:  tensor(1.2659, device='cuda:0')
LOSS is:  tensor(0.4914, device='cuda:0')
LOSS is:  tensor(1.7078, device='cuda:0')
LOSS is:  tensor(0.7904, device='cuda:0')
LOSS is:  tensor(1.0631, device='cuda:0')
LOSS is:  tensor(0.7371, device='cuda:0')
LOSS is:  tensor(0.5848, device='cuda:0')
LOSS is:  tensor(0.5612, device='cuda:0')
LOSS is:  tensor(0.9555, device='cuda:0')
LOSS is:  tensor(1.0700, device='cuda:0')
LOSS is:  tensor(0.6970, device='cuda:0')
LOSS is:  tensor(0.5626, device='cuda:0')
LOSS is:  tensor(0.5816, device='cuda:0')
LOSS is:  tensor(1.0240, device='cuda:0')
LOSS is:  tensor(1.2423, device='cuda:0')
LOSS is:  tensor(1.0116, device='cuda:0')
LOSS is:  tensor(0.5795, device='cuda:0')
LOSS is:  tensor(0.8691, device='cuda:0')
LOSS is:  tensor(0.5876, device='cuda:0')
LOSS is:  tensor(0.9200, device='cuda:0')
LOSS is:  tensor(0.6718, device='cuda:0')
LOSS is:  tensor(0.3756, device='cuda:0')
LOSS is:  tensor(0.7974, device='cuda:0')
LOSS is:  tensor(0.6188, device='cuda:0')
LOSS is:  tensor(0.5093, device='cuda:0')
LOSS is:  tensor(0.5670, device='cuda:0')
LOSS is:  tensor(0.5828, device='cuda:0')
LOSS is:  tensor(0.5699, device='cuda:0')
LOSS is:  tensor(0.4201, device='cuda:0')
LOSS is:  tensor(0.5559, device='cuda:0')
LOSS is:  tensor(0.5409, device='cuda:0')
LOSS is:  tensor(0.4994, device='cuda:0')
LOSS is:  tensor(0.9841, device='cuda:0')
LOSS is:  tensor(0.3028, device='cuda:0')
LOSS is:  tensor(0.8862, device='cuda:0')
LOSS is:  tensor(0.6517, device='cuda:0')
LOSS is:  tensor(1.0225, device='cuda:0')
LOSS is:  tensor(0.7556, device='cuda:0')
LOSS is:  tensor(0.5443, device='cuda:0')
LOSS is:  tensor(0.4813, device='cuda:0')
LOSS is:  tensor(1.2601, device='cuda:0')
LOSS is:  tensor(0.3783, device='cuda:0')
LOSS is:  tensor(0.3678, device='cuda:0')
LOSS is:  tensor(1.0387, device='cuda:0')
LOSS is:  tensor(0.8251, device='cuda:0')
LOSS is:  tensor(1.5552, device='cuda:0')
LOSS is:  tensor(1.6377, device='cuda:0')
LOSS is:  tensor(0.9920, device='cuda:0')
LOSS is:  tensor(1.1500, device='cuda:0')
 eval_ppl=tensor(2.2560, device='cuda:0') eval_epoch_loss=tensor(0.8136, device='cuda:0')
Eval epoch loss:  tensor(0.8136, device='cuda:0') | best_val_loss:  tensor(0.8343, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_4
Time while saving:  2023-10-23 07:08:16 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 5 is 0.8135932683944702
Epoch 5: train_perplexity=1.1988, train_epoch_loss=0.1813, epoch time 65.9114215108566s
Epoch starting time:  2023-10-23 07:08:16 IST+0530
Training Epoch: 6:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 6/10, step 0/20 completed (loss: 0.21550597250461578):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 6/10, step 1/20 completed (loss: 0.14582286775112152):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s]Training Epoch: 6/10, step 2/20 completed (loss: 0.10912486165761948):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 6/10, step 2/20 completed (loss: 0.10912486165761948):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.08s/it]Training Epoch: 6/10, step 3/20 completed (loss: 0.18494999408721924):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.08s/it]Training Epoch: 6/10, step 4/20 completed (loss: 0.1337696611881256):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.08s/it] Training Epoch: 6/10, step 5/20 completed (loss: 0.14846529066562653):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.08s/it]Training Epoch: 6/10, step 6/20 completed (loss: 0.22476153075695038):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.08s/it]Training Epoch: 6/10, step 6/20 completed (loss: 0.22476153075695038):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.05s/it]Training Epoch: 6/10, step 7/20 completed (loss: 0.14741399884223938):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.05s/it]Training Epoch: 6/10, step 8/20 completed (loss: 0.17385715246200562):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.05s/it]Training Epoch: 6/10, step 9/20 completed (loss: 0.17626769840717316):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.05s/it]Training Epoch: 6/10, step 10/20 completed (loss: 0.2064487338066101):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:35<00:39, 13.05s/it]Training Epoch: 6/10, step 10/20 completed (loss: 0.2064487338066101):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.06s/it]Training Epoch: 6/10, step 11/20 completed (loss: 0.16811662912368774):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.06s/it]Training Epoch: 6/10, step 12/20 completed (loss: 0.16598458588123322):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.06s/it]Training Epoch: 6/10, step 13/20 completed (loss: 0.22253009676933289):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.06s/it]Training Epoch: 6/10, step 14/20 completed (loss: 0.08384265750646591):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.06s/it]Training Epoch: 6/10, step 14/20 completed (loss: 0.08384265750646591):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.06s/it]Training Epoch: 6/10, step 15/20 completed (loss: 0.21761579811573029):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.06s/it]Training Epoch: 6/10, step 16/20 completed (loss: 0.13874545693397522):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.06s/it]Training Epoch: 6/10, step 17/20 completed (loss: 0.15868157148361206):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.06s/it]Training Epoch: 6/10, step 18/20 completed (loss: 0.21915209293365479):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.06s/it]Training Epoch: 6/10, step 18/20 completed (loss: 0.21915209293365479): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.08s/it]Training Epoch: 6/10, step 19/20 completed (loss: 0.15669240057468414): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.08s/it]Training Epoch: 6/10, step 19/20 completed (loss: 0.15669240057468414): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.10s/it]
Epoch ending time:  2023-10-23 07:09:22 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:55,  1.77it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:01<00:48,  2.03it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:45,  2.14it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:44,  2.16it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:43,  2.20it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:42,  2.22it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:41,  2.26it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:40,  2.26it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:04<00:39,  2.28it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:39,  2.28it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:38,  2.32it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:38,  2.30it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:38,  2.29it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:37,  2.27it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:37,  2.27it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:07<00:36,  2.27it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:36,  2.28it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:08<00:35,  2.30it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:34,  2.32it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:34,  2.33it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:33,  2.34it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:33,  2.32it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:10<00:33,  2.33it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:32,  2.33it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:32,  2.34it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.34it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:31,  2.31it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:12<00:30,  2.34it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:30,  2.33it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:13<00:30,  2.33it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:29,  2.34it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:29,  2.33it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:28,  2.37it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:27,  2.36it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:15<00:27,  2.36it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.36it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:16<00:26,  2.38it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.36it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:26,  2.35it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:25,  2.32it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.30it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:18<00:24,  2.33it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:24,  2.31it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:19<00:24,  2.31it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:23,  2.30it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:20<00:23,  2.29it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:20<00:22,  2.31it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:22,  2.30it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:21<00:22,  2.29it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:22,  2.27it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:22<00:21,  2.28it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:22<00:21,  2.27it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:23<00:20,  2.26it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:23<00:20,  2.27it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:19,  2.26it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:24<00:19,  2.26it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:18,  2.27it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:25<00:18,  2.29it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:25<00:18,  2.28it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:26<00:17,  2.27it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:26<00:16,  2.30it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:27<00:16,  2.29it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:27<00:16,  2.29it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:15,  2.28it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:28<00:15,  2.28it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:28<00:14,  2.27it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:29<00:14,  2.27it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:29<00:14,  2.26it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:30<00:13,  2.29it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:30<00:13,  2.28it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:31<00:12,  2.25it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:31<00:12,  2.25it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:31<00:11,  2.26it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:32<00:11,  2.27it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:32<00:11,  2.25it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:33<00:10,  2.25it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:33<00:10,  2.28it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:34<00:09,  2.28it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:34<00:09,  2.29it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:34<00:08,  2.28it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:35<00:08,  2.31it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:35<00:07,  2.31it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:36<00:07,  2.33it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:36<00:06,  2.33it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:37<00:06,  2.35it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:37<00:06,  2.33it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:37<00:05,  2.33it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:38<00:05,  2.33it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:38<00:04,  2.32it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:39<00:04,  2.34it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:39<00:03,  2.32it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:40<00:03,  2.33it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:40<00:02,  2.34it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:41<00:02,  2.22it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:41<00:02,  2.28it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:41<00:01,  2.26it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:42<00:01,  2.26it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:42<00:00,  2.29it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:43<00:00,  2.31it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:43<00:00,  2.32it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:43<00:00,  2.29it/s]
LOSS is:  tensor(0.3826, device='cuda:0')
LOSS is:  tensor(0.8255, device='cuda:0')
LOSS is:  tensor(0.4777, device='cuda:0')
LOSS is:  tensor(0.1340, device='cuda:0')
LOSS is:  tensor(0.8217, device='cuda:0')
LOSS is:  tensor(1.3603, device='cuda:0')
LOSS is:  tensor(0.8438, device='cuda:0')
LOSS is:  tensor(0.5574, device='cuda:0')
LOSS is:  tensor(0.7408, device='cuda:0')
LOSS is:  tensor(0.4561, device='cuda:0')
LOSS is:  tensor(0.3958, device='cuda:0')
LOSS is:  tensor(0.5316, device='cuda:0')
LOSS is:  tensor(0.1440, device='cuda:0')
LOSS is:  tensor(1.7678, device='cuda:0')
LOSS is:  tensor(0.5895, device='cuda:0')
LOSS is:  tensor(0.1975, device='cuda:0')
LOSS is:  tensor(1.5416, device='cuda:0')
LOSS is:  tensor(0.4752, device='cuda:0')
LOSS is:  tensor(0.4046, device='cuda:0')
LOSS is:  tensor(0.9764, device='cuda:0')
LOSS is:  tensor(0.6576, device='cuda:0')
LOSS is:  tensor(0.7797, device='cuda:0')
LOSS is:  tensor(0.7543, device='cuda:0')
LOSS is:  tensor(0.2221, device='cuda:0')
LOSS is:  tensor(0.1925, device='cuda:0')
LOSS is:  tensor(0.4063, device='cuda:0')
LOSS is:  tensor(0.7699, device='cuda:0')
LOSS is:  tensor(0.5560, device='cuda:0')
LOSS is:  tensor(0.5816, device='cuda:0')
LOSS is:  tensor(0.9637, device='cuda:0')
LOSS is:  tensor(1.0290, device='cuda:0')
LOSS is:  tensor(0.3417, device='cuda:0')
LOSS is:  tensor(1.1526, device='cuda:0')
LOSS is:  tensor(0.3519, device='cuda:0')
LOSS is:  tensor(1.4273, device='cuda:0')
LOSS is:  tensor(1.0883, device='cuda:0')
LOSS is:  tensor(1.6893, device='cuda:0')
LOSS is:  tensor(0.8453, device='cuda:0')
LOSS is:  tensor(0.7445, device='cuda:0')
LOSS is:  tensor(0.6107, device='cuda:0')
LOSS is:  tensor(2.0128, device='cuda:0')
LOSS is:  tensor(1.5134, device='cuda:0')
LOSS is:  tensor(1.3481, device='cuda:0')
LOSS is:  tensor(0.9694, device='cuda:0')
LOSS is:  tensor(0.4563, device='cuda:0')
LOSS is:  tensor(1.5250, device='cuda:0')
LOSS is:  tensor(1.5108, device='cuda:0')
LOSS is:  tensor(0.8056, device='cuda:0')
LOSS is:  tensor(1.1299, device='cuda:0')
LOSS is:  tensor(0.4988, device='cuda:0')
LOSS is:  tensor(0.4230, device='cuda:0')
LOSS is:  tensor(1.3106, device='cuda:0')
LOSS is:  tensor(0.5153, device='cuda:0')
LOSS is:  tensor(1.3757, device='cuda:0')
LOSS is:  tensor(0.8048, device='cuda:0')
LOSS is:  tensor(0.9784, device='cuda:0')
LOSS is:  tensor(0.7244, device='cuda:0')
LOSS is:  tensor(0.6150, device='cuda:0')
LOSS is:  tensor(0.5227, device='cuda:0')
LOSS is:  tensor(1.0225, device='cuda:0')
LOSS is:  tensor(0.8011, device='cuda:0')
LOSS is:  tensor(0.8703, device='cuda:0')
LOSS is:  tensor(0.6323, device='cuda:0')
LOSS is:  tensor(0.6079, device='cuda:0')
LOSS is:  tensor(1.1232, device='cuda:0')
LOSS is:  tensor(0.9075, device='cuda:0')
LOSS is:  tensor(1.0004, device='cuda:0')
LOSS is:  tensor(0.6741, device='cuda:0')
LOSS is:  tensor(1.0599, device='cuda:0')
LOSS is:  tensor(0.3993, device='cuda:0')
LOSS is:  tensor(0.9706, device='cuda:0')
LOSS is:  tensor(0.7655, device='cuda:0')
LOSS is:  tensor(0.3355, device='cuda:0')
LOSS is:  tensor(1.0587, device='cuda:0')
LOSS is:  tensor(0.5000, device='cuda:0')
LOSS is:  tensor(0.4259, device='cuda:0')
LOSS is:  tensor(0.5331, device='cuda:0')
LOSS is:  tensor(0.6081, device='cuda:0')
LOSS is:  tensor(0.6033, device='cuda:0')
LOSS is:  tensor(0.3714, device='cuda:0')
LOSS is:  tensor(0.6008, device='cuda:0')
LOSS is:  tensor(0.5349, device='cuda:0')
LOSS is:  tensor(0.6077, device='cuda:0')
LOSS is:  tensor(0.9762, device='cuda:0')
LOSS is:  tensor(0.2998, device='cuda:0')
LOSS is:  tensor(1.0284, device='cuda:0')
LOSS is:  tensor(0.7019, device='cuda:0')
LOSS is:  tensor(1.0051, device='cuda:0')
LOSS is:  tensor(0.8288, device='cuda:0')
LOSS is:  tensor(0.6252, device='cuda:0')
LOSS is:  tensor(0.3751, device='cuda:0')
LOSS is:  tensor(1.2293, device='cuda:0')
LOSS is:  tensor(0.4695, device='cuda:0')
LOSS is:  tensor(0.3102, device='cuda:0')
LOSS is:  tensor(1.2312, device='cuda:0')
LOSS is:  tensor(0.6948, device='cuda:0')
LOSS is:  tensor(1.0779, device='cuda:0')
LOSS is:  tensor(1.5653, device='cuda:0')
LOSS is:  tensor(1.1983, device='cuda:0')
LOSS is:  tensor(1.0901, device='cuda:0')
 eval_ppl=tensor(2.2155, device='cuda:0') eval_epoch_loss=tensor(0.7955, device='cuda:0')
Eval epoch loss:  tensor(0.7955, device='cuda:0') | best_val_loss:  tensor(0.8136, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_5
Time while saving:  2023-10-23 07:10:06 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 6 is 0.7954930067062378
Epoch 6: train_perplexity=1.1852, train_epoch_loss=0.1699, epoch time 65.92352920770645s
Epoch starting time:  2023-10-23 07:10:06 IST+0530
Training Epoch: 7:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 7/10, step 0/20 completed (loss: 0.20057044923305511):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 7/10, step 1/20 completed (loss: 0.14882135391235352):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s]Training Epoch: 7/10, step 2/20 completed (loss: 0.0928773432970047):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s] Training Epoch: 7/10, step 2/20 completed (loss: 0.0928773432970047):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.09s/it]Training Epoch: 7/10, step 3/20 completed (loss: 0.16695892810821533):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.09s/it]Training Epoch: 7/10, step 4/20 completed (loss: 0.13631029427051544):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.09s/it]Training Epoch: 7/10, step 5/20 completed (loss: 0.14032194018363953):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.09s/it]Training Epoch: 7/10, step 6/20 completed (loss: 0.22394196689128876):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.09s/it]Training Epoch: 7/10, step 6/20 completed (loss: 0.22394196689128876):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.06s/it]Training Epoch: 7/10, step 7/20 completed (loss: 0.1541832685470581):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.06s/it] Training Epoch: 7/10, step 8/20 completed (loss: 0.1525653451681137):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.06s/it]Training Epoch: 7/10, step 9/20 completed (loss: 0.15450891852378845):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.06s/it]Training Epoch: 7/10, step 10/20 completed (loss: 0.18349520862102509):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:35<00:39, 13.06s/it]Training Epoch: 7/10, step 10/20 completed (loss: 0.18349520862102509):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.06s/it]Training Epoch: 7/10, step 11/20 completed (loss: 0.1469823569059372):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.06s/it] Training Epoch: 7/10, step 12/20 completed (loss: 0.1601845622062683):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.06s/it]Training Epoch: 7/10, step 13/20 completed (loss: 0.22121882438659668):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.06s/it]Training Epoch: 7/10, step 14/20 completed (loss: 0.0872872844338417):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.06s/it] Training Epoch: 7/10, step 14/20 completed (loss: 0.0872872844338417):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.07s/it]Training Epoch: 7/10, step 15/20 completed (loss: 0.2005121111869812):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.07s/it]Training Epoch: 7/10, step 16/20 completed (loss: 0.13471344113349915):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.07s/it]Training Epoch: 7/10, step 17/20 completed (loss: 0.13916729390621185):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.07s/it]Training Epoch: 7/10, step 18/20 completed (loss: 0.20882900059223175):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.07s/it]Training Epoch: 7/10, step 18/20 completed (loss: 0.20882900059223175): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.08s/it]Training Epoch: 7/10, step 19/20 completed (loss: 0.14179286360740662): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.08s/it]Training Epoch: 7/10, step 19/20 completed (loss: 0.14179286360740662): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.11s/it]
Epoch ending time:  2023-10-23 07:11:12 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:54,  1.83it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:00<00:46,  2.09it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:44,  2.20it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:42,  2.27it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:41,  2.29it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:40,  2.30it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:39,  2.33it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:39,  2.34it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:03<00:38,  2.35it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:38,  2.36it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:37,  2.39it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:37,  2.37it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:36,  2.37it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:36,  2.35it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:36,  2.35it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:06<00:35,  2.37it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:34,  2.38it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:34,  2.39it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:34,  2.37it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:33,  2.35it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:33,  2.37it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:33,  2.36it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:09<00:32,  2.36it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:31,  2.38it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:31,  2.41it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.37it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:31,  2.35it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:11<00:30,  2.37it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:30,  2.33it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:12<00:30,  2.33it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:29,  2.31it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:29,  2.29it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:28,  2.34it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:28,  2.32it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:14<00:28,  2.32it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.31it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:15<00:27,  2.33it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.32it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:26,  2.32it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:25,  2.33it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.33it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:17<00:24,  2.34it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:23,  2.39it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:18<00:23,  2.39it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:23,  2.38it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:19<00:22,  2.37it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:20<00:22,  2.39it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:21,  2.39it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:20<00:21,  2.42it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:20,  2.42it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:21<00:20,  2.44it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:22<00:19,  2.43it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:22<00:19,  2.42it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:22<00:18,  2.42it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:18,  2.43it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:23<00:18,  2.43it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:17,  2.43it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:24<00:17,  2.46it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:24<00:16,  2.46it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:25<00:16,  2.46it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:25<00:15,  2.48it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:15,  2.46it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:26<00:15,  2.42it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:14,  2.41it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:27<00:14,  2.39it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:27<00:14,  2.37it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:28<00:13,  2.39it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:28<00:13,  2.40it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:29<00:12,  2.43it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:29<00:12,  2.43it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:29<00:11,  2.42it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:30<00:11,  2.41it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:30<00:11,  2.40it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:31<00:10,  2.40it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:31<00:10,  2.40it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:32<00:10,  2.36it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:32<00:09,  2.35it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:32<00:09,  2.33it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:33<00:08,  2.34it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:33<00:08,  2.35it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:34<00:08,  2.37it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:34<00:07,  2.37it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:35<00:07,  2.43it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:35<00:06,  2.44it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:35<00:06,  2.48it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:36<00:05,  2.44it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:36<00:05,  2.43it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:37<00:04,  2.43it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:37<00:04,  2.38it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:37<00:04,  2.38it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:38<00:03,  2.39it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:38<00:03,  2.37it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:39<00:02,  2.35it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:39<00:02,  2.36it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:40<00:02,  2.38it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:40<00:01,  2.39it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:40<00:01,  2.38it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:41<00:00,  2.36it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:41<00:00,  2.41it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.41it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.37it/s]
LOSS is:  tensor(0.4023, device='cuda:0')
LOSS is:  tensor(0.8920, device='cuda:0')
LOSS is:  tensor(0.5378, device='cuda:0')
LOSS is:  tensor(0.0904, device='cuda:0')
LOSS is:  tensor(0.8670, device='cuda:0')
LOSS is:  tensor(1.2187, device='cuda:0')
LOSS is:  tensor(0.9242, device='cuda:0')
LOSS is:  tensor(0.6283, device='cuda:0')
LOSS is:  tensor(0.9105, device='cuda:0')
LOSS is:  tensor(0.4767, device='cuda:0')
LOSS is:  tensor(0.3363, device='cuda:0')
LOSS is:  tensor(0.5378, device='cuda:0')
LOSS is:  tensor(0.0850, device='cuda:0')
LOSS is:  tensor(1.6635, device='cuda:0')
LOSS is:  tensor(0.5527, device='cuda:0')
LOSS is:  tensor(0.2066, device='cuda:0')
LOSS is:  tensor(1.3522, device='cuda:0')
LOSS is:  tensor(0.4454, device='cuda:0')
LOSS is:  tensor(0.4645, device='cuda:0')
LOSS is:  tensor(0.8642, device='cuda:0')
LOSS is:  tensor(0.7109, device='cuda:0')
LOSS is:  tensor(0.7975, device='cuda:0')
LOSS is:  tensor(0.6911, device='cuda:0')
LOSS is:  tensor(0.2532, device='cuda:0')
LOSS is:  tensor(0.1862, device='cuda:0')
LOSS is:  tensor(0.3781, device='cuda:0')
LOSS is:  tensor(0.6532, device='cuda:0')
LOSS is:  tensor(0.4560, device='cuda:0')
LOSS is:  tensor(0.6200, device='cuda:0')
LOSS is:  tensor(1.0563, device='cuda:0')
LOSS is:  tensor(1.0424, device='cuda:0')
LOSS is:  tensor(0.3479, device='cuda:0')
LOSS is:  tensor(1.3209, device='cuda:0')
LOSS is:  tensor(0.3244, device='cuda:0')
LOSS is:  tensor(1.3519, device='cuda:0')
LOSS is:  tensor(0.9165, device='cuda:0')
LOSS is:  tensor(1.5237, device='cuda:0')
LOSS is:  tensor(0.9524, device='cuda:0')
LOSS is:  tensor(0.6667, device='cuda:0')
LOSS is:  tensor(0.6338, device='cuda:0')
LOSS is:  tensor(2.0913, device='cuda:0')
LOSS is:  tensor(1.5092, device='cuda:0')
LOSS is:  tensor(1.2818, device='cuda:0')
LOSS is:  tensor(0.9764, device='cuda:0')
LOSS is:  tensor(0.6026, device='cuda:0')
LOSS is:  tensor(1.3742, device='cuda:0')
LOSS is:  tensor(1.5155, device='cuda:0')
LOSS is:  tensor(0.8801, device='cuda:0')
LOSS is:  tensor(1.2194, device='cuda:0')
LOSS is:  tensor(0.5317, device='cuda:0')
LOSS is:  tensor(0.3465, device='cuda:0')
LOSS is:  tensor(1.4526, device='cuda:0')
LOSS is:  tensor(0.4925, device='cuda:0')
LOSS is:  tensor(1.3526, device='cuda:0')
LOSS is:  tensor(0.8440, device='cuda:0')
LOSS is:  tensor(0.9597, device='cuda:0')
LOSS is:  tensor(0.7556, device='cuda:0')
LOSS is:  tensor(0.8122, device='cuda:0')
LOSS is:  tensor(0.4243, device='cuda:0')
LOSS is:  tensor(0.9734, device='cuda:0')
LOSS is:  tensor(0.7603, device='cuda:0')
LOSS is:  tensor(0.8968, device='cuda:0')
LOSS is:  tensor(0.6139, device='cuda:0')
LOSS is:  tensor(0.6461, device='cuda:0')
LOSS is:  tensor(1.1493, device='cuda:0')
LOSS is:  tensor(0.8307, device='cuda:0')
LOSS is:  tensor(1.0084, device='cuda:0')
LOSS is:  tensor(0.7141, device='cuda:0')
LOSS is:  tensor(1.0368, device='cuda:0')
LOSS is:  tensor(0.2712, device='cuda:0')
LOSS is:  tensor(0.9384, device='cuda:0')
LOSS is:  tensor(0.7742, device='cuda:0')
LOSS is:  tensor(0.3113, device='cuda:0')
LOSS is:  tensor(1.1296, device='cuda:0')
LOSS is:  tensor(0.3965, device='cuda:0')
LOSS is:  tensor(0.2978, device='cuda:0')
LOSS is:  tensor(0.5860, device='cuda:0')
LOSS is:  tensor(0.6270, device='cuda:0')
LOSS is:  tensor(0.6077, device='cuda:0')
LOSS is:  tensor(0.3435, device='cuda:0')
LOSS is:  tensor(0.6132, device='cuda:0')
LOSS is:  tensor(0.5085, device='cuda:0')
LOSS is:  tensor(0.8094, device='cuda:0')
LOSS is:  tensor(0.8936, device='cuda:0')
LOSS is:  tensor(0.2500, device='cuda:0')
LOSS is:  tensor(1.0904, device='cuda:0')
LOSS is:  tensor(0.7455, device='cuda:0')
LOSS is:  tensor(0.9679, device='cuda:0')
LOSS is:  tensor(0.8689, device='cuda:0')
LOSS is:  tensor(0.6603, device='cuda:0')
LOSS is:  tensor(0.2903, device='cuda:0')
LOSS is:  tensor(1.2966, device='cuda:0')
LOSS is:  tensor(0.4498, device='cuda:0')
LOSS is:  tensor(0.2604, device='cuda:0')
LOSS is:  tensor(1.5480, device='cuda:0')
LOSS is:  tensor(0.6286, device='cuda:0')
LOSS is:  tensor(0.8689, device='cuda:0')
LOSS is:  tensor(1.3243, device='cuda:0')
LOSS is:  tensor(1.0449, device='cuda:0')
LOSS is:  tensor(1.0528, device='cuda:0')
 eval_ppl=tensor(2.2000, device='cuda:0') eval_epoch_loss=tensor(0.7885, device='cuda:0')
Eval epoch loss:  tensor(0.7885, device='cuda:0') | best_val_loss:  tensor(0.7955, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_6
Time while saving:  2023-10-23 07:11:55 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 7 is 0.7884699106216431
Epoch 7: train_perplexity=1.1732, train_epoch_loss=0.1598, epoch time 65.93030680902302s
Epoch starting time:  2023-10-23 07:11:55 IST+0530
Training Epoch: 8:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 8/10, step 0/20 completed (loss: 0.18232038617134094):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 8/10, step 1/20 completed (loss: 0.14034338295459747):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s]Training Epoch: 8/10, step 2/20 completed (loss: 0.08317863941192627):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 8/10, step 2/20 completed (loss: 0.08317863941192627):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.12s/it]Training Epoch: 8/10, step 3/20 completed (loss: 0.15997940301895142):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.12s/it]Training Epoch: 8/10, step 4/20 completed (loss: 0.13815481960773468):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.12s/it]Training Epoch: 8/10, step 5/20 completed (loss: 0.1271602362394333):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.12s/it] Training Epoch: 8/10, step 6/20 completed (loss: 0.20706404745578766):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.12s/it]Training Epoch: 8/10, step 6/20 completed (loss: 0.20706404745578766):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.08s/it]Training Epoch: 8/10, step 7/20 completed (loss: 0.14827288687229156):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.08s/it]Training Epoch: 8/10, step 8/20 completed (loss: 0.14009948074817657):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.08s/it]Training Epoch: 8/10, step 9/20 completed (loss: 0.1318047195672989):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.08s/it] Training Epoch: 8/10, step 10/20 completed (loss: 0.16335967183113098):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:36<00:39, 13.08s/it]Training Epoch: 8/10, step 10/20 completed (loss: 0.16335967183113098):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.08s/it]Training Epoch: 8/10, step 11/20 completed (loss: 0.1294812560081482):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.08s/it] Training Epoch: 8/10, step 12/20 completed (loss: 0.13916373252868652):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.08s/it]Training Epoch: 8/10, step 13/20 completed (loss: 0.19979768991470337):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.08s/it]Training Epoch: 8/10, step 14/20 completed (loss: 0.08156810700893402):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.08s/it]Training Epoch: 8/10, step 14/20 completed (loss: 0.08156810700893402):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.09s/it]Training Epoch: 8/10, step 15/20 completed (loss: 0.18914568424224854):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.09s/it]Training Epoch: 8/10, step 16/20 completed (loss: 0.11520311236381531):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.09s/it]Training Epoch: 8/10, step 17/20 completed (loss: 0.12615220248699188):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.09s/it]Training Epoch: 8/10, step 18/20 completed (loss: 0.18259982764720917):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.09s/it]Training Epoch: 8/10, step 18/20 completed (loss: 0.18259982764720917): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.09s/it]Training Epoch: 8/10, step 19/20 completed (loss: 0.13069593906402588): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.09s/it]Training Epoch: 8/10, step 19/20 completed (loss: 0.13069593906402588): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.12s/it]
Epoch ending time:  2023-10-23 07:13:01 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:53,  1.83it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:00<00:46,  2.09it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:44,  2.17it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:42,  2.23it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:41,  2.27it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:41,  2.29it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:40,  2.31it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:39,  2.32it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:03<00:39,  2.33it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:39,  2.29it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:38,  2.30it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:38,  2.30it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:37,  2.31it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:37,  2.31it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:36,  2.33it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:07<00:36,  2.33it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:35,  2.33it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:34,  2.35it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:34,  2.35it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:34,  2.32it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:34,  2.31it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:33,  2.32it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:10<00:33,  2.33it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:32,  2.33it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:31,  2.36it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.37it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:30,  2.36it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:12<00:30,  2.38it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:30,  2.34it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:12<00:29,  2.36it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:29,  2.35it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:29,  2.33it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:28,  2.32it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:28,  2.32it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:15<00:28,  2.29it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.29it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:16<00:27,  2.31it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.31it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:26,  2.33it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:26,  2.30it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.29it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:18<00:25,  2.31it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:24,  2.34it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:19<00:23,  2.35it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:23,  2.34it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:19<00:23,  2.33it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:20<00:22,  2.36it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:21,  2.37it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:21<00:21,  2.37it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:21,  2.36it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:22<00:20,  2.34it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:22<00:20,  2.32it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:22<00:20,  2.30it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:23<00:19,  2.32it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:19,  2.32it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:24<00:19,  2.29it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:18,  2.30it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:25<00:18,  2.31it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:25<00:17,  2.31it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:25<00:17,  2.31it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:26<00:16,  2.33it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:16,  2.31it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:27<00:16,  2.30it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:15,  2.30it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:28<00:15,  2.28it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:28<00:14,  2.28it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:28<00:14,  2.30it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:29<00:13,  2.29it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:29<00:13,  2.30it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:30<00:12,  2.31it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:30<00:12,  2.32it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:31<00:11,  2.34it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:31<00:11,  2.30it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:31<00:11,  2.31it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:32<00:10,  2.29it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:32<00:10,  2.29it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:33<00:10,  2.29it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:33<00:09,  2.28it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:34<00:09,  2.32it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:34<00:08,  2.32it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:35<00:08,  2.33it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:35<00:07,  2.34it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:35<00:07,  2.37it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:36<00:06,  2.37it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:36<00:06,  2.39it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:37<00:05,  2.35it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:37<00:05,  2.33it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:37<00:05,  2.34it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:38<00:04,  2.33it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:38<00:04,  2.36it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:39<00:03,  2.35it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:39<00:03,  2.36it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:40<00:03,  2.32it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:40<00:02,  2.28it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:40<00:02,  2.32it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:41<00:01,  2.31it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:41<00:01,  2.31it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:42<00:00,  2.36it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:42<00:00,  2.40it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:43<00:00,  2.38it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:43<00:00,  2.31it/s]
LOSS is:  tensor(0.3104, device='cuda:0')
LOSS is:  tensor(0.9466, device='cuda:0')
LOSS is:  tensor(0.3578, device='cuda:0')
LOSS is:  tensor(0.0755, device='cuda:0')
LOSS is:  tensor(0.7401, device='cuda:0')
LOSS is:  tensor(1.3672, device='cuda:0')
LOSS is:  tensor(0.9796, device='cuda:0')
LOSS is:  tensor(0.5240, device='cuda:0')
LOSS is:  tensor(0.7990, device='cuda:0')
LOSS is:  tensor(0.4971, device='cuda:0')
LOSS is:  tensor(0.3665, device='cuda:0')
LOSS is:  tensor(0.4273, device='cuda:0')
LOSS is:  tensor(0.0806, device='cuda:0')
LOSS is:  tensor(1.5737, device='cuda:0')
LOSS is:  tensor(0.5474, device='cuda:0')
LOSS is:  tensor(0.1507, device='cuda:0')
LOSS is:  tensor(1.2417, device='cuda:0')
LOSS is:  tensor(0.5212, device='cuda:0')
LOSS is:  tensor(0.3253, device='cuda:0')
LOSS is:  tensor(0.7514, device='cuda:0')
LOSS is:  tensor(0.4916, device='cuda:0')
LOSS is:  tensor(0.7304, device='cuda:0')
LOSS is:  tensor(0.6989, device='cuda:0')
LOSS is:  tensor(0.1434, device='cuda:0')
LOSS is:  tensor(0.0727, device='cuda:0')
LOSS is:  tensor(0.4075, device='cuda:0')
LOSS is:  tensor(0.6110, device='cuda:0')
LOSS is:  tensor(0.3869, device='cuda:0')
LOSS is:  tensor(0.5374, device='cuda:0')
LOSS is:  tensor(1.1752, device='cuda:0')
LOSS is:  tensor(1.1457, device='cuda:0')
LOSS is:  tensor(0.2997, device='cuda:0')
LOSS is:  tensor(1.5101, device='cuda:0')
LOSS is:  tensor(0.1276, device='cuda:0')
LOSS is:  tensor(1.3114, device='cuda:0')
LOSS is:  tensor(1.1743, device='cuda:0')
LOSS is:  tensor(1.4250, device='cuda:0')
LOSS is:  tensor(0.9199, device='cuda:0')
LOSS is:  tensor(0.6232, device='cuda:0')
LOSS is:  tensor(0.5601, device='cuda:0')
LOSS is:  tensor(2.5567, device='cuda:0')
LOSS is:  tensor(1.3705, device='cuda:0')
LOSS is:  tensor(1.1546, device='cuda:0')
LOSS is:  tensor(0.8873, device='cuda:0')
LOSS is:  tensor(0.8412, device='cuda:0')
LOSS is:  tensor(1.4296, device='cuda:0')
LOSS is:  tensor(1.5870, device='cuda:0')
LOSS is:  tensor(0.8605, device='cuda:0')
LOSS is:  tensor(1.2024, device='cuda:0')
LOSS is:  tensor(0.3137, device='cuda:0')
LOSS is:  tensor(0.2548, device='cuda:0')
LOSS is:  tensor(1.3913, device='cuda:0')
LOSS is:  tensor(0.4337, device='cuda:0')
LOSS is:  tensor(1.6143, device='cuda:0')
LOSS is:  tensor(0.8003, device='cuda:0')
LOSS is:  tensor(1.1461, device='cuda:0')
LOSS is:  tensor(0.7205, device='cuda:0')
LOSS is:  tensor(0.8222, device='cuda:0')
LOSS is:  tensor(0.3967, device='cuda:0')
LOSS is:  tensor(0.8805, device='cuda:0')
LOSS is:  tensor(0.7463, device='cuda:0')
LOSS is:  tensor(0.9754, device='cuda:0')
LOSS is:  tensor(0.6012, device='cuda:0')
LOSS is:  tensor(0.5362, device='cuda:0')
LOSS is:  tensor(1.1494, device='cuda:0')
LOSS is:  tensor(0.7892, device='cuda:0')
LOSS is:  tensor(0.9226, device='cuda:0')
LOSS is:  tensor(0.6197, device='cuda:0')
LOSS is:  tensor(0.9683, device='cuda:0')
LOSS is:  tensor(0.0642, device='cuda:0')
LOSS is:  tensor(0.8668, device='cuda:0')
LOSS is:  tensor(0.5836, device='cuda:0')
LOSS is:  tensor(0.2203, device='cuda:0')
LOSS is:  tensor(1.1436, device='cuda:0')
LOSS is:  tensor(0.2789, device='cuda:0')
LOSS is:  tensor(0.2383, device='cuda:0')
LOSS is:  tensor(0.6356, device='cuda:0')
LOSS is:  tensor(0.5833, device='cuda:0')
LOSS is:  tensor(0.5864, device='cuda:0')
LOSS is:  tensor(0.2748, device='cuda:0')
LOSS is:  tensor(0.6000, device='cuda:0')
LOSS is:  tensor(0.3920, device='cuda:0')
LOSS is:  tensor(0.7412, device='cuda:0')
LOSS is:  tensor(1.0312, device='cuda:0')
LOSS is:  tensor(0.1337, device='cuda:0')
LOSS is:  tensor(1.2155, device='cuda:0')
LOSS is:  tensor(0.6726, device='cuda:0')
LOSS is:  tensor(0.9020, device='cuda:0')
LOSS is:  tensor(0.8264, device='cuda:0')
LOSS is:  tensor(0.6121, device='cuda:0')
LOSS is:  tensor(0.2470, device='cuda:0')
LOSS is:  tensor(1.3039, device='cuda:0')
LOSS is:  tensor(0.2936, device='cuda:0')
LOSS is:  tensor(0.1122, device='cuda:0')
LOSS is:  tensor(1.4947, device='cuda:0')
LOSS is:  tensor(0.5133, device='cuda:0')
LOSS is:  tensor(0.9169, device='cuda:0')
LOSS is:  tensor(1.4329, device='cuda:0')
LOSS is:  tensor(1.1889, device='cuda:0')
LOSS is:  tensor(1.1104, device='cuda:0')
 eval_ppl=tensor(2.1409, device='cuda:0') eval_epoch_loss=tensor(0.7612, device='cuda:0')
Eval epoch loss:  tensor(0.7612, device='cuda:0') | best_val_loss:  tensor(0.7885, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_7
Time while saving:  2023-10-23 07:13:44 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 8 is 0.7612391710281372
Epoch 8: train_perplexity=1.1569, train_epoch_loss=0.1458, epoch time 66.01611208170652s
Epoch starting time:  2023-10-23 07:13:44 IST+0530
Training Epoch: 9:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 9/10, step 0/20 completed (loss: 0.1609361469745636):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 9/10, step 1/20 completed (loss: 0.12405877560377121):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s]Training Epoch: 9/10, step 2/20 completed (loss: 0.057942356914281845):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 9/10, step 2/20 completed (loss: 0.057942356914281845):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.11s/it]Training Epoch: 9/10, step 3/20 completed (loss: 0.1496976763010025):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.11s/it]  Training Epoch: 9/10, step 4/20 completed (loss: 0.12321052700281143):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.11s/it]Training Epoch: 9/10, step 5/20 completed (loss: 0.11294930428266525):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.11s/it]Training Epoch: 9/10, step 6/20 completed (loss: 0.20079578459262848):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.11s/it]Training Epoch: 9/10, step 6/20 completed (loss: 0.20079578459262848):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.07s/it]Training Epoch: 9/10, step 7/20 completed (loss: 0.12961611151695251):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.07s/it]Training Epoch: 9/10, step 8/20 completed (loss: 0.10609303414821625):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.07s/it]Training Epoch: 9/10, step 9/20 completed (loss: 0.11340688914060593):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.07s/it]Training Epoch: 9/10, step 10/20 completed (loss: 0.1349433809518814):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:36<00:39, 13.07s/it]Training Epoch: 9/10, step 10/20 completed (loss: 0.1349433809518814):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.08s/it]Training Epoch: 9/10, step 11/20 completed (loss: 0.11006291955709457):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.08s/it]Training Epoch: 9/10, step 12/20 completed (loss: 0.1147351861000061):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.08s/it] Training Epoch: 9/10, step 13/20 completed (loss: 0.18684259057044983):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.08s/it]Training Epoch: 9/10, step 14/20 completed (loss: 0.06302527338266373):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.08s/it]Training Epoch: 9/10, step 14/20 completed (loss: 0.06302527338266373):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.08s/it]Training Epoch: 9/10, step 15/20 completed (loss: 0.1838541179895401):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.08s/it] Training Epoch: 9/10, step 16/20 completed (loss: 0.10685629397630692):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.08s/it]Training Epoch: 9/10, step 17/20 completed (loss: 0.08896593004465103):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.08s/it]Training Epoch: 9/10, step 18/20 completed (loss: 0.1574230045080185):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.08s/it] Training Epoch: 9/10, step 18/20 completed (loss: 0.1574230045080185): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.09s/it]Training Epoch: 9/10, step 19/20 completed (loss: 0.10634453594684601): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.09s/it]Training Epoch: 9/10, step 19/20 completed (loss: 0.10634453594684601): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.12s/it]
Epoch ending time:  2023-10-23 07:14:50 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:52,  1.88it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:00<00:44,  2.18it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:43,  2.23it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:42,  2.26it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:41,  2.28it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:40,  2.30it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:40,  2.32it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:39,  2.32it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:03<00:38,  2.34it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:38,  2.34it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:37,  2.39it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:36,  2.41it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:36,  2.41it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:36,  2.38it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:36,  2.36it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:06<00:35,  2.39it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:34,  2.39it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:34,  2.38it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:34,  2.35it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:34,  2.31it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:33,  2.33it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:33,  2.32it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:09<00:33,  2.30it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:32,  2.32it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:32,  2.34it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.33it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:31,  2.32it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:12<00:30,  2.35it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:30,  2.32it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:12<00:30,  2.33it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:29,  2.31it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:28,  2.34it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:28,  2.37it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:28,  2.36it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:15<00:27,  2.35it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.34it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:15<00:27,  2.30it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.30it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:26,  2.29it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:26,  2.30it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.27it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:18<00:25,  2.29it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:24,  2.32it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:18<00:23,  2.35it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:23,  2.33it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:19<00:23,  2.32it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:20<00:22,  2.33it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:22,  2.35it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:21<00:21,  2.35it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:21,  2.32it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:21<00:21,  2.30it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:22<00:20,  2.30it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:22<00:20,  2.31it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:23<00:19,  2.31it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:19,  2.31it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:24<00:19,  2.31it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:18,  2.30it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:24<00:18,  2.30it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:25<00:18,  2.27it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:25<00:17,  2.28it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:26<00:16,  2.30it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:16,  2.32it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:27<00:15,  2.33it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:27<00:15,  2.33it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:27<00:14,  2.34it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:28<00:14,  2.33it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:28<00:14,  2.33it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:29<00:13,  2.34it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:29<00:13,  2.35it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:30<00:12,  2.36it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:30<00:12,  2.32it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:30<00:12,  2.31it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:31<00:11,  2.32it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:31<00:11,  2.33it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:32<00:10,  2.31it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:32<00:10,  2.32it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:33<00:09,  2.32it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:33<00:09,  2.30it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:34<00:09,  2.33it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:34<00:08,  2.35it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:34<00:08,  2.34it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:35<00:07,  2.31it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:35<00:07,  2.31it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:36<00:06,  2.35it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:36<00:06,  2.37it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:36<00:05,  2.37it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:37<00:05,  2.36it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:37<00:05,  2.36it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:38<00:04,  2.35it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:38<00:04,  2.39it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:39<00:03,  2.38it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:39<00:03,  2.37it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:39<00:02,  2.38it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:40<00:02,  2.36it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:40<00:02,  2.36it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:41<00:01,  2.36it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:41<00:01,  2.38it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:42<00:00,  2.42it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:42<00:00,  2.44it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.45it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.33it/s]
LOSS is:  tensor(0.1665, device='cuda:0')
LOSS is:  tensor(0.6504, device='cuda:0')
LOSS is:  tensor(0.2215, device='cuda:0')
LOSS is:  tensor(0.0260, device='cuda:0')
LOSS is:  tensor(0.4697, device='cuda:0')
LOSS is:  tensor(1.8167, device='cuda:0')
LOSS is:  tensor(1.0162, device='cuda:0')
LOSS is:  tensor(0.3979, device='cuda:0')
LOSS is:  tensor(0.3544, device='cuda:0')
LOSS is:  tensor(0.4280, device='cuda:0')
LOSS is:  tensor(0.4110, device='cuda:0')
LOSS is:  tensor(0.4390, device='cuda:0')
LOSS is:  tensor(0.0233, device='cuda:0')
LOSS is:  tensor(1.7561, device='cuda:0')
LOSS is:  tensor(0.4694, device='cuda:0')
LOSS is:  tensor(0.0947, device='cuda:0')
LOSS is:  tensor(1.2818, device='cuda:0')
LOSS is:  tensor(0.4111, device='cuda:0')
LOSS is:  tensor(0.2496, device='cuda:0')
LOSS is:  tensor(0.7543, device='cuda:0')
LOSS is:  tensor(0.3086, device='cuda:0')
LOSS is:  tensor(0.5823, device='cuda:0')
LOSS is:  tensor(0.6302, device='cuda:0')
LOSS is:  tensor(0.0408, device='cuda:0')
LOSS is:  tensor(0.0189, device='cuda:0')
LOSS is:  tensor(0.3434, device='cuda:0')
LOSS is:  tensor(0.5712, device='cuda:0')
LOSS is:  tensor(0.3639, device='cuda:0')
LOSS is:  tensor(0.4602, device='cuda:0')
LOSS is:  tensor(1.3769, device='cuda:0')
LOSS is:  tensor(1.0815, device='cuda:0')
LOSS is:  tensor(0.2527, device='cuda:0')
LOSS is:  tensor(2.2513, device='cuda:0')
LOSS is:  tensor(0.0188, device='cuda:0')
LOSS is:  tensor(1.2349, device='cuda:0')
LOSS is:  tensor(1.4027, device='cuda:0')
LOSS is:  tensor(1.5047, device='cuda:0')
LOSS is:  tensor(1.4629, device='cuda:0')
LOSS is:  tensor(0.5950, device='cuda:0')
LOSS is:  tensor(0.8913, device='cuda:0')
LOSS is:  tensor(3.1222, device='cuda:0')
LOSS is:  tensor(1.6499, device='cuda:0')
LOSS is:  tensor(1.2226, device='cuda:0')
LOSS is:  tensor(0.9116, device='cuda:0')
LOSS is:  tensor(1.0578, device='cuda:0')
LOSS is:  tensor(1.2455, device='cuda:0')
LOSS is:  tensor(1.7768, device='cuda:0')
LOSS is:  tensor(0.9400, device='cuda:0')
LOSS is:  tensor(1.5698, device='cuda:0')
LOSS is:  tensor(0.2158, device='cuda:0')
LOSS is:  tensor(0.1059, device='cuda:0')
LOSS is:  tensor(1.7176, device='cuda:0')
LOSS is:  tensor(0.2944, device='cuda:0')
LOSS is:  tensor(2.1427, device='cuda:0')
LOSS is:  tensor(0.7477, device='cuda:0')
LOSS is:  tensor(1.3670, device='cuda:0')
LOSS is:  tensor(0.5853, device='cuda:0')
LOSS is:  tensor(1.1738, device='cuda:0')
LOSS is:  tensor(0.1740, device='cuda:0')
LOSS is:  tensor(0.8109, device='cuda:0')
LOSS is:  tensor(0.8910, device='cuda:0')
LOSS is:  tensor(1.3028, device='cuda:0')
LOSS is:  tensor(0.5702, device='cuda:0')
LOSS is:  tensor(0.4265, device='cuda:0')
LOSS is:  tensor(1.2659, device='cuda:0')
LOSS is:  tensor(0.4221, device='cuda:0')
LOSS is:  tensor(0.8581, device='cuda:0')
LOSS is:  tensor(0.5915, device='cuda:0')
LOSS is:  tensor(0.9419, device='cuda:0')
LOSS is:  tensor(0.0559, device='cuda:0')
LOSS is:  tensor(0.7282, device='cuda:0')
LOSS is:  tensor(0.4989, device='cuda:0')
LOSS is:  tensor(0.0828, device='cuda:0')
LOSS is:  tensor(1.4270, device='cuda:0')
LOSS is:  tensor(0.1221, device='cuda:0')
LOSS is:  tensor(0.1911, device='cuda:0')
LOSS is:  tensor(0.8074, device='cuda:0')
LOSS is:  tensor(0.5060, device='cuda:0')
LOSS is:  tensor(0.6154, device='cuda:0')
LOSS is:  tensor(0.2321, device='cuda:0')
LOSS is:  tensor(0.5992, device='cuda:0')
LOSS is:  tensor(0.2403, device='cuda:0')
LOSS is:  tensor(0.9351, device='cuda:0')
LOSS is:  tensor(1.1906, device='cuda:0')
LOSS is:  tensor(0.0289, device='cuda:0')
LOSS is:  tensor(1.2094, device='cuda:0')
LOSS is:  tensor(0.3920, device='cuda:0')
LOSS is:  tensor(0.8834, device='cuda:0')
LOSS is:  tensor(0.7263, device='cuda:0')
LOSS is:  tensor(0.6950, device='cuda:0')
LOSS is:  tensor(0.1010, device='cuda:0')
LOSS is:  tensor(1.4097, device='cuda:0')
LOSS is:  tensor(0.1742, device='cuda:0')
LOSS is:  tensor(0.0300, device='cuda:0')
LOSS is:  tensor(1.8161, device='cuda:0')
LOSS is:  tensor(0.3895, device='cuda:0')
LOSS is:  tensor(1.4868, device='cuda:0')
LOSS is:  tensor(1.4634, device='cuda:0')
LOSS is:  tensor(1.3246, device='cuda:0')
LOSS is:  tensor(1.1982, device='cuda:0')
 eval_ppl=tensor(2.1922, device='cuda:0') eval_epoch_loss=tensor(0.7849, device='cuda:0')
Eval epoch loss:  tensor(0.7849, device='cuda:0') | best_val_loss:  tensor(0.7612, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/epoch_8
Time while saving:  2023-10-23 07:15:34 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
Epoch 9: train_perplexity=1.1349, train_epoch_loss=0.1266, epoch time 66.00679322704673s
Epoch starting time:  2023-10-23 07:15:34 IST+0530
Training Epoch: 10:   0%|[34m          [0m| 0/5 [00:00<?, ?it/s]Training Epoch: 10/10, step 0/20 completed (loss: 0.13436824083328247):   0%|[34m          [0m| 0/5 [00:03<?, ?it/s]Training Epoch: 10/10, step 1/20 completed (loss: 0.0837775319814682):   0%|[34m          [0m| 0/5 [00:06<?, ?it/s] Training Epoch: 10/10, step 2/20 completed (loss: 0.03548764809966087):   0%|[34m          [0m| 0/5 [00:09<?, ?it/s]Training Epoch: 10/10, step 2/20 completed (loss: 0.03548764809966087):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.08s/it]Training Epoch: 10/10, step 3/20 completed (loss: 0.1375831812620163):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:13<00:52, 13.08s/it] Training Epoch: 10/10, step 4/20 completed (loss: 0.1108846366405487):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:16<00:52, 13.08s/it]Training Epoch: 10/10, step 5/20 completed (loss: 0.10431304574012756):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:19<00:52, 13.08s/it]Training Epoch: 10/10, step 6/20 completed (loss: 0.19817596673965454):  20%|[34mâ–ˆâ–ˆ        [0m| 1/5 [00:22<00:52, 13.08s/it]Training Epoch: 10/10, step 6/20 completed (loss: 0.19817596673965454):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.06s/it]Training Epoch: 10/10, step 7/20 completed (loss: 0.0993393138051033):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:26<00:39, 13.06s/it] Training Epoch: 10/10, step 8/20 completed (loss: 0.06712967902421951):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:29<00:39, 13.06s/it]Training Epoch: 10/10, step 9/20 completed (loss: 0.09214726835489273):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:32<00:39, 13.06s/it]Training Epoch: 10/10, step 10/20 completed (loss: 0.10292910784482956):  40%|[34mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 2/5 [00:35<00:39, 13.06s/it]Training Epoch: 10/10, step 10/20 completed (loss: 0.10292910784482956):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.07s/it]Training Epoch: 10/10, step 11/20 completed (loss: 0.07461759448051453):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:39<00:26, 13.07s/it]Training Epoch: 10/10, step 12/20 completed (loss: 0.06861806660890579):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:42<00:26, 13.07s/it]Training Epoch: 10/10, step 13/20 completed (loss: 0.16889765858650208):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:45<00:26, 13.07s/it]Training Epoch: 10/10, step 14/20 completed (loss: 0.07606630772352219):  60%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 3/5 [00:49<00:26, 13.07s/it]Training Epoch: 10/10, step 14/20 completed (loss: 0.07606630772352219):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.08s/it]Training Epoch: 10/10, step 15/20 completed (loss: 0.17408813536167145):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:52<00:13, 13.08s/it]Training Epoch: 10/10, step 16/20 completed (loss: 0.09588714689016342):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:55<00:13, 13.08s/it]Training Epoch: 10/10, step 17/20 completed (loss: 0.06311823427677155):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [00:58<00:13, 13.08s/it]Training Epoch: 10/10, step 18/20 completed (loss: 0.11969543248414993):  80%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 4/5 [01:02<00:13, 13.08s/it]Training Epoch: 10/10, step 18/20 completed (loss: 0.11969543248414993): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.08s/it]Training Epoch: 10/10, step 19/20 completed (loss: 0.07633664458990097): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.08s/it]Training Epoch: 10/10, step 19/20 completed (loss: 0.07633664458990097): 100%|[34mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 5/5 [01:05<00:00, 13.11s/it]
Epoch ending time:  2023-10-23 07:16:40 IST+0530
Max CUDA memory allocated was 5 GB
Max CUDA memory reserved was 6 GB
Peak active CUDA memory was 5 GB
Cuda Malloc retires : 0
CPU Total Peak Memory consumed during the train (max): 8 GB
evaluating Epoch:   0%|[32m          [0m| 0/100 [00:00<?, ?it/s]evaluating Epoch:   1%|[32m          [0m| 1/100 [00:00<00:55,  1.79it/s]evaluating Epoch:   2%|[32mâ–         [0m| 2/100 [00:00<00:47,  2.06it/s]evaluating Epoch:   3%|[32mâ–Ž         [0m| 3/100 [00:01<00:44,  2.17it/s]evaluating Epoch:   4%|[32mâ–         [0m| 4/100 [00:01<00:43,  2.19it/s]evaluating Epoch:   5%|[32mâ–Œ         [0m| 5/100 [00:02<00:42,  2.24it/s]evaluating Epoch:   6%|[32mâ–Œ         [0m| 6/100 [00:02<00:41,  2.28it/s]evaluating Epoch:   7%|[32mâ–‹         [0m| 7/100 [00:03<00:40,  2.31it/s]evaluating Epoch:   8%|[32mâ–Š         [0m| 8/100 [00:03<00:39,  2.31it/s]evaluating Epoch:   9%|[32mâ–‰         [0m| 9/100 [00:03<00:38,  2.34it/s]evaluating Epoch:  10%|[32mâ–ˆ         [0m| 10/100 [00:04<00:38,  2.33it/s]evaluating Epoch:  11%|[32mâ–ˆ         [0m| 11/100 [00:04<00:37,  2.35it/s]evaluating Epoch:  12%|[32mâ–ˆâ–        [0m| 12/100 [00:05<00:37,  2.35it/s]evaluating Epoch:  13%|[32mâ–ˆâ–Ž        [0m| 13/100 [00:05<00:36,  2.37it/s]evaluating Epoch:  14%|[32mâ–ˆâ–        [0m| 14/100 [00:06<00:36,  2.36it/s]evaluating Epoch:  15%|[32mâ–ˆâ–Œ        [0m| 15/100 [00:06<00:35,  2.40it/s]evaluating Epoch:  16%|[32mâ–ˆâ–Œ        [0m| 16/100 [00:06<00:34,  2.40it/s]evaluating Epoch:  17%|[32mâ–ˆâ–‹        [0m| 17/100 [00:07<00:34,  2.42it/s]evaluating Epoch:  18%|[32mâ–ˆâ–Š        [0m| 18/100 [00:07<00:33,  2.43it/s]evaluating Epoch:  19%|[32mâ–ˆâ–‰        [0m| 19/100 [00:08<00:33,  2.42it/s]evaluating Epoch:  20%|[32mâ–ˆâ–ˆ        [0m| 20/100 [00:08<00:33,  2.41it/s]evaluating Epoch:  21%|[32mâ–ˆâ–ˆ        [0m| 21/100 [00:09<00:32,  2.40it/s]evaluating Epoch:  22%|[32mâ–ˆâ–ˆâ–       [0m| 22/100 [00:09<00:33,  2.35it/s]evaluating Epoch:  23%|[32mâ–ˆâ–ˆâ–Ž       [0m| 23/100 [00:09<00:32,  2.39it/s]evaluating Epoch:  24%|[32mâ–ˆâ–ˆâ–       [0m| 24/100 [00:10<00:32,  2.36it/s]evaluating Epoch:  25%|[32mâ–ˆâ–ˆâ–Œ       [0m| 25/100 [00:10<00:31,  2.37it/s]evaluating Epoch:  26%|[32mâ–ˆâ–ˆâ–Œ       [0m| 26/100 [00:11<00:31,  2.38it/s]evaluating Epoch:  27%|[32mâ–ˆâ–ˆâ–‹       [0m| 27/100 [00:11<00:30,  2.38it/s]evaluating Epoch:  28%|[32mâ–ˆâ–ˆâ–Š       [0m| 28/100 [00:11<00:29,  2.42it/s]evaluating Epoch:  29%|[32mâ–ˆâ–ˆâ–‰       [0m| 29/100 [00:12<00:29,  2.41it/s]evaluating Epoch:  30%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 30/100 [00:12<00:29,  2.40it/s]evaluating Epoch:  31%|[32mâ–ˆâ–ˆâ–ˆ       [0m| 31/100 [00:13<00:28,  2.39it/s]evaluating Epoch:  32%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 32/100 [00:13<00:28,  2.36it/s]evaluating Epoch:  33%|[32mâ–ˆâ–ˆâ–ˆâ–Ž      [0m| 33/100 [00:14<00:28,  2.38it/s]evaluating Epoch:  34%|[32mâ–ˆâ–ˆâ–ˆâ–      [0m| 34/100 [00:14<00:27,  2.36it/s]evaluating Epoch:  35%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 35/100 [00:14<00:27,  2.36it/s]evaluating Epoch:  36%|[32mâ–ˆâ–ˆâ–ˆâ–Œ      [0m| 36/100 [00:15<00:27,  2.37it/s]evaluating Epoch:  37%|[32mâ–ˆâ–ˆâ–ˆâ–‹      [0m| 37/100 [00:15<00:26,  2.36it/s]evaluating Epoch:  38%|[32mâ–ˆâ–ˆâ–ˆâ–Š      [0m| 38/100 [00:16<00:26,  2.36it/s]evaluating Epoch:  39%|[32mâ–ˆâ–ˆâ–ˆâ–‰      [0m| 39/100 [00:16<00:25,  2.37it/s]evaluating Epoch:  40%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 40/100 [00:17<00:25,  2.36it/s]evaluating Epoch:  41%|[32mâ–ˆâ–ˆâ–ˆâ–ˆ      [0m| 41/100 [00:17<00:25,  2.35it/s]evaluating Epoch:  42%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 42/100 [00:17<00:24,  2.36it/s]evaluating Epoch:  43%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž     [0m| 43/100 [00:18<00:23,  2.39it/s]evaluating Epoch:  44%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–     [0m| 44/100 [00:18<00:23,  2.40it/s]evaluating Epoch:  45%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 45/100 [00:19<00:22,  2.40it/s]evaluating Epoch:  46%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ     [0m| 46/100 [00:19<00:22,  2.39it/s]evaluating Epoch:  47%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     [0m| 47/100 [00:19<00:22,  2.40it/s]evaluating Epoch:  48%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–Š     [0m| 48/100 [00:20<00:21,  2.41it/s]evaluating Epoch:  49%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     [0m| 49/100 [00:20<00:21,  2.43it/s]evaluating Epoch:  50%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 50/100 [00:21<00:20,  2.42it/s]evaluating Epoch:  51%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     [0m| 51/100 [00:21<00:20,  2.43it/s]evaluating Epoch:  52%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 52/100 [00:21<00:19,  2.45it/s]evaluating Epoch:  53%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    [0m| 53/100 [00:22<00:19,  2.44it/s]evaluating Epoch:  54%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    [0m| 54/100 [00:22<00:18,  2.43it/s]evaluating Epoch:  55%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 55/100 [00:23<00:18,  2.44it/s]evaluating Epoch:  56%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    [0m| 56/100 [00:23<00:17,  2.44it/s]evaluating Epoch:  57%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    [0m| 57/100 [00:24<00:17,  2.46it/s]evaluating Epoch:  58%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    [0m| 58/100 [00:24<00:16,  2.49it/s]evaluating Epoch:  59%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    [0m| 59/100 [00:24<00:16,  2.47it/s]evaluating Epoch:  60%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 60/100 [00:25<00:16,  2.45it/s]evaluating Epoch:  61%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    [0m| 61/100 [00:25<00:15,  2.47it/s]evaluating Epoch:  62%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 62/100 [00:26<00:15,  2.45it/s]evaluating Epoch:  63%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   [0m| 63/100 [00:26<00:15,  2.43it/s]evaluating Epoch:  64%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   [0m| 64/100 [00:26<00:14,  2.43it/s]evaluating Epoch:  65%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 65/100 [00:27<00:14,  2.42it/s]evaluating Epoch:  66%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   [0m| 66/100 [00:27<00:13,  2.44it/s]evaluating Epoch:  67%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   [0m| 67/100 [00:28<00:13,  2.43it/s]evaluating Epoch:  68%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   [0m| 68/100 [00:28<00:13,  2.42it/s]evaluating Epoch:  69%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   [0m| 69/100 [00:28<00:12,  2.42it/s]evaluating Epoch:  70%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 70/100 [00:29<00:12,  2.42it/s]evaluating Epoch:  71%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   [0m| 71/100 [00:29<00:12,  2.39it/s]evaluating Epoch:  72%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 72/100 [00:30<00:11,  2.38it/s]evaluating Epoch:  73%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  [0m| 73/100 [00:30<00:11,  2.38it/s]evaluating Epoch:  74%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  [0m| 74/100 [00:31<00:10,  2.39it/s]evaluating Epoch:  75%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 75/100 [00:31<00:10,  2.37it/s]evaluating Epoch:  76%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  [0m| 76/100 [00:31<00:10,  2.39it/s]evaluating Epoch:  77%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  [0m| 77/100 [00:32<00:09,  2.38it/s]evaluating Epoch:  78%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  [0m| 78/100 [00:32<00:09,  2.39it/s]evaluating Epoch:  79%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  [0m| 79/100 [00:33<00:08,  2.40it/s]evaluating Epoch:  80%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 80/100 [00:33<00:08,  2.37it/s]evaluating Epoch:  81%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  [0m| 81/100 [00:33<00:07,  2.39it/s]evaluating Epoch:  82%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 82/100 [00:34<00:07,  2.37it/s]evaluating Epoch:  83%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž [0m| 83/100 [00:34<00:07,  2.39it/s]evaluating Epoch:  84%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– [0m| 84/100 [00:35<00:06,  2.39it/s]evaluating Epoch:  85%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 85/100 [00:35<00:06,  2.40it/s]evaluating Epoch:  86%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ [0m| 86/100 [00:36<00:05,  2.38it/s]evaluating Epoch:  87%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ [0m| 87/100 [00:36<00:05,  2.34it/s]evaluating Epoch:  88%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š [0m| 88/100 [00:36<00:05,  2.31it/s]evaluating Epoch:  89%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ [0m| 89/100 [00:37<00:04,  2.31it/s]evaluating Epoch:  90%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 90/100 [00:37<00:04,  2.31it/s]evaluating Epoch:  91%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ [0m| 91/100 [00:38<00:03,  2.29it/s]evaluating Epoch:  92%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 92/100 [00:38<00:03,  2.29it/s]evaluating Epoch:  93%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž[0m| 93/100 [00:39<00:03,  2.28it/s]evaluating Epoch:  94%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–[0m| 94/100 [00:39<00:02,  2.26it/s]evaluating Epoch:  95%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 95/100 [00:40<00:02,  2.27it/s]evaluating Epoch:  96%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ[0m| 96/100 [00:40<00:01,  2.23it/s]evaluating Epoch:  97%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹[0m| 97/100 [00:40<00:01,  2.23it/s]evaluating Epoch:  98%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š[0m| 98/100 [00:41<00:00,  2.27it/s]evaluating Epoch:  99%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰[0m| 99/100 [00:41<00:00,  2.31it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.33it/s]evaluating Epoch: 100%|[32mâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ[0m| 100/100 [00:42<00:00,  2.36it/s]
LOSS is:  tensor(0.0323, device='cuda:0')
LOSS is:  tensor(0.6592, device='cuda:0')
LOSS is:  tensor(0.1308, device='cuda:0')
LOSS is:  tensor(0.0379, device='cuda:0')
LOSS is:  tensor(0.2424, device='cuda:0')
LOSS is:  tensor(2.3174, device='cuda:0')
LOSS is:  tensor(0.9977, device='cuda:0')
LOSS is:  tensor(0.3492, device='cuda:0')
LOSS is:  tensor(0.1983, device='cuda:0')
LOSS is:  tensor(0.4448, device='cuda:0')
LOSS is:  tensor(0.5364, device='cuda:0')
LOSS is:  tensor(0.2695, device='cuda:0')
LOSS is:  tensor(0.0260, device='cuda:0')
LOSS is:  tensor(1.4778, device='cuda:0')
LOSS is:  tensor(0.3914, device='cuda:0')
LOSS is:  tensor(0.1304, device='cuda:0')
LOSS is:  tensor(1.1691, device='cuda:0')
LOSS is:  tensor(1.0550, device='cuda:0')
LOSS is:  tensor(0.1876, device='cuda:0')
LOSS is:  tensor(0.3057, device='cuda:0')
LOSS is:  tensor(0.1801, device='cuda:0')
LOSS is:  tensor(0.6702, device='cuda:0')
LOSS is:  tensor(0.7615, device='cuda:0')
LOSS is:  tensor(0.0106, device='cuda:0')
LOSS is:  tensor(0.0041, device='cuda:0')
LOSS is:  tensor(0.3729, device='cuda:0')
LOSS is:  tensor(0.5560, device='cuda:0')
LOSS is:  tensor(0.0795, device='cuda:0')
LOSS is:  tensor(0.4747, device='cuda:0')
LOSS is:  tensor(1.9008, device='cuda:0')
LOSS is:  tensor(0.7108, device='cuda:0')
LOSS is:  tensor(0.1107, device='cuda:0')
LOSS is:  tensor(2.8707, device='cuda:0')
LOSS is:  tensor(0.0018, device='cuda:0')
LOSS is:  tensor(1.0629, device='cuda:0')
LOSS is:  tensor(1.2788, device='cuda:0')
LOSS is:  tensor(1.0535, device='cuda:0')
LOSS is:  tensor(1.3828, device='cuda:0')
LOSS is:  tensor(0.6535, device='cuda:0')
LOSS is:  tensor(0.6938, device='cuda:0')
LOSS is:  tensor(3.7514, device='cuda:0')
LOSS is:  tensor(1.4301, device='cuda:0')
LOSS is:  tensor(1.1208, device='cuda:0')
LOSS is:  tensor(0.9452, device='cuda:0')
LOSS is:  tensor(1.6981, device='cuda:0')
LOSS is:  tensor(0.4126, device='cuda:0')
LOSS is:  tensor(1.8355, device='cuda:0')
LOSS is:  tensor(0.6650, device='cuda:0')
LOSS is:  tensor(1.5791, device='cuda:0')
LOSS is:  tensor(0.1049, device='cuda:0')
LOSS is:  tensor(0.0684, device='cuda:0')
LOSS is:  tensor(2.0158, device='cuda:0')
LOSS is:  tensor(0.3095, device='cuda:0')
LOSS is:  tensor(2.1714, device='cuda:0')
LOSS is:  tensor(0.4287, device='cuda:0')
LOSS is:  tensor(1.7708, device='cuda:0')
LOSS is:  tensor(0.2584, device='cuda:0')
LOSS is:  tensor(1.4924, device='cuda:0')
LOSS is:  tensor(0.3089, device='cuda:0')
LOSS is:  tensor(0.7484, device='cuda:0')
LOSS is:  tensor(0.3145, device='cuda:0')
LOSS is:  tensor(1.4503, device='cuda:0')
LOSS is:  tensor(0.6175, device='cuda:0')
LOSS is:  tensor(0.3428, device='cuda:0')
LOSS is:  tensor(1.1616, device='cuda:0')
LOSS is:  tensor(0.1105, device='cuda:0')
LOSS is:  tensor(0.6136, device='cuda:0')
LOSS is:  tensor(0.3898, device='cuda:0')
LOSS is:  tensor(0.5696, device='cuda:0')
LOSS is:  tensor(0.0169, device='cuda:0')
LOSS is:  tensor(0.7544, device='cuda:0')
LOSS is:  tensor(0.2851, device='cuda:0')
LOSS is:  tensor(0.0446, device='cuda:0')
LOSS is:  tensor(1.6015, device='cuda:0')
LOSS is:  tensor(0.0370, device='cuda:0')
LOSS is:  tensor(0.0802, device='cuda:0')
LOSS is:  tensor(1.2991, device='cuda:0')
LOSS is:  tensor(0.6254, device='cuda:0')
LOSS is:  tensor(0.5308, device='cuda:0')
LOSS is:  tensor(0.1508, device='cuda:0')
LOSS is:  tensor(0.6536, device='cuda:0')
LOSS is:  tensor(0.1311, device='cuda:0')
LOSS is:  tensor(0.9295, device='cuda:0')
LOSS is:  tensor(1.3592, device='cuda:0')
LOSS is:  tensor(0.0080, device='cuda:0')
LOSS is:  tensor(1.2365, device='cuda:0')
LOSS is:  tensor(0.3412, device='cuda:0')
LOSS is:  tensor(0.7356, device='cuda:0')
LOSS is:  tensor(0.5769, device='cuda:0')
LOSS is:  tensor(0.9063, device='cuda:0')
LOSS is:  tensor(0.0295, device='cuda:0')
LOSS is:  tensor(1.2579, device='cuda:0')
LOSS is:  tensor(0.0715, device='cuda:0')
LOSS is:  tensor(0.0039, device='cuda:0')
LOSS is:  tensor(2.1082, device='cuda:0')
LOSS is:  tensor(0.2670, device='cuda:0')
LOSS is:  tensor(0.5412, device='cuda:0')
LOSS is:  tensor(1.1923, device='cuda:0')
LOSS is:  tensor(1.5203, device='cuda:0')
LOSS is:  tensor(1.2460, device='cuda:0')
 eval_ppl=tensor(2.1173, device='cuda:0') eval_epoch_loss=tensor(0.7502, device='cuda:0')
Eval epoch loss:  tensor(0.7502, device='cuda:0') | best_val_loss:  tensor(0.7612, device='cuda:0')
we are about to save the PEFT modules
SAVE DIR is:  ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827/best_model_yet_epoch_9
Time while saving:  2023-10-23 07:17:22 IST+0530
PEFT modules are saved in ./models_saved/32_32_8f6b78de-c452-4f3f-a312-810f90528827 directory
best eval loss on epoch 10 is 0.7501554489135742
Epoch 10: train_perplexity=1.1098, train_epoch_loss=0.1042, epoch time 65.96658834768459s
Key: avg_train_prep, Value: 1.4247313737869263
Key: avg_train_loss, Value: 0.2949828803539276
Key: avg_eval_prep, Value: 3.4114882946014404
Key: avg_eval_loss, Value: 1.0118982791900635
Key: avg_epoch_time, Value: 66.02703546206467
Key: avg_checkpoint_time, Value: 0.0337987189181149
  0%|          | 0/10 [00:00<?, ?it/s] 10%|â–ˆ         | 1/10 [00:01<00:11,  1.25s/it] 20%|â–ˆâ–ˆ        | 2/10 [00:02<00:08,  1.12s/it] 30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:05<00:16,  2.30s/it] 40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:07<00:10,  1.81s/it] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:08<00:07,  1.53s/it] 60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:08<00:04,  1.25s/it] 70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [00:09<00:03,  1.09s/it] 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [00:10<00:02,  1.05s/it] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [00:11<00:00,  1.05it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.00it/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:12<00:00,  1.23s/it]
Ending time is:  2023-10-23 07:17:36 IST+0530
